<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="神机喵算" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。">
<meta property="og:type" content="website">
<meta property="og:title" content="神机喵算">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="神机喵算">
<meta property="og:description" content="侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神机喵算">
<meta name="twitter:description" content="侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> 神机喵算 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">神机喵算</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/03/17/deep-learning-with-python-chapter-3-3.4/" itemprop="url">
                  《Deep Learning with Python》第三章 3.4 走进神经网络之电影影评分类
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-03-17T12:15:58+08:00" content="2018-03-17">
              2018-03-17
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="3-4-电影影评分类"><a href="#3-4-电影影评分类" class="headerlink" title="3.4 电影影评分类"></a>3.4 电影影评分类</h5><p>二元分类，或者称为二值分类，可能是应用最广泛的机器学习问题。通过学习本例，你将掌握如何基于文本内容将影评分为正、负二类。</p>
<h6 id="3-4-1-IMDB数据集"><a href="#3-4-1-IMDB数据集" class="headerlink" title="3.4.1 IMDB数据集"></a>3.4.1 IMDB数据集</h6><p>本文将从互联网电影数据库（IMDB）获取50,000个流行电影影评作为数据集。这里将其分割为25,000个影评的训练集和25,000个影评的测试集。其中每个数据集都包含50%的好评和50%的差评。</p>
<p>为什么要将数据集分割成训练集和测试集呢？因为测试机器学习模型所使用的数据集不能和训练该模型的数据集是同一个。在训练集上表现良好的模型，并不意味着一定会在“未曾见过”的测试集上也有相同的表现。也就是说，你更关注的是训练的模型在新数据集上的性能（因为训练集数据的标签是已知的，很显然这些是不需要去预测的）。例如，可能你的模型可以将训练样本和对应的目标在内存中进行一一映射，但是这个模型对从“未见过的”数据无法进行预测。下一章会更详细的讨论该观点。</p>
<p>Keras已经包括IMDB数据集，并进行了数据预处理：影评（单词序列）转换成整数序列，这里每个整数代表对应单词在字典的索引值。</p>
<p>下面的代码将加载IMDB数据集，当你首次运行该代码，将会在服务器上下载大约80M的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.1 Loading the IMDB dataset</span></div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdv</div><div class="line">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(</div><div class="line">num_words=<span class="number">10000</span>)</div></pre></td></tr></table></figure>
<p>设置参数num_words=10000，保留训练集中词频为top 10000的单词，低频单词丢弃。变量train_data和test_data是影评列表（list），每条影评看成是单词序列，用单词索引进行编码。train_labels和test_labels是0和1的列表，其中0代表差评（negative），1代表好评（positive）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>train_data[<span class="number">0</span>]</div><div class="line">[<span class="number">1</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">16</span>, ... <span class="number">178</span>, <span class="number">32</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>train_labels[<span class="number">0</span>]</div><div class="line"><span class="number">1</span></div></pre></td></tr></table></figure>
<p>前面限制影评中的单词词频为top 10000，所以单词的索引不会超过10000：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>max([max(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> train_data])</div><div class="line"><span class="number">9999</span></div></pre></td></tr></table></figure>
<p>下面来个好玩的，如何将编码后的影评进行解码得到单词呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">word_index is a dictionary mapping</div><div class="line">words to an integer index.</div><div class="line">'''</div><div class="line">word_index = imdb.get_word_index()</div><div class="line">reverse_word_index = dict(</div><div class="line"><span class="string">'''</span></div><div class="line">Reverses it, mapping integer indices to words</div><div class="line">'''</div><div class="line">    [(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</div><div class="line">decoded_review = <span class="string">' '</span>.join(</div><div class="line"><span class="string">'''</span></div><div class="line">Decodes the review. Note that the indices</div><div class="line">are offset by 3 because 0, 1, and 2 are</div><div class="line">reserved indices for “padding,” “start of</div><div class="line">sequence,” and “unknown.”</div><div class="line">'''</div><div class="line">    [reverse_word_index.get(i - <span class="number">3</span>, <span class="string">'?'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</div></pre></td></tr></table></figure>
<h6 id="3-4-2-准备数据"><a href="#3-4-2-准备数据" class="headerlink" title="3.4.2 准备数据"></a>3.4.2 准备数据</h6><p>神经网络不能输入整数列表，所以需要将整数列表转换成张量。有两种方式可以实现：</p>
<ul>
<li>填充列表：先将列表填充成相同长度的，再转成形状为（样本数，单词索引长度）的整数张量。接着用神经网络的第一层layer（Embedding layer）处理整数张量。</li>
<li>one-hot编码：one-hot编码是将单词索引转成0、1的向量。比如，将序列[3, 5]转成10,000维向量，其中索引3和5的值为1，其它索引对应的值为0。然后使用神经网络的Dense layer作为第一层layer处理浮点型向量数据。</li>
</ul>
<p>下面采用后一种方法向量化数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></div><div class="line">    <span class="comment">#Creates an all-zero matrix of shape (len(sequences), dimension)</span></div><div class="line">    results = np.zeros((len(sequences), dimension))</div><div class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</div><div class="line">         <span class="string">'''</span></div><div class="line">         Sets specific indices of results[i] to 1s</div><div class="line">         '''</div><div class="line">          results[i, sequence] = <span class="number">1.</span></div><div class="line">    <span class="keyword">return</span> results</div><div class="line"><span class="string">'''</span></div><div class="line">Vectorized training data and test data</div><div class="line">'''</div><div class="line">x_train = vectorize_sequences(train_data)</div><div class="line">x_test = vectorize_sequences(test_data)</div></pre></td></tr></table></figure>
<p>下面看下向量化后的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x_train[<span class="number">0</span>]</div><div class="line">array([ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]</div></pre></td></tr></table></figure>
<p>同理，向量化对应的label：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">y_train = np.asarray(train_labels).astype(<span class="string">'float32'</span>)</div><div class="line">y_test = np.asarray(test_labels).astype(<span class="string">'float32'</span>)</div></pre></td></tr></table></figure>
<p>数据准备好了，就等着传入神经网络模型。</p>
<h6 id="3-4-3-构建神经网络模型"><a href="#3-4-3-构建神经网络模型" class="headerlink" title="3.4.3 构建神经网络模型"></a>3.4.3 构建神经网络模型</h6><p>输入数据为向量，label为标量（1和0），相当简单。一系列带有relu激活函数的全联接层（Dense layer）的神经网络就可以很好的解决影评分类：Dense(16, activation=’relu’)。</p>
<p>每个Dense layer设置隐藏单元（<em>hidden unit</em>）数为16。<em>hidden unit</em>是layer的一维表征空间。由第二章得知，每个带有relu激励函数的Dense layer可以实现下面链式的张量操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">output = relu(dot(W, input) + b)</div></pre></td></tr></table></figure>
<p>16个<em>hidden unit</em>意味着权重矩阵的形状为（输入维度，16）:输入数据与权重矩阵W点积的结果是投影到16维表征空间（，接着加上偏置向量b，然后应用relu激活操作）。给人的直觉是表征空间的维数即是中间学习表示的自由度。<em>hidden unit</em>越多（高维表征空间）允许神经网络学习更复杂的表示，但同时也让神经网络计算成本增加，可能导致不可预期的模式（模式会提高训练集上的性能，降低测试集上的表现，也就是常说的“过拟合”现象）。</p>
<p>逐层排列的Dense layer架构有两个关键点：</p>
<ul>
<li>选择多少层Dense layer</li>
<li>每个Dense layer选择多少个<em>hidden unit</em></li>
</ul>
<p>在第四章中的常规性原则将会指导你对上述问题做出选择。此时，你就暂时相信下面的架构选择哦：</p>
<ul>
<li>两个具有16个<em>hidden unit</em>的中间层</li>
<li>第三层layer将输出当前影评的情感预测值（标量）</li>
</ul>
<p>中间层使用relu作为激活函数，最后一层layer使用sigmoid激活函数，输出0到1之间的概率值。激活函数relu（rectified linear unit（修正线性单元），ReLU），对于所有负值都置为0，而正值不变，见图3.4；而激活函数sigmoid将变量值映射为[0, 1]区间，可以看作是概率值，见图3.5。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-8c1b32ee4e274044..png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图3.4 Relu激活函数</p>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-59e3a51f28a20168..png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图3.5 Sigmoid激活函数</p>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-c1ef5755c15b6a15..png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图3.6 三层layer神经网络</p>
<p>图3.6显示了神经网络的大体架构。下面是Keras的实现，和前面MNIST数字识别的例子类似：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.3 The model definition</span></div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div><div class="line">model = models.Sequential()</div><div class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</div><div class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>)) model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div></pre></td></tr></table></figure>
<blockquote>
<p>什么是激活函数呢？为什么要使用激活函数？</p>
<p>没有像relu这样的激活函数（俗称非线性单元）的话，那Dense layer只剩下两个线性操作：点积和加法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; output = dot(W, input) + b</div><div class="line">&gt;</div></pre></td></tr></table></figure>
</blockquote>
<p>&gt;</p>
<blockquote>
<p>这样layer只能学习到输入数据的线性变换（仿射变换）：layer的假设空间就成了输入数据的所有可能的线性变换到16维表征空间的集合。这样的假设空间并不能学习到多层layer的表征，因为一系列的线性layer等效于一个线性操作：layer数的增加并不会扩展假设空间。</p>
<p>为了从深度学习中得到更丰富的假设空间，你需要加入非线性部分，或者激活函数。relu是深度学习中最常用的激活函数之一，但是也有其它可选：prelu激活函数、elu激活函数等等。</p>
</blockquote>
<p>接着，选择损失函数和优化器。因为本例是二值分类问题，神经网络模型输出是概率值（网络的最后一层layer带有sigmoid激活函数，输出一维数据），所以最好的损失函数是binary_crossentropy损失函数。但这不是唯一的选择，你也可以使用mean_squared_error损失函数。一般输出为概率值的模型优先选择交叉熵损失函数（<em>crossentropy</em>）。交叉熵是信息论中的指标，用来度量概率分布之间的距离。本例是用来度量实际分布与预测值的差距。</p>
<p>这里为模型选择binary_crossentropy损失函数和rmsprop优化器。注意监控模型训练过程中的准确度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.4 Compiling the model</span></div><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</div><div class="line">loss=<span class="string">'binary_crossentropy'</span>,</div><div class="line">metrics=[<span class="string">'accuracy'</span>])</div></pre></td></tr></table></figure>
<p>上面传入的优化器<em>optimizer</em>、损失函数<em>loss</em>和指标<em>metrics</em>三个参数都是字符串型，这是因为’rmsprop’、’binary_crossentropy’和’accuracy’都是Keras内置实现的。如果想配置自定义的优化器或者损失函数或者指标函数，你可以用参数<em>optimizer</em>传入优化器类，见代码3.5；用参数<em>loss</em>和<em>metrics</em>传入函数对象，见代码3.6：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.5 Configuring the optimiser</span></div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimisers</div><div class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</div><div class="line">loss=<span class="string">'binary_crossentropy'</span>,</div><div class="line">metrics=[<span class="string">'accuracy'</span>])</div><div class="line"></div><div class="line"><span class="comment">#Listing 3.6 Using custom losses and metrics</span></div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> losses</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> metrics</div><div class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</div><div class="line">loss=losses.binary_crossentropy,</div><div class="line">metrics=[metrics.binary_accuracy])</div></pre></td></tr></table></figure>
<h6 id="3-4-4-验证模型"><a href="#3-4-4-验证模型" class="headerlink" title="3.4.4 验证模型"></a>3.4.4 验证模型</h6><p>为了监控模型训练过程中模型在新数据上的准确度，需要从原始的训练数据集中分出10,000个样本作为验证集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.7 Setting aside a validation set</span></div><div class="line">x_val = x_train[:<span class="number">10000</span>]</div><div class="line">partial_x_train = x_train[<span class="number">10000</span>:]</div><div class="line"></div><div class="line">y_val = y_train[:<span class="number">10000</span>]</div><div class="line">partial_y_train = y_train[<span class="number">10000</span>:]</div></pre></td></tr></table></figure>
<p>现在开始模型训练，迭代训练的epoch（在所有训练集数据上跑完一次称为一个epoch）为20个，mini-batch大小为512。训练过程中监控验证集数据上的损失函数和准确度，设置参数validation_data。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.8 Training your model</span></div><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</div><div class="line">loss=<span class="string">'binary_crossentropy'</span>,</div><div class="line">metrics=[<span class="string">'acc'</span>])</div><div class="line">history = model.fit(partial_x_train,</div><div class="line">partial_y_train,</div><div class="line">epochs=<span class="number">20</span>,</div><div class="line">batch_size=<span class="number">512</span>,</div><div class="line">validation_data=(x_val, y_val))</div></pre></td></tr></table></figure>
<p>在CPU上训练模型时，每个epoch耗时不到2秒，整个训练过程大概持续20秒。每个epoch结束时，会有个短暂的停顿，这时模型会计算验证集数据上的损失值和准确度。</p>
<p>注意，调用model.fit()会返回一个History对象，该对象有个history成员，它是一个包含训练过程的每个数据的字典。下面来看下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>history_dict = history.history</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>history_dict.keys()</div><div class="line">[<span class="string">u'acc'</span>, <span class="string">u'loss'</span>, <span class="string">u'val_acc'</span>, <span class="string">u'val_loss'</span>]</div></pre></td></tr></table></figure>
<p>history字典有四项：模型训练和验证中每个指标一项。接下来的两段代码，使用Matplotlib在同一幅图中绘制训练集损失和验证集损失，见图3.7；同时将训练集准确度和验证集准确度绘制在同一幅图中，见图3.8。注意，因为神经网络的初始化是随机的，可能会导致你的结果与本例稍有差别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.9 Plotting the training and validation loss</span></div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> pet</div><div class="line"></div><div class="line">history_dict = history.history</div><div class="line">loss_values = history_dict[<span class="string">'loss'</span>]</div><div class="line">val_loss_values = history_dict[<span class="string">'val_loss'</span>]</div><div class="line"></div><div class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">“bo” is for “blue dot.”</div><div class="line">“b” is for “solid blue line.”</div><div class="line">'''</div><div class="line">plt.plot(epochs, loss_values, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>) plt.plot(epochs, val_loss_values, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</div><div class="line">plt.title(<span class="string">'Training and validation loss'</span>)</div><div class="line">plt.xlabel(<span class="string">'Epochs'</span>)</div><div class="line">plt.ylabel(<span class="string">'Loss'</span>)</div><div class="line">plt.legend()</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-7dc921898c9a6b17..png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图3.7 迭代训练中训练集和验证集的损失趋势</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.10 Plotting the training and validation accuracy</span></div><div class="line"><span class="comment">#Clears the figure</span></div><div class="line">plt.clf()</div><div class="line">acc_values = history_dict[<span class="string">'acc'</span>]</div><div class="line">val_acc_values = history_dict[<span class="string">'val_acc'</span>]</div><div class="line"></div><div class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</div><div class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</div><div class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</div><div class="line">plt.xlabel(<span class="string">'Epochs'</span>)</div><div class="line">plt.ylabel(<span class="string">'Loss'</span>)</div><div class="line">plt.legend()</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-45638c54a2426c6a..png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图3.8 迭代训练中的训练集和验证集的准确度趋势</p>
<p>正如你所见，随着迭代训练的epoch，训练损失值不断减小，而准确度不断提升。这也是执行梯度下降优化器期待的结果：不断迭代训练减小损失。但是验证集数据上的损失值和准确度表现的并不是如此：验证集在第四个epoch后效果达到最好。这也是前面提醒过的：模型在训练集上表现良好并不代表在新数据集上也有同样的表现。准确地来讲，这是过拟合（<em>overfiting</em>）：在迭代训练第2个epoch后，模型在训练集上出现了过度优化，最终的学习表征像是为训练集特制的，对新数据丧失了泛化能力。</p>
<p>本例中，为了防止过拟合出现，需要在迭代训练3个epoch后停止训练。一般来讲，我们可以使用多种技术解决过拟合，这些会在第四章中详细介绍。</p>
<p>下面从头迭代训练4个epoch生成新的神经网络，并在测试集上评估效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 3.11 Retraining a model from scratch</span></div><div class="line">model = models.Sequential()</div><div class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,))) model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>)) model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</div><div class="line">              loss=<span class="string">'binary_crossentropy'</span>,</div><div class="line">              metrics=[<span class="string">'accuracy'</span>])</div><div class="line">model.fit(x_train, y_train, epochs=<span class="number">4</span>, batch_size=<span class="number">512</span>)</div><div class="line">results = model.evaluate(x_test, y_test)</div></pre></td></tr></table></figure>
<p>最好的评估结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>results</div><div class="line">[<span class="number">0.2929924130630493</span>, <span class="number">0.88327999999999995</span>]</div></pre></td></tr></table></figure>
<p>这个相当直白的方法获得了88%的准确度。使用最新的方法，你将会得到接近95%的准确度。</p>
<h6 id="3-4-5-模型预测"><a href="#3-4-5-模型预测" class="headerlink" title="3.4.5 模型预测"></a>3.4.5 模型预测</h6><p>训练完神经网络模型，使用predict方法进行影评情感预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>model.predict(x_test)</div><div class="line">array([[ <span class="number">0.98006207</span>]</div><div class="line">       [ <span class="number">0.99758697</span>]</div><div class="line">       [ <span class="number">0.99975556</span>]</div><div class="line">       ...,</div><div class="line">       [ <span class="number">0.82167041</span>]</div><div class="line">       [ <span class="number">0.02885115</span>]</div><div class="line">       [ <span class="number">0.65371346</span>]], dtype=float32)</div></pre></td></tr></table></figure>
<p>正如你所看到的结果，神经网络模型对一些样本数据的预测结果自信（概率为0.99或者更高，或者0.01或者更小），但是对另外一些的预测结果不是太自信（概率为0.6，0.4的情况）。</p>
<h6 id="3-4-6-延伸实验"><a href="#3-4-6-延伸实验" class="headerlink" title="3.4.6 延伸实验"></a>3.4.6 延伸实验</h6><p>下面的一些实验使得神经网络的架构选择更合理些（虽然还是有待提升的空间）：</p>
<ul>
<li>本例使用的两个隐藏层。可以尝试选择一个或者三个隐藏层，看下会怎样影响验证集和测试集的准确度；</li>
<li>选择更多的<em>hidden unit</em>或者更少的<em>hidden unit</em>：32个unit，64个unit等等；</li>
<li>使用mse损失函数代替binary_crossentropy损失函数；</li>
<li>使用tanh激活函数（在神经网络早期常用的激活函数）代替relu激活函数。</li>
</ul>
<h6 id="3-4-7-总结"><a href="#3-4-7-总结" class="headerlink" title="3.4.7 总结"></a>3.4.7 总结</h6><p>从本实例学到的知识点：</p>
<ul>
<li>原始数据集预处理为张量传入神经网络。单词序列编码为二值向量或者其它形式；</li>
<li>一系列带有relu激活函数的Dense layer能解决广泛的问题，包括情感分类，后续会常用到的；</li>
<li>二值分类问题（输出两个类别）中，最后的一个Dense layer带有一个sigmoid激活函数和一个单元：网络输出是0到1之间的标量，代表概率值；</li>
<li>二分类问题中有sigmoid标量输出的，损失函数选择binary_crossentropy损失函数；</li>
<li>rmsprop优化器对于大部分深度学习模型来说是足够好的选择；</li>
<li>随着在训练集上表现越来越好，神经网络模型开始过拟合，在新数据上表现越来越差。关注验证集上的监控指标</li>
</ul>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<blockquote>
<p>翻译本书系列的初衷是，觉得其中把深度学习讲解的通俗易懂。不光有实例，也包含作者多年实践对深度学习概念、原理的深度理解。最后说不重要的一点，François Chollet是Keras作者。<br>声明本资料仅供个人学习交流、研究，禁止用于其他目的。如果喜欢，请购买英文原版。</p>
</blockquote>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/03/17/deep-learning-with-python-chapter-3-3.2/" itemprop="url">
                  《Deep Learning with Python》第三章 3.2 走进神经网络之Keras简单入门
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-03-17T12:15:17+08:00" content="2018-03-17">
              2018-03-17
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="3-2-Keras简单入门"><a href="#3-2-Keras简单入门" class="headerlink" title="3.2 Keras简单入门"></a>3.2 Keras简单入门</h5><p>全书使用的代码示例采用Keras（<a href="https://keras.io）实现。Keras是一个Python编写的深度学习框架，提供方便的方式定义和训练几乎所有的深度学习模型。Keras原本是为研究者开发的，旨在加速试验。Keras具有以下特色：" target="_blank" rel="external">https://keras.io）实现。Keras是一个Python编写的深度学习框架，提供方便的方式定义和训练几乎所有的深度学习模型。Keras原本是为研究者开发的，旨在加速试验。Keras具有以下特色：</a></p>
<ul>
<li>同一段代码可以在CPU或者GPU上无缝切换</li>
<li>用户友好的API使得创建深度学习模型的原型更简单</li>
<li>內建支持卷积神经网络（计算机视觉）、循环神经网络（序列处理），以及两者的任意组合</li>
<li>支持任意网络结构：多输入或者多输出模型，layer共享，模型共享，等等。这意味着Keras能构建任意深度学习模型，从对抗生成网络到图灵机。</li>
</ul>
<p>Keras采用MIT license分发，意味着可以在商业项目中使用。截止到2017年中旬，Keras同时兼容Python 2.7到3.6版本。</p>
<p>Keras已有超过200,000个使用者，涵盖从学术研究到工业企业（包括创业公司和大型公司）。Google、Netflix、Uber、Yelp和成百上千的创业公司使用Keras解决各种问题。Keras也是机器学习竞赛网站Kaggle最流行的使用框架。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-133c6b2bc31bc930..jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图 3.2 Google搜索中深度学习框架的关注度趋势</p>
<h6 id="3-2-1-Keras、TensorFlow、Theano和CNTK"><a href="#3-2-1-Keras、TensorFlow、Theano和CNTK" class="headerlink" title="3.2.1 Keras、TensorFlow、Theano和CNTK"></a>3.2.1 Keras、TensorFlow、Theano和CNTK</h6><p>Keras提供high-level的开发深度学习模型的构建模块，其是model-level的库。Keras不能解决low-level的操作，比如张量操作和差分。Keras可以依赖指定的、经过优化的张量操作库作为其后端引擎（<em>backend engine</em>），而不是选择一个张量库去试图作为Keras的实现。Keras是以模块化的方式解决问题，见图3.3，不同的后端引擎能够为Keras进行无缝地扩展。当前已经存在三种后端引擎实现：TensorFlow后端引擎，Theano后端引擎，和CNTK后端引擎。将来可能会为Keras扩展更多的深度学习执行引擎。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/9803709-93fb1cf14e0132ec..jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<p>图3.3 深度学习软件和硬件栈</p>
<p>TensorFlow、CNTK和Theano是当前主流的深度学习平台，其中Theano（<a href="http://deeplearning.net/software/theano）是蒙特利尔大学大学MILA实验室开发的，TensorFlow（www.tensorflow.org）由谷歌开发，CNTK（https://github.com/Microsoft/CNTK）由微软开发。用Keras编写的代码不用做任何改变即可在这些执行引擎上运行。在深度学习模型开发阶段，使用Keras可以在两种不同的执行引擎之间切换，比如，解决某种任务时，其中某个执行引擎执行会快。我们推荐使用TensorFlow作为深度学习模型的默认执行引擎，因为TensorFlow已经被广泛采纳、扩展，以及产品化。" target="_blank" rel="external">http://deeplearning.net/software/theano）是蒙特利尔大学大学MILA实验室开发的，TensorFlow（www.tensorflow.org）由谷歌开发，CNTK（https://github.com/Microsoft/CNTK）由微软开发。用Keras编写的代码不用做任何改变即可在这些执行引擎上运行。在深度学习模型开发阶段，使用Keras可以在两种不同的执行引擎之间切换，比如，解决某种任务时，其中某个执行引擎执行会快。我们推荐使用TensorFlow作为深度学习模型的默认执行引擎，因为TensorFlow已经被广泛采纳、扩展，以及产品化。</a></p>
<p>通过TensorFlow（CNTK或者Theano），Keras能在CPU和GPU上无缝运行。TensorFlow封装low-level的Eigen（<a href="http://eigen.tuxfamily.org）张量操作库来运行CPU；封装经过优化的深度学习操作的库，即NVIDIA" target="_blank" rel="external">http://eigen.tuxfamily.org）张量操作库来运行CPU；封装经过优化的深度学习操作的库，即NVIDIA</a> CUDA神经网络库（cuDNN），来运行GPU。</p>
<h6 id="3-2-2-使用Keras开发：快速预览"><a href="#3-2-2-使用Keras开发：快速预览" class="headerlink" title="3.2.2 使用Keras开发：快速预览"></a>3.2.2 使用Keras开发：快速预览</h6><p>你已经看过一个Keras模型的例子：MNIST数字识别的实例。典型的Keras工作流程就像如下的例子：</p>
<ol>
<li>定义训练数据集：输入张量和目标张量</li>
<li>定义layer的网络（或者model）：将输入张量映射为目标张量</li>
<li>配置学习过程：选定损失函数、优化器和监控的一些指标</li>
<li>迭代训练数据：调用模型的fit()函数在训练数据集上迭代训练</li>
</ol>
<p>有两种方式定义神经网络模型：使用<em>Sequential</em>类（专为layer的线性逐层连接的模型，截止目前大部分都是此类模型）或者使用函数式API（为有向无环图式layer连接的模型，可以构建任意形式的模型）。</p>
<p>对于新手来讲，下面的例子使用<em>Sequential</em>类定义两层layer的模型（注意，为第一个layer传入指定形状的输入数据）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div><div class="line">model = models.Sequential()</div><div class="line">model.add(layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">784</span>,)))</div><div class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</div></pre></td></tr></table></figure>
<p>接着用函数式API定义上述相同的模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">input_tensor = layers.Input(shape=(<span class="number">784</span>,))</div><div class="line">x = layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)(input_tensor)</div><div class="line">output_tensor = layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)(x)</div><div class="line">model = models.Model(inputs=input_tensor, outputs=output_tensor)</div></pre></td></tr></table></figure>
<p>使用函数式API操作模型处理的数据张量，将layer应用于这些张量，就好像它们是函数一样使用。</p>
<blockquote>
<p>备注：函数式API的详细使用教程将在第七章介绍。在第七章之前，代码例子会使用<em>Sequential</em>类创建模型。</p>
</blockquote>
<p>一旦定义好了模型架构，使用<em>Sequential</em>模型还是函数式API模型都不重要。下面的步骤是相同的。</p>
<p>在编译步骤配置学习过程，指定使用模型的优化器和损失函数，选择训练的监控指标。下面的例子使用单个损失函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimisers</div><div class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</div><div class="line">loss=<span class="string">'use'</span>,</div><div class="line">metrics=[<span class="string">'accuracy'</span>])</div></pre></td></tr></table></figure>
<p>最后，为模型传入输入数据和相应的目标数据的Numpy数组，通过fit()函数进行学习过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.fit(input_tensor, target_tensor, batch_size=<span class="number">128</span>, epochs=<span class="number">10</span>)</div></pre></td></tr></table></figure>
<p>后面几个章节将会帮你建立坚实的直觉：哪类的问题适用哪种网络架构？如何选择正确的学习配置？如何调整模型直到得到想要的结果？下面将会在3.4，3.5和3.6小节介绍三个基本的例子：二分类，多分类和回归。</p>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<blockquote>
<p>翻译本书系列的初衷是，觉得其中把深度学习讲解的通俗易懂。不光有实例，也包含作者多年实践对深度学习概念、原理的深度理解。最后说不重要的一点，François Chollet是Keras作者。<br>声明本资料仅供个人学习交流、研究，禁止用于其他目的。如果喜欢，请购买英文原版。</p>
</blockquote>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/02/11/deep-learning-with-python-chapter-3-3.1/" itemprop="url">
                  《Deep Learning with Python》第三章 3.1 走进神经网络之神经网络剖析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-02-11T12:38:52+08:00" content="2018-02-11">
              2018-02-11
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>第三章 走进神经网络</p>
<p>本章涉及的知识点：</p>
<ul>
<li><p>神经网络核心组件</p>
</li>
<li><p>开始Keras之旅</p>
</li>
<li><p>组建深度学习工作站</p>
</li>
<li><p>使用神经网络解决基本的分类和回归问题</p>
<p>本章开始使用神经网络解决实际问题。巩固第二章中的示例，并应用学到的知识解决三类问题，其可以覆盖最常见三类神经网络场景：二值分类，多分类和线性回归。</p>
<p>本章将仔细讲解第二章涉及的神经网络核心组件：layer，网络，观察函数和优化器。接着快速的过一下Keras，其是本章通篇使用的Python深度学习库。组建支持TensorFlow、Keras和GPU的深度学习工作站。然后将着重深挖使用深度学习解决三个实际问题：</p>
<ul>
<li>影评分类（好评或者差评，二分类）</li>
<li>路途社新闻主题（多分类）</li>
<li>预估房价（回归）</li>
</ul>
<p>本章之后，你会使用神经网络解决简单的机器学习问题，比如，分类问题和回归问题。你将在第四章开始建立更有原则性、理论驱动的理解机器学习。</p>
<h5 id="3-1-神经网络剖析"><a href="#3-1-神经网络剖析" class="headerlink" title="3.1 神经网络剖析"></a>3.1 神经网络剖析</h5><p>训练神经网络模型绕不开下面的对象：</p>
<ul>
<li>Layer：layer可以组成一个网络（network）或者模型（model）</li>
<li>输入数据和相应的目标</li>
<li>损失函数：损失函数定义深度学习中的反馈信号</li>
<li>优化器：优化器决定深度学习的行进</li>
</ul>
<p>如图3.1所示，可视化上述对象间的交互：网络是由多个layer联结组成的，将输入数据映射到输出的预测数据。损失函数则比较预测值和目标的差值，意即损失值。优化器最小化损失函数来调整网络权重。</p>
<p><img src="http://img0.ph.126.net/AYl7KUwGk9DdvOaJopqpDQ==/1034702014408438491.png" alt="image"></p>
<p>图3.1  网络、layer、损失函数和优化器之间的关系</p>
<p>下面详细介绍网络、layer、损失函数和优化器。</p>
<h6 id="3-1-1-Layer：深度学习的基础组件"><a href="#3-1-1-Layer：深度学习的基础组件" class="headerlink" title="3.1.1 Layer：深度学习的基础组件"></a>3.1.1 Layer：深度学习的基础组件</h6><p>神经网络的基础数据结构是layer，其在第二章中有提到。layer是将一个或者多个输入张量转换成一个或者多个输出张量的数据处理模块。有些layer是无状态的，但是更多的layer是带状态的：layer的权重，该权重是由随机梯度下降学习的一个或者几个张量，它们包含网络的知识（<em>knowledge</em>）。</p>
<p>不同的张量格式和数据类型需要不同的layer进行数据处理，比如，简单的向量数据存储成形状为（样本，特征）的2D张量，它经常用致密的全联接层（也称为全联接层或者致密层，Keras中的<em>Dense</em>类）处理。序列数据存储成形状为（样本，时间戳，特征）的3D张量，使用循环神经网络层（<em>recurrent layer</em>，比如，LSTM layer）处理。图片数据存储成4D张量，常用2D卷积层（<em>Conv2D</em>）处理。</p>
<p>Layer犹如深度学习的“乐高积木”，Keras通过剪辑拼接兼容的layer来构建深度学习模型，从而形成数据转换的管道。这里layer的兼容性特指：每类layer只接受一定形状的输入张量，返回一定形状的输出张量。下面看个具体的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div><div class="line">layer = layers.Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,))</div></pre></td></tr></table></figure>
<p>上面的例子中，创建一个只接受2D张量的layer，该2D张量的第一个维度是784（轴0，batch维度并没有指定，因此它可以接受任意值）。该layer返回第一个维度是32的张量。</p>
<p>因此，这个layer联结的下游layer是以32维的向量为输入。使用Keras时无需担心layer的兼容性，因为加入到模型的layer会自动适配上一layer的形状。例如，下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div><div class="line"></div><div class="line">model = models.Sequential()</div><div class="line">model.add(layers.Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,)))</div><div class="line">model.add(layers.Dense(<span class="number">32</span>))</div></pre></td></tr></table></figure>
<p>其中第二个layer没有输入形状的参数，但是它可以自动推导其输入张量的形状是前一个layer的输出张量的形状。</p>
<h6 id="3-1-2-模型：层的网络（networks-of-layers）"><a href="#3-1-2-模型：层的网络（networks-of-layers）" class="headerlink" title="3.1.2 模型：层的网络（networks of layers）"></a>3.1.2 模型：层的网络（networks of layers）</h6><p>深度学习模型是一个有向无环图。最常见的例子是layer的逐层排列、线性连接，将单个输入映射到单个输出。</p>
<p>继续深究，你会发现更多种网络拓扑的变种。下面是一些常用的网络拓扑：</p>
<ul>
<li>Two-branch网络</li>
<li>Multihead网络</li>
<li>感知机</li>
</ul>
<p>网络组成的拓扑定义了假设空间（hypothesis space）。你可能还记得第一章中机器学习的定义：在预定的可能空间中，基于反馈信号寻找输入数据集的有效的表示。选定了一个网络拓扑，意味着限制了一系列张量操作的可行性空间（假设空间）。为权重张量搜索一组合适的值，将输入数据映射到输出数据。</p>
<p>挑选正确的网络结构更像是一个艺术活，而不是一种科学。虽然有一些最佳实践和基本原则貌似可以依赖，但是实际上只有不断地实践才能帮你成为合适的神经网络架构师。后面几个章节将会教你明确的原则构建神经网络，帮你塑造直面问题的直觉。</p>
<h6 id="3-1-3-损失函数和优化器：掌控学习的进度"><a href="#3-1-3-损失函数和优化器：掌控学习的进度" class="headerlink" title="3.1.3 损失函数和优化器：掌控学习的进度"></a>3.1.3 损失函数和优化器：掌控学习的进度</h6><p>一旦网络定义好，接着迫在眉睫的是以下两件事：</p>
<ul>
<li>损失函数（观察函数）：模型训练中损失函数值最小化，意味着任务的成功；</li>
<li>优化器：决定基于损失函数的神经网络如何迭代。它一般是随机梯度下降（stochastic gradient descent，SGD）的某种变体。</li>
</ul>
<p>有多路输出的神经网络可能有多个损失函数（每路输出一个损失函数）。而梯度下降的过程必须基于单个标量损失值；所以，对于多损失函数的网络，所有损失函数被组合（一般通过平均）成单个标量值。</p>
<p>选择好正确的观察函数对于解决问题来说是至关重要的：你的网络尽可能找到最小化损失的捷径。所以，如果观察函数不能很好的与任务的成功相关联，那网络迭代结束并不会得到预想的结果。记住所有的神经网络都是最小化损失函数。</p>
<p>幸运地是，对于常见问题（比如分类、回归、序列预测），有些简单的指导原则来选择正确的损失函数。例如，二分类问题采用二值交叉熵损失，多分类问题采用分类交叉熵，回归问题选取均方误差，序列化学习问题选择联结时序分类（connectionist temporal classification，CTC）损失，等等。只有当你遇到完全新的问题，才需要开发自定义的观察函数。后面几章将会详细的阐述哪类问题选择哪种损失函数。</p>
</li>
</ul>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<blockquote>
<p>翻译本书系列的初衷是，觉得其中把深度学习讲解的通俗易懂。不光有实例，也包含作者多年实践对深度学习概念、原理的深度理解。最后说不重要的一点，François Chollet是Keras作者。<br>声明本资料仅供个人学习交流、研究，禁止用于其他目的。如果喜欢，请购买英文原版。</p>
</blockquote>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/27/deep-learning-with-python-chapter-2-2.2/" itemprop="url">
                  《Deep Learning with Python》第二章 2.2 神经网络的数据表示
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-01-27T11:40:44+08:00" content="2018-01-27">
              2018-01-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h6 id="2-2-神经网络的数据表示"><a href="#2-2-神经网络的数据表示" class="headerlink" title="2.2 神经网络的数据表示"></a>2.2 神经网络的数据表示</h6><p>在上面的例子中，数据存储为多维Numpy数组，也称为张量（tensor）。当前流行的机器学习系统都以张量作为基本数据结构。所以Google的TensorFlow也拿张量命名。那张量是什么呢？</p>
<p>张量是数据的容器（container）。这里的数据一般是数值型数据，所以是数字的容器。大家所熟悉的矩阵是二维（2D）张量。张量是广义的矩阵，它的某一维也称为轴（axis）。</p>
<ul>
<li>标量（Scalar，0D 张量）</li>
</ul>
<p>只包含一个数字的张量称为标量（或者数量张量，零维张量，0D张量）。在Numpy中，一个float32或者float64位的数值称为数量张量。Numpy张量可用其<code>ndim</code>属性显示轴的序数，数量张量有0个轴（ndim == 0）。张量的轴的序数也称为阶（rank）。下面是Numpy标量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">        &gt;&gt;&gt; x = np.array(<span class="number">12</span>)</div><div class="line">        &gt;&gt;&gt; x</div><div class="line">        array(<span class="number">12</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x.ndim <span class="number">0</span></div></pre></td></tr></table></figure>
<ul>
<li>向量（1D张量）</li>
</ul>
<p>数字的数组也称为向量，或者一维张量（1D张量）。一维张量只有一个轴。下面来看一个Numpy向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([<span class="number">12</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">14</span>])</div><div class="line">        &gt;&gt;&gt; x</div><div class="line">        array([<span class="number">12</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">14</span>])</div><div class="line">        &gt;&gt;&gt; x.ndim</div><div class="line"><span class="number">1</span></div></pre></td></tr></table></figure>
<p>该向量有5项，也称为5维的向量。但是不要混淆5D向量和5D张量！一个5D向量只有一个轴，以及沿该轴有5个维数（元素）；然而一个5D张量有5个轴，并且沿每个轴可以有任意个的维数。维度既能表示沿某个轴的项的数量（比如，上面的5D向量），又能表示一个张量中轴的数量（比如，上面的5D张量），时常容易混淆。对于后者，用更准确地技术术语来讲，应该称为5阶张量（张量的阶即是轴的数量），但人们更常用的表示方式是5D张量。</p>
<ul>
<li>矩阵（2D张量）</li>
</ul>
<p>向量的数组称为矩阵，或者二维张量（2D张量）。矩阵有两个轴，也常称为行和列。你可以将数字排成的矩形网格看成矩阵，下面是一个Numpy矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([[<span class="number">5</span>, <span class="number">78</span>, <span class="number">2</span>, <span class="number">34</span>, <span class="number">0</span>],</div><div class="line">                  [<span class="number">6</span>, <span class="number">79</span>, <span class="number">3</span>, <span class="number">35</span>, <span class="number">1</span>],</div><div class="line">                  [<span class="number">7</span>, <span class="number">80</span>, <span class="number">4</span>, <span class="number">36</span>, <span class="number">2</span>]])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x.ndim</div><div class="line"><span class="number">2</span></div></pre></td></tr></table></figure>
<p>沿着第一个轴的项称为行，沿着第二个轴的项称为列。上面的例子中，[5, 78, 2, 34, 0]是矩阵 x 第一行，[5, 6, 7]是第一列。</p>
<ul>
<li>三维张量（3D张量）和更高维张量</li>
</ul>
<p>矩阵的数组称为三维张量（3D张量），你可以将其看成是数字排列成的立方体，下面是一个Numpy三维张量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([[[<span class="number">5</span>, <span class="number">78</span>, <span class="number">2</span>, <span class="number">34</span>, <span class="number">0</span>],</div><div class="line">                   [<span class="number">6</span>, <span class="number">79</span>, <span class="number">3</span>, <span class="number">35</span>, <span class="number">1</span>],</div><div class="line">                   [<span class="number">7</span>, <span class="number">80</span>, <span class="number">4</span>, <span class="number">36</span>, <span class="number">2</span>]],</div><div class="line">                   [[<span class="number">5</span>, <span class="number">78</span>, <span class="number">2</span>, <span class="number">34</span>, <span class="number">0</span>],</div><div class="line">                   [<span class="number">6</span>, <span class="number">79</span>, <span class="number">3</span>, <span class="number">35</span>, <span class="number">1</span>],</div><div class="line">                   [<span class="number">7</span>, <span class="number">80</span>, <span class="number">4</span>, <span class="number">36</span>, <span class="number">2</span>]],</div><div class="line">                   [[<span class="number">5</span>, <span class="number">78</span>, <span class="number">2</span>, <span class="number">34</span>, <span class="number">0</span>],</div><div class="line">                   [<span class="number">6</span>, <span class="number">79</span>, <span class="number">3</span>, <span class="number">35</span>, <span class="number">1</span>],</div><div class="line">                   [<span class="number">7</span>, <span class="number">80</span>, <span class="number">4</span>, <span class="number">36</span>, <span class="number">2</span>]]])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x.ndim</div><div class="line"><span class="number">3</span></div></pre></td></tr></table></figure>
<p>同理，将三维张量放进数组可以创建四维张量，其它更高维的张量亦是如此。深度学习中常用的张量是 0D 到 4D。如果处理视频数据，你会用到5D。</p>
<ul>
<li><p>关键属性</p>
<p>张量具有如下三个关键属性：</p>
<ul>
<li>轴的数量（阶数，rank）：一个三维张量有3个轴，矩阵有2个轴。Python Numpy中的张量维度为<code>ndim</code>。</li>
<li>形状（shape）：它是一个整数元组，描述张量沿每个轴有多少维。例如，前面的例子中，矩阵的形状为（3，5），三维张量的形状为（3，3，5）。向量的形状只有三个元素，比如（3，），标量有空形状，（）。</li>
<li>数据类型：张量中包含的数据类型有float32，unit8，float64等等，调用Python的dtype属性获取。字符型张量是极少见的。注意，Numpy中不存在字符串张量，其它大部分库也不存在。因为张量存在于预先申请的、连续的内存分段；而字符是变长的。</li>
</ul>
</li>
</ul>
<p>下面来几个具体的例子，回看MNIST数据集。首先加载MNIST数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line">(train_images, train_labels), (test_images, test_labels) = mnist.load_data()</div></pre></td></tr></table></figure>
<p>接着，用<code>ndim</code>属性显示张量train_images的轴数量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(train_images.ndim)</div><div class="line"><span class="number">3</span></div></pre></td></tr></table></figure>
<p>打印形状：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(train_images.shape)</div><div class="line">(<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>)</div></pre></td></tr></table></figure>
<p>使用<code>dtype</code>属性打印数据类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(train_images.dtype)</div><div class="line">uint8</div></pre></td></tr></table></figure>
<p>所以train_images是一个8-bit 整数的三维张量。更确切地说，它是一个包含60,000个矩阵的数组，其中每个矩阵是28 x 28 的整数。每个矩阵是一个灰度图，其值为0到255。</p>
<p>下面使用Python Matplotlib库显示三维张量中的第四幅数字图，见图2.2：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 2.6 Displaying the fourth digit</span></div><div class="line">digit = train_images[<span class="number">4</span>]</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">plt.imshow(digit, cmap=plt.cm.binary)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="http://img2.ph.126.net/HFQ9QC5QHRxolxEKfV0sXA==/6632699440956084761.png" alt="image"></p>
<p>图2.2 数字图样例</p>
<ul>
<li>Numpy中的张量操作</li>
</ul>
<p>上面的例子中，使用了train_images[i]沿第一个轴选择指定的数字图。选择张量的指定元素称为张量分片（tensor slicing），下面看Numpy数组中的张量切片操作：</p>
<p>选择#10到#100（不包括#100）的数字图，对应的张量形状为（90，28，28）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>my_slice = train_images[<span class="number">10</span>:<span class="number">100</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(my_slice.shape)</div><div class="line">(<span class="number">90</span>, <span class="number">28</span>, <span class="number">28</span>)</div></pre></td></tr></table></figure>
<p>其等效的表示方法有，沿每个轴为张量分片指定起始索引和终止索引。注意，“:”等效于选择整个轴的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>my_slice = train_images[<span class="number">10</span>:<span class="number">100</span>, :, :]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>my_slice.shape</div><div class="line">(<span class="number">90</span>, <span class="number">28</span>, <span class="number">28</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>my_slice = train_images[<span class="number">10</span>:<span class="number">100</span>, <span class="number">0</span>:<span class="number">28</span>, <span class="number">0</span>:<span class="number">28</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>my_slice.shape</div><div class="line">(<span class="number">90</span>, <span class="number">28</span>, <span class="number">28</span>)</div></pre></td></tr></table></figure>
<p>一般，你可以沿着张量每个轴任意选择两个索引之间的元素。例如，选择所有图片的右下角的14 x 14的像素：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">my_slice = train_images[:, <span class="number">14</span>:, <span class="number">14</span>:]</div></pre></td></tr></table></figure>
<p>你也可以用负索引。就像Python list中的负索引一样，它表示相对于当前轴末端的位置。剪切图片中间14 x 14像素，使用如下的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">my_slice = train_images[:, <span class="number">7</span>:<span class="number">-7</span>, <span class="number">7</span>:<span class="number">-7</span>]</div></pre></td></tr></table></figure>
<ul>
<li><p>批量数据（batch）的表示</p>
<p>在深度学习中，张量数据的第一个轴（axis 0，轴的序数从0开始）一般是样本轴（sample axis），有时也称为样本维度（sample dimension ）。在MNIST手写数字识别的例子中，样本是数字图片。</p>
<p>另外，深度学习模型不会一次处理整个数据集，而是将其拆分成小批量的数据集。下面是一个MNIST手写数字的batch，其中batch大小为128:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">batch = train_images[:<span class="number">128</span>]</div></pre></td></tr></table></figure>
<p>接着下一个batch：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">batch = train_images[<span class="number">128</span>:<span class="number">256</span>]</div></pre></td></tr></table></figure>
<p>第n个batch：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">batch = train_images[<span class="number">128</span> * n:<span class="number">128</span> * (n + <span class="number">1</span>)]</div></pre></td></tr></table></figure>
<p>对于张量batch来说，第一个轴（axis 0）称为batch轴或者batch维度。在使用Keras和其它深度学习库时会遇到这个术语。</p>
</li>
</ul>
<ul>
<li><p>真实世界中的张量数据</p>
<p>下面来一些具体的张量例子，后续也会用到。大部分张量都可以归为以下几类：</p>
<ul>
<li>向量数据：形状为（样本，特征）[^ (samples, features) ]的二维张量</li>
<li>时序数据（timeseries data）或者序列数据（sequence data）：形状为（样本，时间戳，特征）[^(samples, timesteps, features)]的三维张量</li>
<li>图片数据：形状为（样本，高度，宽度，管道）[^(samples, height, width, channels)]或者（样本，管道，高度，宽度）[^(samples, channels, height, width)]的四维张量</li>
<li>视频数据：形状为（样本，帧，高度，宽度，管道）[^(samples, frames, height, width, channels)]或者（样本，帧，管道，高度，宽度）[^(samples, frames, channels, height, width)]的五维张量</li>
</ul>
</li>
<li><p>向量数据</p>
<p>向量数据是最常见的例子。在数据集中，单个数据点可以编码成一个向量，然后一批向量数据可以编码成二维张量（即，向量的数组），其中第一个轴为样本轴（samples axis），第二个轴为特征轴（features axis）。</p>
<p>下面来看两个实例：</p>
<ul>
<li>人口数据：这里考虑人的年龄，邮政编码和收入。每个人的特征是一个包含3个值的向量，因此100,000个人的数据集存储为形状为（100000，3）的二维张量</li>
<li>文本数据：这里每个文档用词汇表（考虑20,000个常用词的字典）中每个词出现的次数来表示。那么每个文档编码成一个包含20,000个值（词汇表中每个词一个值）的向量。因此，500个文档的数据集存储为形状为（500，20000）的张量</li>
</ul>
</li>
<li><p>时序数据或者序列数据</p>
<p>当样本数据集中时间或者序列的排序较为重要，你应该将数据集存储为带显式的时间轴（time axis）的三维张量。每个样本编码成一个向量的序列（二维张量），因此，一批二维张量数据可以编码成三维张量，见图2.3：</p>
<p><img src="http://img0.ph.126.net/QsAxhiYNNp6Xehzatzy2ag==/6632623574653766754.png" alt="image"></p>
<p>图2.3 三维时序张量数据</p>
<p>习惯上，时间轴是第二个轴（轴序数为1）。下面看几个例子：</p>
<ul>
<li>股票价格数据：每分钟保存股票的当前价格，上一分钟的最高价格，上一分钟的最低价格。每分钟的股票价格编码成一个三维向量，一整天的股票交易编码成形状为（390，3）的二维张量（股票交易每天有390分钟）。250天的股票数据存储为（250，390，3）的三维张量。这里每个样本为一天的股票交易数据。</li>
<li>推特消息数据：这里用128个不重复的字符表将每条推文编码成280字符序列。每个字符编码成大小为128的二进制向量（该字符所在的索引位置的项为1，其它值都为0）。每条推文编码成形状为（280，128）的二维张量，那么1亿条推文存储为（1000000，280，128）的张量。</li>
</ul>
</li>
<li><p>图片数据</p>
<p>图片典型有三个维度：高度、宽度和颜色深度。灰度图片（比如MNIST手写数字图片）仅有一个颜色通道，因此可以存储为二维张量，但是习惯上图片张量都是三维的，因此灰度图片只用一维颜色管道表示。128张大小为256 x 256的灰度图片存储成形状为（128，256，256，1）的张量，128张彩色图片存储成形状为（128，256，256，1）的张量，见图2.4。</p>
<p><img src="http://img1.ph.126.net/tj2C-Dip2UIJH3gnHm0Uqg==/6632730227281661839.png" alt="image"></p>
<p>图片张量有两种写法：颜色管道在后（TensorFlow的写法），颜色管道在前（Theano的写法）。谷歌的TensorFlow机器学习框架将颜色深度轴放在末尾：（样本，高度，宽度，管道）[^(samples, height, width, channels)]。同时，Theano将颜色深度轴放在batch轴右边。按Theano的写法，前面的例子写成（128，1，256，256）和（128，3，256，256）。Keras深度学习框架对两种表示方法都支持。</p>
</li>
<li><p>视频数据</p>
<p>视频数据是现实世界中少有的几种需用五维张量表示的数据。视频可以理解成帧的序列，每帧是一副彩色图片。因为每帧是三维张量（高度，宽度，管道），所以帧的序列存储成四维张量（帧，高度，宽度，管道）。那不同的视频就要存储为五维张量了（样本，帧，高度，宽度，管道）[^(samples, frames, height, width, channels)]。</p>
<p>例如，一个60秒，144 x 256的油管视频按每秒采样4帧将会有240帧。那么4个不同的视频采样存储为形状为（4，240，144，256，3），总共有106,168,320个值。如果数据类型dtype为float32，那每个值保存为32位，所以该张量表示占405MB。而在真实生活中，你看到的视频都不用float32保存，一般都用大块数据存储格式（比如MPEG格式）压缩。</p>
</li>
</ul>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<blockquote>
<p>翻译本书系列的初衷是，觉得其中把深度学习讲解的通俗易懂。不光有实例，也包含作者多年实践对深度学习概念、原理的深度理解。最后说不重要的一点，François Chollet是Keras作者。<br>声明本资料仅供个人学习交流、研究，禁止用于其他目的。如果喜欢，请购买英文原版。</p>
</blockquote>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/06/deep-learning-with-python-chapter-2-2.1/" itemprop="url">
                  《Deep Learning with Python》第二章 2.1 神经网络的MNIST手写数字识别
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-01-06T17:57:12+08:00" content="2018-01-06">
              2018-01-06
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>第二章 神经网络的数学基础</p>
<p>本章涉及的知识点：</p>
<ul>
<li>神经网络的MNIST手写数字识别（概览）</li>
<li>张量（Tensor）和张量操作</li>
<li>如何通过后向传播和梯度下降进行神经网络学习</li>
</ul>
<p>理解深度学习要求熟悉许多简单的数学概念：张量，张量操作，微分，梯度下降等等。本章目的是让读者对这些概念有个大体的认识。</p>
<p>这里以一个实际的神经网络例子为开头，增加一些张量和梯度下降背景的了解。然后一点点的介绍新概念。记住，这些概念对理解后续章节的例子有帮助。</p>
<p>读完本章后，你将对神经网络的工作原理有个直观的认识。神经网络的应用实践将在第三章详细讲解。</p>
<h6 id="2-1-神经网络的MNIST手写数字识别"><a href="#2-1-神经网络的MNIST手写数字识别" class="headerlink" title="2.1 神经网络的MNIST手写数字识别"></a>2.1 神经网络的MNIST手写数字识别</h6><p>第一个具体的神经网络例子是，使用Keras（Python库）学习手写数字分类。如果对Keras或者类似的库没有什么经验，那么你可能无法立即搞懂该例子的所有步骤。可能你压根还没安装Keras，那也没关系咯。下一章会详细讲解该例子的每一步。所以，不用担心啦，准备开始了。</p>
<p>解决的问题：识别灰度的手写数字图片（28 x 28）的数字（0到9）。本例使用机器学习经典的MNIST手写数字数据集，包含60000张训练图片饿10000张测试图片。它是NIST（National Institute of Standards and Technology）数据库的子集，建立于1980年代。你可以把“MNIST手写数字识别”看成是深度学习的“Hello World”，其可以验证算法的正确性。如果成为机器学习工作者，你将会在科学论文、博客等上不断地看到它。图2.1 是MNIST数据集的图片。</p>
<p><img src="http://img1.ph.126.net/TePJYaz140JSSQ2-WFaJxg==/6632713734607017367.png" alt="image"></p>
<p>图2.1 MNIST手写数字图片</p>
<blockquote>
<p><strong>类（class）和标签（label）的区别</strong>：</p>
<p>在机器学习中，分类问题中的一个类别称之为类（class）；数据点称为样本；类关联的具体样本称为标签（label）。</p>
</blockquote>
<p>你不需要立即重现本例，下一章3.3小结将会使用Keras。</p>
<p> Keras会预加载MNIST数据集，得到的是四个Numpy数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 2.1. Loading the MNIST dataset in Keras</span></div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line">(train_images, train_labels), (test_images, test_labels) = mnist.load_data()</div></pre></td></tr></table></figure>
<p><code>train_images</code> 和<code>train_labels</code>形成训练数据集。<code>test_images</code>和<code>test_labels</code>形成测试数据集。图片由NUmpy数组组成，标签是一个数字数组，范围是0到9。图片和标签是一一对应的。</p>
<p>下面看下训练数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>train_images.shape</div><div class="line">(<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>len(train_labels)</div><div class="line"><span class="number">60000</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>train_labels</div><div class="line">array([<span class="number">5</span>, <span class="number">0</span>, <span class="number">4</span>, ..., <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>], dtype=uint8)</div></pre></td></tr></table></figure>
<p>接着是测试数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>test_images.shape</div><div class="line">(<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>len(test_labels)</div><div class="line"><span class="number">10000</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>test_labels</div><div class="line">array([<span class="number">7</span>, <span class="number">2</span>, <span class="number">1</span>, ..., <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], dtype=uint8)</div></pre></td></tr></table></figure>
<p>接下来的流程是：首先，将训练数据（<code>train_images</code> 和<code>train_labels</code>）赋值给神经网络模型；然后神经网络学习图片及相应的标签；最后训练好的模型输入测试图片<code>test_images</code>进行预测，并用<code>test_labels</code>验证预测值。</p>
<p>下面构建神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 2.2. The network architecture</span></div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</div><div class="line"></div><div class="line">network = models.Sequential()</div><div class="line">network.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span> * <span class="number">28</span>,)))</div><div class="line">network.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</div></pre></td></tr></table></figure>
<p>神经网络的核心基础组件是层（layer），它是数据处理模块，可以认为是数据的过滤器（filter）。训练数据进入layer输出有用的形式，具体地说，layer抽取训练数据的学习特征。希望的是学习表征可以有效地解决问题。大部分深度学习包含多个layer形成链式，不断地进行数据提取。深度学习模型由一系列连续的数据过滤器（layer）提炼数据。</p>
<p>本例中的神经网络由两个稠密层（Dense layer）序列组成，其中稠密层也称为全联接层（*fully connected layer）。第二层是个softmax layer，它将输出一个包含10个概率的数组（概率之和为1）。每个概率值表示当前的数字图片属于10个数字分类中某一个的概率。</p>
<p>准备训练的步骤，下面是模型编译步骤（<em>compilation step</em>）中的三步：</p>
<ul>
<li>损失函数：度量神经网络模型在训练数据集上的性能，使得其向正确的方向迭代。</li>
<li>优化器：基于训练数据和损失函数调整模型的机制。</li>
<li>模型训练和测试的监控指标：本例只关注准确度（正确分类的图片比例）。</li>
</ul>
<p>后续两章会清晰的讲解损失函数和优化器的功能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 2.3. The compilation step</span></div><div class="line">network.compile(optimizer=<span class="string">'rmsprop'</span>,</div><div class="line">                loss=<span class="string">'categorical_crossentropy'</span>,</div><div class="line">                metrics=[<span class="string">'accuracy'</span>])</div></pre></td></tr></table></figure>
<p>在模型训练之前进行数据预处理，将数据集按神经网络模型的要求重塑（即，改变大小形状），并归一化到[0, 1]区间。例如，前面训练图片存储为(60000, 28, 28)维德数组，数值类型为uint8，其大小为[0, 255]。这里将其转换成值为0到1的float32类型的(60000, 28 * 28) 维数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 2.4. Preparing the image data</span></div><div class="line">train_images = train_images.reshape((<span class="number">60000</span>, <span class="number">28</span> * <span class="number">28</span>))</div><div class="line">train_images = train_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></div><div class="line"></div><div class="line">test_images = test_images.reshape((<span class="number">10000</span>, <span class="number">28</span> * <span class="number">28</span>))</div><div class="line">test_images = test_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></div></pre></td></tr></table></figure>
<p>下面对标签进行编码，具体解释将在第三章给出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Listing 2.5. Preparing the labels</span></div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</div><div class="line"></div><div class="line">train_labels = to_categorical(train_labels)</div><div class="line">test_labels = to_categorical(test_labels)</div></pre></td></tr></table></figure>
<p>Keras调用<code>fit</code>方法开始训练神经网络模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>network.fit(train_images, train_labels, epochs=<span class="number">5</span>, batch_size=<span class="number">128</span>)</div><div class="line">Epoch <span class="number">1</span>/<span class="number">5</span></div><div class="line"><span class="number">60000</span>/<span class="number">60000</span> [==============================] - <span class="number">9</span>s - loss: <span class="number">0.2524</span> - acc: <span class="number">0.9273</span></div><div class="line">Epoch <span class="number">2</span>/<span class="number">5</span></div><div class="line"><span class="number">51328</span>/<span class="number">60000</span> [========================&gt;.....] - ETA: <span class="number">1</span>s - loss: <span class="number">0.1035</span> - acc: <span class="number">0.9692</span></div></pre></td></tr></table></figure>
<p>上面显示的两个数字是训练神经网络模型时的损失值和准确度。</p>
<p>可以看到，很快在训练数据上达到0.989 (98.9%) 的准确度。下面在测试数据集上验证模型的性能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>test_loss, test_acc = network.evaluate(test_images, test_labels)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">'test_acc:'</span>, test_acc)</div><div class="line">test_acc: <span class="number">0.9785</span></div></pre></td></tr></table></figure>
<p>测试数据集上的准确度为97.8%，比训练数据集上的小一点。训练数据集上的准确度和测试数据集上的差距意味着过拟合，机器学习模型在新数据集上的效果比训练数据集的差。过拟合将在第三章详细讲解。</p>
<p>从上面可以看到：只用不到20行Python代码实现构建和训练一个神经网络模型来进行手写数字图片识别。下一小结，你将学习张量（，神经网络的数据存储对象），张量操作，梯度下降。</p>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<blockquote>
<p>翻译本书系列的初衷是，觉得其中把深度学习讲解的通俗易懂。不光有实例，也包含作者多年实践对深度学习概念、原理的深度理解。最后说不重要的一点，François Chollet是Keras作者。<br>声明本资料仅供个人学习交流、研究，禁止用于其他目的。如果喜欢，请购买英文原版。</p>
</blockquote>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/deep-learning-with-python-chapter-1-1.1/" itemprop="url">
                  《Deep Learning with Python》第一章 1.1 人工智能、机器学习和深度学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T16:21:11+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>第一章 什么是深度学习？</p>
<p>本章涉及的知识点：</p>
<ul>
<li>基本概念的高层次（High-level）定义</li>
<li>机器学习的发展历程</li>
<li>深度学习兴起背后的关键因素以及未来的展望</li>
</ul>
<p>过去几十年，人工智能（artificial intelligence，AI）一直是媒体强烈炒作的主题。机器学习、深度学习和人工智能也经常出现在无数非技术刊物上。人们构想将来智能聊天机器人、自动驾驶汽车和虚拟助理的工作生活的画面——在昏暗的灯光下，人类的工作很少，而大部分经济活动都有机器人或者AI智能实体。对于当前或者未来机器学习的从业者来讲，需要从吹捧过度的新闻中意识到改变世界的新产品。你们的将来将承担重要的任务：读完本书后，你将会成为开发AI智能实体的开发者。接着解决这几个问题：目前深度学习能实现什么？深度学习的意义如何？人类下一步该如何做？你相信关于人工智能的宣传吗？</p>
<p>本章介绍人工智能、机器学习和深度学习相关知识。</p>
<h5 id="1-1-人工智能、机器学习和深度学习"><a href="#1-1-人工智能、机器学习和深度学习" class="headerlink" title="1.1 人工智能、机器学习和深度学习"></a>1.1 人工智能、机器学习和深度学习</h5><p>首先，当人们讨论AI时要清楚谈论的是什么？什么是人工智能、机器学习和深度学习（见图1.1）？它们之间又有什么关系呢？</p>
<p><img src="http://img2.ph.126.net/_vMUT5Tf4E2AW8xp0PwRSQ==/3083558369884862744.jpg" alt="image"></p>
<p>图1.1 人工智能、机器学习和深度学习</p>
<h6 id="1-1-1-人工智能"><a href="#1-1-1-人工智能" class="headerlink" title="1.1.1 人工智能"></a>1.1.1 人工智能</h6><p>人工智能诞生于1950年代，当时少数计算机科学的先行者开始探讨计算机是否能够像人类一样“思考”——这个问题到现在还在探索。其简明的定义如下：像人类一样自动化完成智力任务。比如，AI通常认为包括机器学习和深度学习的领域，但是也包含许多非学习的方法。例如，早期的棋类程序只涉及程序设定的硬编码规则，没用到机器学习。在相当长一段时期内，许多专家相信：程序处理足够大的基于知识的显式规则集合能达到人类水平的智能。这种方法称之为符号型AI（symbolic AI），它是1950年代到1980年代主流的AI，并在1980年代专家系统方面快速达到巅峰。</p>
<p>虽然符号型AI能解决定义明确的、逻辑性的问题，比如棋类问题，但是却不能解决更复杂、模糊类的问题，比如，图像分类、语音识别和语言翻译。随之而来的是机器学习这种新方法取代了符号型AI。</p>
<h6 id="1-1-2-机器学习"><a href="#1-1-2-机器学习" class="headerlink" title="1.1.2 机器学习"></a>1.1.2 机器学习</h6><p>在英国维多利亚时代，埃达·洛夫莱斯伯爵夫人（Ada Lovelace）是查尔斯·巴贝奇（Charles Babbage）的好友和合作者。巴贝奇是分析机（<em>Analytical Engine</em>）的发明者。该分析机是公认的第一个机械式通用电脑。虽然预言性的远见超越了当时的时代，但是，在1830年代到1840年代设计的分析机并不是真正意义上的通用电脑。因为通用计算机的概念那时尚未出现，它仅仅是一种自动的数学计算分析，因此命名为分析机。在1843年，埃达注记分析机，“分析机谈不上能创造什么东西。但是能做我们命令它做的任何工作……它的职责是帮助我们去实现已知的事情。”</p>
<p>在1950年，AI先行者阿兰·图灵（Alan Turing）在他的著作《计算机器和智能》中引用这个注记作为“洛夫莱斯伯爵夫人的异议”，并提出图灵测试（<em>Turing test</em>）的概念。图灵思考通用计算机是否有学习和创造的能力，并得出下面的结论：</p>
<p>机器学习起因于以下问题：对于计算机来说，除“我们命令它做的任务”之外，它能自我学习完成特定任务吗？计算机能做的工作会让我们感到意外吗？除了程序员人为制定规则的数据处理外，计算机从数据中能自我学习出规则吗？</p>
<p>上述问题打开了新编程范式的大门。在经典编程中，即符号型AI范式，人们输入规则（即为程序）和数据，根据这些规则处理数据，输出答案（见图1.2）；在机器学习中，人们输入数据和该数据对应的答案，输出的是程序规则。这些学习来的规则能应用到新的数据上，并产生原创性的答案。</p>
<p><img src="http://img2.ph.126.net/zS-WEc-ALKQMRPfBMCdxDw==/1277896394286009152.jpg" alt="image"></p>
<p>图1.2 机器学习：新的编程范式</p>
<p>机器学习系统是训练得到的，而不是用显式的编制。给机器学习一个任务相关的许多例子，它能发现这些例子的统计性的结构，并形成规则自动完成任务。例如，如果想给假期照片自动化打标签，你需要提出一个机器学习系统，输入许多打好标签的照片，该系统学习统计性规则并为指定的照片打标签。</p>
<p>虽然机器学习在1990年代才开始繁荣，但是由于硬件性能和数据大小的提升，机器学习很快变得非常流行，并成为AI最成功的子领域。机器学习与数学统计紧密相关，但是它在许多方面又有别于统计学。不像统计学，机器学习试图处理海量、复杂的数据集（比如，数百万张图片，包含数以万计的像素），然而经典统计分析（比如贝叶斯分析）将对此无能为力。因此，机器学习，特别是深度学习，展现相对较少的数学理论，更多的是工程化导向。</p>
<h6 id="1-1-3-数据的特征学习"><a href="#1-1-3-数据的特征学习" class="headerlink" title="1.1.3 数据的特征学习"></a>1.1.3 数据的特征学习</h6><p>为了定义深度学习，以及理解深度学习和其它机器学习方法的不同，首先，需要知道机器学习算法在做什么。这里仅仅讲述机器学习在给定期望的数据例子下发现规则，执行数据处理的任务。所以为了实现机器学习，需要知道下面三件事：</p>
<ul>
<li>输入数据点（<em>Input data points</em>）：例如，如果是语音识别的任务，这些数据点应该是语音文件。如果是图标标注的任务，数据点应该是图片；</li>
<li>期望的输出样例（<em>Examples of the expected output</em>）：语音识别的任务中，期望的输出样例是语音的手写文本；图像标注的任务中，期望的输出样例是“狗”，“猫”等等的标签；</li>
<li>算法的评估标准：算法的评估标准是为了判断当前算法的输出值与期望的输出值之间的距离。评估标准可以反馈调节算法的工作，这个调节的步骤经常成为学习（<em>learning</em>）。</li>
</ul>
<p>机器学习模型将输入数据集转化成有意义的输出，这个过程是从已有的输入和输出对的例子中学习到的。因此，机器学习和深度学习的中心问题是可读性的转化数据（<em>transform data</em>）：换句话说，学习输入数据的有用的表征（<em>representations</em>）。数据表征使得数据更接近期望的输出。</p>
<p>那什么是数据的表征？其核心是数据的表现形式——表示（<em>represent</em>）或者编码（<em>encode</em>）数据。例如，彩色图片可以编码为RGB格式（红－绿－蓝）或者HSV格式（色相，饱和度，色调）。机器学习模型就是为了找到输入数据的合适表征——数据的转换是为了任务的更容易处理，比如，分类任务。</p>
<p>下面举一个例子。假设有x轴，y轴和一些数据点坐标（x，y），见图1.3：</p>
<p><img src="http://img0.ph.126.net/04Sz9oujEoWniyq8hB1c5Q==/6632724729723197958.jpg" alt="image"></p>
<p>图1.3 样本数据点</p>
<p>正如你所见，有一些白色的数据点，一些黑色的数据点。本例假设想实现一个算法：输入数据点的坐标（x，y），输出该数据点是黑色还是白色的。在本例中，</p>
<ul>
<li>输入是数据点的坐标；</li>
<li>期望输出是数据点的颜色；</li>
<li>算法评估标准：判断正确的数据点的百分比</li>
</ul>
<p>此处的首要任务是数据集的新表征，该数据表征需要能清晰分离白色的点和黑色的点。本例使用的数据转换是坐标变换，见图1.4：</p>
<p><img src="http://img2.ph.126.net/ozi-X0Uo6GzqaInar-PlBQ==/6632474041074666089.jpg" alt="image"></p>
<p>图1.4 坐标变换</p>
<p>在新的坐标系统中，数据点的坐标可以看成是数据集的一个新表征。并且效果非常棒！使用了数据集的新表征，黑/白分类问题就可以用很简单的规则解决了：“黑色数据点的x &gt; 0，或者”白色数据点的x &lt; 0“。”这个新表征方法基本解决了分类问题。</p>
<p>在本例中，人工定义了坐标变换。但是，如果尝试系统性地搜索所有不同的可能的坐标变换，并将正确分类数据点的百分比作为反馈，那就是在做机器学习。机器学习中的“学习”，是描述自动搜索更优的数据表征的过程。</p>
<p>所有机器学习算法都包含自动化寻找这么一个转换：该转换能根据给定的任务将数据集转化成有用的特征表示。这个操作可能是坐标变换，如前所见，或者线性投影（线性投影可能损失有用的信息），翻译，非线性操作（比如，当x &gt; 0时，选中所有数据点），等等。机器学习算法通常不能创造性地搜索到这些转换；它们仅仅通过预定义的操作集合进行搜索，此过程也称为超参数空间（<em>hypothesis space</em>）。</p>
<p>那究什么是竟机器学习呢？从技术上来讲，在预定义的参数空间内，自动搜索输入数据集有效的表征，并以反馈信号做引导。这个简单的理念可以解决广大的人工职能任务，从语音识别到自动驾驶。</p>
<p>现在理解完机器学习的学习，下面开始探索是什么让深度学习比较特别。</p>
<h6 id="1-1-4-何为深度学习的“深度”"><a href="#1-1-4-何为深度学习的“深度”" class="headerlink" title="1.1.4 何为深度学习的“深度”"></a>1.1.4 何为深度学习的“深度”</h6><p>深度学习是机器学习的一个特定子领域，其数据集的学习表征强调学习一系列连续的表征层，这些逐层的表征层不断地增加了有效的数据表征。深度学习的“深度”并不涉及更深度的学习方法；而是表示一系列连续的特征层的理念。数据模型的层数称为模型的深度（<em>depth</em>）。深度学习的其它叫法有，分层表征学习和多级表征学习。当前的深度学习经常涉及十层甚至上百层的连续特征表示层，它们都是从训练数据集自动学习的。其它机器学习的方法一般倾向于从训练数据学习一层或者两层的表征，因此，这种机器学习也称为浅层学习（<em>shallow learning</em>）。</p>
<p>在深度学习中，这些表征层通常是通过多层神经网络（<em>neural network</em>）模型学习得到的。神经网络来源于生物科学，深度学习的核心概念启发自对人类大脑的理解，但是深度学习模型并不是大脑的模型。没有证据表明大脑实现的学习机制被用在了当前的深度学习模型。你可能偶然发现某些顶级科学文章宣称深度学习像大脑一样工作或者模拟大脑，但是实际情况不是这样的。这可能对该领域的新人在理解深度学习上带来疑惑和困扰。你不需要搞得像大脑一样神秘，只管忘掉看到的关于深度学习和生物相关的假设。深度学习是一个从训练数据学习表征的数学框架。</p>
<p>深度学习算法到底如何进行表征学习呢？下面看一个几层深度网络的例子，其转换数字图片来识别图片中的数字，见图1.5：</p>
<p><img src="http://img1.ph.126.net/zcurzP-FbaeciNhnqPCh-A==/6632257437283995751.jpg" alt="image"></p>
<p>图1.5 图片识别数字的分类神经网络</p>
<p>如图1.6所示，神经网络将数字图片转换为学习特征，对原始图片进行图像增强，从而识别出最终的结果。你可以认为神经网络经过多层连续的过滤器进行信息提取，最后得到结果。</p>
<p><img src="http://img0.ph.126.net/GBppKkcw7ElSMkcN1nBC8A==/2590132735711099905.jpg" alt="image"></p>
<p>图1.6 数字分类模型的深度学习表征</p>
<p>所以，什么是深度学习呢？从技术性上讲，深度学习是多级数据集表征学习。就这么简单的机制，经过足够多层的扩展，能够魔术般的解决问题。</p>
<h6 id="1-1-5-三张图理解深度学习工作原理"><a href="#1-1-5-三张图理解深度学习工作原理" class="headerlink" title="1.1.5 三张图理解深度学习工作原理"></a>1.1.5 三张图理解深度学习工作原理</h6><p>此时，你已经知道机器学习是通过观察样本数据集的输入和目标，进而学习将输入（比如，图片）和目标（比如，“cat”标签）映射。你也知道深度神经网络是从样本数据集中学习数据转换（也即学习表征），通过多层数据转换层实现输入和目标的映射。下面看下这个学习过程具体是如何工作的？</p>
<p>layer处理输入数据的规范要求存储在layer的权重（<em>weights</em>）中，这些权重其实是一堆数值。从技术术语上讲，layer通过权重参数化实现了数据转换（权重有时也称layer的参数），见图1.7。本文中，学习（learning）意味着寻找神经网络中所有layer的权重值的集合，比如正确地将样本数据集的输入和相关的目标映射。这里需要注意的是，一个神经网络可能包含成千上万个参数。修改某个参数可能会影响其它所有的参数，那找到所有参数的正确值看似是个相当艰巨的任务。</p>
<p><img src="http://img1.ph.126.net/qscFw2XAikKq0BnRFpyIpQ==/6632556504446747512.jpg" alt="image"></p>
<p>图1.7  权重参数化的神经网络</p>
<p>为了控制神经网络的输出，需要度量模型输出和期望值之间的距离。这部分是神经网络模型的损失函数（<em>loss function</em>）的工作，有时也称观察函数（<em>objective function</em>）。损失函数输入神经网络模型的预测值和实际目标（期望输出），计算两者之间的距离值，评估神经网络在训练模型上的效果，见图1.8。</p>
<p><img src="http://img0.ph.126.net/WKE1LCZ2BbXaYf3mNGaejA==/6632287124097945627.jpg" alt="image"></p>
<p>图1.8 度量神经网络模型输出的损失函数</p>
<p>深度学习的主要诀窍是，使用损失函数值作为反馈信号微调权重值，降低训练数据在某个方向上的损失值，见图1.9。前面的调节过程是神经网络的优化器（<em>optimizer</em>）的工作。优化器是由后向传播算法（<em>Backpropagation</em>）实现的，其是深度学习的核心算法，下一章惠详细讲解向传播算法是如何工作的。</p>
<p><img src="http://img2.ph.126.net/Vt1sOr95zZ_p5MSEzRD7yQ==/6632646664397631389.jpg" alt="image"></p>
<p>图1.9 损失函数值调节权重值</p>
<p>一般神经网络权重值先随机初始化，这时神经网络完成的看起来仅仅是些随机数据转换，它输出的结果自然地远离理想值，损失函数值也相应很高。但是随着神经网络数据处理的推进，权重值也在正确的方向上逐步微调，损失值也在降低。前面描述的过程称为迭代训练（<em>training loop</em>）。重复迭代足够的训练次数后得到的权重值会最小化损失函数值。具有最小化损失值的神经网络模型输出与期望的目标值几乎相同。</p>
<h6 id="1-16-深度学习的应用场景"><a href="#1-16-深度学习的应用场景" class="headerlink" title="1.16 深度学习的应用场景"></a>1.16 深度学习的应用场景</h6><p>虽然深度学习是机器学习中早期的子领域，但是其也就在2010年代才稍微兴盛起来。过去几十年，深度学习没什么进展，只在感知学习问题上有点成绩。</p>
<p>深度学习当前已经在机器学习难以出成绩的领域有了以下突破：</p>
<ul>
<li>图像分类</li>
<li>语音识别</li>
<li>手写字识别</li>
<li>机器翻译</li>
<li>文本语音转换</li>
<li>智能数字设备，比如 Google Now和Amazon Alexa</li>
<li>自动驾驶</li>
<li>广告投放，比如Google，百度和微软的Bing</li>
<li>网站搜索</li>
<li>自然语言的问答</li>
<li>AlphaGo</li>
</ul>
<p>人们仍在探索深度学习更广泛的领域，如果成功的话，深度学习可能在科学、软件开发等方面帮助人类开辟新世纪。</p>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<blockquote>
<p>翻译本书系列的初衷是，觉得其中把深度学习讲解的通俗易懂。不光有实例，也包含作者多年实践对深度学习概念、原理的深度理解。最后说不重要的一点，François Chollet是Keras作者。<br>声明本资料仅供个人学习交流、研究，禁止用于其他目的。如果喜欢，请购买英文原版。</p>
</blockquote>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/face-emotion-recognition/" itemprop="url">
                  面部表情（表情包）识别
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T16:07:41+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h5><p>人类面部表情丰富，但可以总结归纳为7类基本表情： happy, sad, surprise, fear, anger, disgust, and neutral。面部表情是通过面部肌肉活动表达出来，有些比较微妙且复杂，包含了大量内心活动信息。通过面部表情识别，我们能简单而低成本地度量出观众/用户对内容和服务的态度。例如，零售商使用这些度量评估客户的满意度。健康医疗提供商能在治疗的过程根据病人的表情状态来提高服务。娱乐厂商能够监控观众的喜欢来持续的生产优质的内容。</p>
<p>训练过的人类很容易读懂其他人的情绪。事实上，只有14个月大的婴儿就可以区别出happy和sad的区别。但是计算机能够比人类在识别情绪上做的更好吗？为了找到答案，我们设计一个深度神经网络使得机器可以读懂人类情绪。换句话说，给机器以“眼”识别面部表情。</p>
<h5 id="语料数据"><a href="#语料数据" class="headerlink" title="语料数据"></a>语料数据</h5><p>训练模型的数据集使用的是Kaggle面部识别挑战赛的数据集（2013年）。它由35887张面部图片组成，48x48像素灰度图片，标注为7类基本表情： happy, sad, surprise, fear, anger, disgust, and neutral。<br><img src="http://img1.ph.126.net/rMw0LOC29HbsfzcAXU7zLw==/6632541111283960069.png" alt="image"><br>Figure 1. An overview of FER2013</p>
<p>当作者分析语料数据集时，发现“disgust”分类相对于其它分类不均衡（只有113张样本）。作者将两类相似的情感（disgust和anger）合并起来。为了防止数据倾斜，作者构建一个数据生成器 <a href="https://github.com/JostineHo/mememoji/blob/master/src/fer2013datagen.py" target="_blank" rel="external">fer2013datagen.py</a>，该生成器很容易分割训练集和保留数据集。本例使用28709张面部图片作为训练集，余下的图片作为测试集和验证集（每个数据集3589张）。这样我们获得了6类均衡的数据集，见图2，包含happy, sad, surprise, fear, anger, and neutral。</p>
<p><img src="http://img1.ph.126.net/-94jcsPjstG_I4Lh5Q6KUw==/1286622118564049914.png" alt="image"><br>Figure 2. Training and validation data distribution.</p>
<h5 id="算法模型"><a href="#算法模型" class="headerlink" title="算法模型"></a>算法模型</h5><p><img src="http://img1.ph.126.net/jQoTGwwtyMz4CVnTExalYg==/6632600484911863570.png" alt="image"><br>Figure 3. Mr. Bean, the model for the model.</p>
<p>深度学习在计算机视觉上是非常流行的技术。本文选择卷积神经网络（CNN）层作为构建基础创建模型架构。CNN是有名的模仿人脑工作的模型。本文使用憨豆先生的图片作为示例来解释如何将图像赋值给卷积神经网络模型。</p>
<p>典型的卷积神经网络包涵输入层，卷积层，稠密层（比如，全联接层）和输出层（见图4）。这些层按序组合，在 <a href="https://keras.io/models/sequential/" target="_blank" rel="external">Keras</a>中，使用Sequential()函数创建模型，再把其它层加入进来。<br><img src="http://img0.ph.126.net/yxSj5yiIKuZ-0KCmNk-l4w==/6632346497725842891.png" alt="image"><br>Figure 4. Facial Emotion Recognition CNN Architecture (modification from Eindhoven University of Technology-PARsE).</p>
<h6 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h6><ul>
<li>输入层需要预处理，输入固定维度的数据。所以图片需先预处理再传入输入层。作者使用 <a href="http://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0" target="_blank" rel="external">OpenCV</a>（计算机视觉库）做图像面部识别。OpenCV的haar-cascade_frontalface_default.xml文件包含预训练的过滤器，使用Adaboost算法能快速找到面部并裁剪。</li>
<li>使用cv2.cvtColor函数将裁剪面部图片转化为灰度图，并使用cv2.resize改变图片大小为48x48像素。处理完的面部图片，相比于原始的（3，48，48）三色RGB格式“瘦身”不少。同时也确保传入输入层的图片是（1，48，48）的numpy数组。</li>
</ul>
<h6 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h6><ul>
<li>numpy数组传入Convolution2D层，指定过滤层的数量作为超参数。过滤层（比如，核函数）是随机生成权重。每个过滤层，（3，3）的感受野，采用权值共享与原图像卷积生成feature map。</li>
<li><p>卷积层生成的feature map代表像素值的强度。例如，图5，通过过滤层1和原始图像卷积生成一个feature map，其它过滤层紧接着进行卷积操作生成一系列feature map。<br><img src="http://img2.ph.126.net/5dussQ8UCCWvk6A8_nOvoQ==/6632702739490648439.png" alt="image"><br>Figure 5. Convolution and 1st max-pooling used in the network</p>
</li>
<li><p>池化（Pooling）是一种降低维度的技术，常用于一个或者多个卷积层之后。池化操作是构建CNN的重要步骤，因为增加的多个卷积层会极大的影响计算时间。本文使用流行的池化方法MaxPooling2D，其使用（2，2）窗口作用于feature map求的最大像素值。池化后图像降低4个维度。</p>
</li>
</ul>
<h6 id="稠密层"><a href="#稠密层" class="headerlink" title="稠密层"></a>稠密层</h6><ul>
<li><p>稠密层（比如，全联接层）是模仿人脑传输神经元的方式。它输入大量输入特征和变换特征，通过联接层与训练权重相连。<br><img src="http://img2.ph.126.net/G3e8Ye0wiS4g595FhAVVrQ==/2601954684732937664.png" alt="image"><br>Figure 6. Neural network during training: Forward propagation (left) to Backward propagation (right).</p>
</li>
<li><p>模型训练时权重前向传播，而误差是反向传播。反向传播起始与预测值和实际值的差值，计算所需的权重调整大小反向传回到每层。采用超参数调优手段（比如，学习率和网络密度）控制训练速度和架构的复杂度。随着灌入更多的训练数据，神经网络能够使得误差最小化。</p>
</li>
<li>一般，神经网络层/节点数越多，越能捕捉到足够的信号。但是，也会造成算法模型训练过拟合。应用dropout可以防止训练模型过拟合。Dropout随机选择部分节点（通常，占总节点数的百分比不超过50%），并将其权重置为0。该方法能有效的控制模型对噪声对敏感度，同时也保留架构的复杂度。</li>
</ul>
<h6 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h6><ul>
<li>本文的输出层使用softmax激励函数代替sigmoid函数，将输出每类表情的概率。</li>
<li>因此，本文的算法模型能显示出人脸表情组成的详细组成概率。随后会发现没必要将人类表情表示为单个表情。本文采用的是混合表情来精确表示特定情感</li>
</ul>
<blockquote>
<p>注意，没有特定的公式能建立一个神经网络保证对各种场景都有效。不同的问题需要不同的模型架构，产生期待的验证准确度。这也是为什么说神经网络是个“黒盒算法”。但是也不要太气馁，模型训练的时间会让你找到最佳模型，获得最大价值。</p>
</blockquote>
<h6 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h6><p>刚开始创建了一个简单的CNN深度学习模型，包括一个输入层，三个卷积层和一个输出层。事实证明，简单的算法模型效果比较差。准确度0.1500意味着仅仅是随机猜测的结果（1/6）。简单的网络结构导致不能有效的判别面部表情，那只能说明要“深挖”。。。<br><a href="http://img2.ph.126.net/uiC8pbN-PK9vk3i3i_E_dg==/6632460846935132816.png" target="_blank" rel="external">image</a><br>下面稍微修改下三部分的组合，增加模型的复杂度：</p>
<ul>
<li>卷积层的数量和配置</li>
<li>稠密层的数量和配置</li>
<li>稠密层的dropout占比</li>
</ul>
<p>使用AWS的GPU计算（g2.2xlarge）训练和评估组合的算法模型。这次极大的减少了训练时间和模型调优的效率。最后的网络模型是九层，每三层卷积层接着一个max-pooling层，见图7。<br><img src="http://img1.ph.126.net/byZdgskm07usZbByAzg6rQ==/6632680749258091039.png" alt="image"><br>Figure 7. Final model CNN architecture.</p>
<h5 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h5><p><img src="http://img0.ph.126.net/MyTvn8QWikiz0lzd4WKVyw==/6632437757190955644.png" alt="image"></p>
<h6 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h6><p>最后的CNN模型交叉验证准确度是58%，其具有积极意义。因为人类面部表情经常由多个基本表情组合，仅仅用单一表情是很难描述。本例中，当训练模型预测不准确时，正确的标签一般是第二相似的表情，见图8（浅蓝色标签）。<br><img src="http://img0.ph.126.net/D-QOV5WTGJ_hnBtTAi6mVQ==/6632316810911891151.png" alt="image"><br>Figure 8. Prediction of 24 example faces randomly selected from test set.</p>
<h6 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h6><p><img src="http://img1.ph.126.net/_I-J4aQiQ910-JCPhYx8-Q==/3082713944954739157.png" alt="image"><br>Figure 9. Confusion matrix for true and prediction emotion counts.</p>
<p>仔细看下每个表情的预测结果。图9是测试集的模型预测的混淆矩阵。矩阵给出表情预测的数量和多分类模型的效果展示：</p>
<ul>
<li>该模型很好的鉴别出正表情（happy和surprised），预测准确度高。大约7000张训练集中，happy表情的准确度达到76.7%。surprised表情预测准确度为69.3%。</li>
<li>平均意义上讲，本例的神经网络模型对负表情的预测效果较差。sad表情只有39.7%的准确度，并且该网络模型频繁的误判别angry、fear和neutral表情。另外，当预测sad表情和neutral表情时经常搞混，可能是因为这两个表情很少出现。</li>
<li>误分类预测小于3的频率<br><img src="http://img2.ph.126.net/_w5tDCvH66Aqjk3XbQS4ow==/6632441055725838950.png" alt="image"><br>Figure 10. Correct predictions on 2nd and 3rd highest probable emotion.</li>
</ul>
<h6 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h6><p>随着池化层数量的增加，下游神经网络管道的feature map越来越抽象。图11和图12可视化第二次和第三次max-pooling池化层后的feature map。</p>
<p>分析和可视化卷积神经网络内层输出的代码见，<a href="https://github.com/JostineHo/mememoji/blob/master/data_visualization.ipynb" target="_blank" rel="external">https://github.com/JostineHo/mememoji/blob/master/data_visualization.ipynb</a>。<br><img src="http://img2.ph.126.net/YdQguRO5Fk-FllUX_Nzi1Q==/1282962943866801548.png" alt="image"><br>Figure 11. 第二个max-pooling池化层后的CNN (64-filter) feature maps。<br><img src="http://img1.ph.126.net/jVkrxuRkGihe8C6ywfJYLA==/6632453150353738432.png" alt="iamge"><br>Figure 12. 第三个max-pooling池化层后的CNN (128-filter) feature maps。</p>
<h5 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h5><p><strong>Jostine Ho</strong>是数据科学家和深度学习研究者。她感兴趣于计算机视觉和自动化解决现实世界中具体问题。她毕业于德克萨斯大学奥斯汀分校，取得石油系统工程专业硕士学位。</p>
<h5 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h5><ol>
<li><a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" target="_blank" rel="external"><em>“Dataset: Facial Emotion Recognition (FER2013)”</em></a> ICML 2013 Workshop in Challenges in Representation Learning, June 21 in Atlanta, GA.</li>
<li><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external"><em>“Andrej Karpathy’s Convolutional Neural Networks (CNNs / ConvNets)”</em></a> Convolutional Neural Networks for Visual Recognition (CS231n), Stanford University.</li>
<li>Srivastava et al., 2014. <em>“Dropout: A Simple Way to Prevent Neural Networks from Overfitting”</em>, Journal of Machine Learning Research, 15:1929-1958.</li>
<li>Duncan, D., Shine, G., English, C., 2016. <a href="http://cs231n.stanford.edu/reports2016/022_Report.pdf" target="_blank" rel="external"><em>“Report: Facial Emotion Recognition in Real-time”</em></a> Convolutional Neural Networks for Visual Recognition (CS231n), Stanford University.</li>
</ol>
<h2 id="Enjoy"><a href="#Enjoy" class="headerlink" title="Enjoy!"></a>Enjoy!</h2><p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/BeautifulSoup-scrap/" itemprop="url">
                  Python:BeautifulSoup爬虫手把手实例教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:25:17+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Web爬虫能自动抽取数据，并以人们容易理解的方式展现。本文章将举个金融市场的例子，但是Web爬虫能做的远不止于此。</p>
<p>如果你是一个狂热的投资者，当你需要的股票价格跨多个网站，那获取每天的股票价格是相当痛苦。本文通过创建一个Web爬虫自动从互联网上检索股指数据。</p>
<h5 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h5><p>我们将使用Python和BeautifulSoup编写爬虫：</p>
<ul>
<li>对于Mac用户，Python已预装好。打开终端，输入python —version，你回看到Python版本是2.7.x；</li>
<li>对于Windows用户，请按官方文档安装Python</li>
</ul>
<p>接下来使用<code>pip</code>安装BeautifulSoup库，在terminal中执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">easy_install pip  </div><div class="line">pip install BeautifulSoup4</div></pre></td></tr></table></figure>
<p><strong>Note</strong>：如果执行以上命令失败，请尝试加上<code>sudo</code>再次执行。</p>
<h5 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h5><p>在看代码之前，先理解一下HTML网页基本知识和爬取规则。</p>
<h6 id="HTML标签"><a href="#HTML标签" class="headerlink" title="HTML标签"></a>HTML标签</h6><p>如果你已经熟悉HTML标签，可以跳过此部分。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span>  </div><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span> First Scraping <span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span> Hello World <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<p>上面是HTML网页基本的语法，网页中的每个<tag>代表一个功能块：</tag></p>
<ol>
<li><code>&lt;!DOCTYPE html&gt;</code>：HTML文档必须以&lt;!DOCTYPE html&gt;标签为起点；</li>
<li>HTML文档包含在<code>&lt;html&gt;</code> 和<code>&lt;/html&gt;</code>标签之间；</li>
<li>HTML文档的元数据和脚本声明放在<code>&lt;head&gt;</code> 和 <code>&lt;/head&gt;</code>标签之间；</li>
<li>HTML文档的正文部分放在 <code>&lt;body&gt;</code> 和 <code>&lt;/body&gt;</code>标签内；</li>
<li><code>&lt;h1&gt;</code> 到 <code>&lt;h6&gt;</code>标签定义标题；</li>
<li><code>&lt;p&gt;</code> 标签定义段落； </li>
</ol>
<p>其它常用的标签有，<code>&lt;a&gt;</code> ：超链接，<code>&lt;table&gt;</code> ：表格；<code>&lt;tr&gt;</code> 表格的行，<code>&lt;td&gt;</code>表格的列。</p>
<p>有时，HTML标签也带有 <code>id</code> 或者 <code>class</code>  属性。 <code>id</code> 属性是指定HTML标签的唯一id，其在HTML文档内取值唯一。 <code>class</code> 属性是表示同一类HTML标签。我们可以使用两个属性进行数据定位。</p>
<p>W3Schools上可以学到更多关于HTML tag，id和class的知识。</p>
<h6 id="爬取规则"><a href="#爬取规则" class="headerlink" title="爬取规则"></a>爬取规则</h6><ul>
<li>爬取网站的第一步是，阅读网站的爬取协议或者声明。一般情况，爬取的数据不能用于商业目的。</li>
<li>不能太频繁的请求网站数据，不然会被列入黑名单。最好能让你的程序模拟人的行为。一般设为每秒访问一个页面为最佳。</li>
<li>网站的布局会随时改变，确保改写你的代码能重新爬取该网页。</li>
</ul>
<h5 id="检查（Inspect）网页"><a href="#检查（Inspect）网页" class="headerlink" title="检查（Inspect）网页"></a>检查（Inspect）网页</h5><p>下面拿<a href="http://www.bloomberg.com/quote/SPX:IND" target="_blank" rel="external">Bloomberg Quote</a>网站举例：</p>
<p>当前炒股非常火，假设某个炒股者关注股票市场，想得到股指（S&amp;P 500）名字和价格。首先在浏览器打开该网页，使用浏览器的检查器（inspector）来检查网页。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*KOJCuAYQyMIC8QdQyXERyw.png" alt="imge"></p>
<p>鼠标悬停在价格的位置，你会看到价格周围蓝色的方框。当点击它时，相关的网页在浏览器控制台上显示被选中。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*T0t6G2tawfTtKHR4yY_iVQ.png" alt="image"></p>
<p>上面的结果显示，该股指的价格包含在HTML标签的一级， <code>&lt;div class=&quot;basic-quote&quot;&gt;</code> → <code>&lt;div class=&quot;price-container up&quot;&gt;</code> → <code>&lt;div class=&quot;price&quot;&gt;</code>。</p>
<p>相似的，如果将鼠标悬停在“S&amp;P 500 Index”并点击名字，会看到它包含在<code>&lt;div class=&quot;basic-quote&quot;&gt;</code> 和 <code>&lt;h1 class=&quot;name&quot;&gt;</code>。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*ga5bmPtLDdWUTvL-pNxBgg.png" alt="imge"></p>
<p>现在我们知道可以通过<code>class</code> 标签辅助定位所需爬取的数据。</p>
<h5 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h5><p>知道所要爬取的数据位置，那就动起手来开始爬虫。</p>
<p>首先，导入所需的编程库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># import libraries</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div></pre></td></tr></table></figure>
<p>接着，声明网页URL变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># specify the url</span></div><div class="line">quote_page = ‘http://www.bloomberg.com/quote/SPX:IND<span class="string">'</span></div></pre></td></tr></table></figure>
<p>然后，使用Python urllib2获取HTML网页：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># query the website and return the html to the variable ‘page’</span></div><div class="line">page = urllib2.urlopen(quote_page)</div></pre></td></tr></table></figure>
<p>最后，把网页解析成BeautifulSoup格式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># parse the html using beautiful soap and store in variable `soup`</span></div><div class="line">soup = BeautifulSoup(page, ‘html.parser’)</div></pre></td></tr></table></figure>
<p>上面<code>soup</code>变量获得网页的HTML内容。我们将从其中抽取数据。</p>
<p>还记得所需爬取数据的唯一层吗？BeautifulSoup能帮我们获取这些层，并使用<code>find()</code>抽取其内容。因为HTML的class标签是唯一的，所以可简单的查询 <code>&lt;div class=&quot;name&quot;&gt;</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Take out the &lt;div&gt; of name and get its value</span></div><div class="line">name_box = soup.find(‘h1’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span> ‘name’&#125;)</div></pre></td></tr></table></figure>
<p>通过 <code>text</code>函数获取数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">name = name_box.text.strip() <span class="comment"># strip() is used to remove starting and trailing</span></div><div class="line"><span class="keyword">print</span> name</div></pre></td></tr></table></figure>
<p>同样地，我们获取股指价格：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get the index price</span></div><div class="line">price_box = soup.find(‘div’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span>’price’&#125;)</div><div class="line">price = price_box.text</div><div class="line"><span class="keyword">print</span> price</div></pre></td></tr></table></figure>
<p>当运行程序，将会打印S&amp;P 500股指。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*8sCE0XTu0Q0iHi2-QLpgXg.png" alt="image"></p>
<h5 id="导出Excel-CSV文件"><a href="#导出Excel-CSV文件" class="headerlink" title="导出Excel CSV文件"></a>导出Excel CSV文件</h5><p>获取数据之后进行存储，Excel逗号分隔的格式看起来不错。你能用Excel打开查看数据。</p>
<p>首先，导入Python的csv模块和datetime模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> csv</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div></pre></td></tr></table></figure>
<p>将爬取的数据存储到一个csv文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># open a csv file with append, so old data will not be erased</span></div><div class="line"><span class="keyword">with</span> open(‘index.csv’, ‘a’) <span class="keyword">as</span> csv_file:</div><div class="line"> writer = csv.writer(csv_file)</div><div class="line"> writer.writerow([name, price, datetime.now()])</div></pre></td></tr></table></figure>
<p>执行程序后，你可以打开一个index.csv文件，看到如下内容：</p>
<p><img src="http://img1.ph.126.net/7RTZNqWxEwVnVHR6LIA8Aw==/6632293721166253840.png" alt="image"></p>
<p>如果每天执行该程序，你无需打开网站即可获得S&amp;P 500股指价格。</p>
<h5 id="进阶使用"><a href="#进阶使用" class="headerlink" title="进阶使用"></a>进阶使用</h5><p>这时你可以轻松爬取一个股指，下面举例一次抽取多个股指数据。</p>
<p>首先，更新quote_page变量为一个URL数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">quote_page = [‘http://www.bloomberg.com/quote/SPX:IND<span class="string">', ‘http://www.bloomberg.com/quote/CCMP:IND'</span>]</div></pre></td></tr></table></figure>
<p>然后，将爬取代码加一个for循环，其处理每个URL并将数据存储到data：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># for loop</span></div><div class="line">data = []</div><div class="line"><span class="keyword">for</span> pg <span class="keyword">in</span> quote_page:</div><div class="line"> <span class="comment"># query the website and return the html to the variable ‘page’</span></div><div class="line"> page = urllib2.urlopen(pg)</div><div class="line"><span class="comment"># parse the html using beautiful soap and store in variable `soup`</span></div><div class="line"> soup = BeautifulSoup(page, ‘html.parser’)</div><div class="line"><span class="comment"># Take out the &lt;div&gt; of name and get its value</span></div><div class="line"> name_box = soup.find(‘h1’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span> ‘name’&#125;)</div><div class="line"> name = name_box.text.strip() <span class="comment"># strip() is used to remove starting and trailing</span></div><div class="line"><span class="comment"># get the index price</span></div><div class="line"> price_box = soup.find(‘div’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span>’price’&#125;)</div><div class="line"> price = price_box.text</div><div class="line"><span class="comment"># save the data in tuple</span></div><div class="line"> data.append((name, price))</div></pre></td></tr></table></figure>
<p>同时，更改存储csv文件部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># open a csv file with append, so old data will not be erased</span></div><div class="line"><span class="keyword">with</span> open(‘index.csv’, ‘a’) <span class="keyword">as</span> csv_file:</div><div class="line"> writer = csv.writer(csv_file)</div><div class="line"> <span class="comment"># The for loop</span></div><div class="line"> <span class="keyword">for</span> name, price <span class="keyword">in</span> data:</div><div class="line"> writer.writerow([name, price, datetime.now()])</div></pre></td></tr></table></figure>
<p>现在实现一次爬取两个股指价格。</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/how-apache-flink-enables-new-streaming-applications/" itemprop="url">
                  Flink开启流处理技术新潮流：解决流处理event time和消息乱序
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:24:57+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>写在之前：此文翻译自：<a href="http://data-artisans.com/how-apache-flink-enables-new-streaming-applications-part-1" target="_blank" rel="external">how-apache-flink-enables-new-streaming-applications</a>，做了少许改动，感谢原作者。</em></p>
<p>速度是成功的一重要要素，流处理技术的速度使得其越来越受青睐。在现实世界中，数据产品总是以持续不断的处理面目示人，比如，web服务日志，移动应用用户行为，或者传感器数据。</p>
<p>到目前为止，大部分数据处理架构技术栈都建立在有限的、静态的数据假设之上。现代流处理技术在不断地努力，通过模拟和处理现实世界的event，而最理想的模拟情况是把数据看作“streams”。Flink不但实现“streams”流，而且具有开创性的技术点。本篇先来讲述Flink解决消息乱序和event time窗口。</p>
<h5 id="消息乱序和event-time窗口"><a href="#消息乱序和event-time窗口" class="headerlink" title="消息乱序和event time窗口"></a>消息乱序和event time窗口</h5><p>在讨论解决消息乱序问题之前，需先定义时间和顺序。在流处理中，时间的概念有两个：</p>
<ul>
<li><strong>Event time </strong>：Event time是事件发生的时间，经常以时间戳表示，并和数据一起发送。带时间戳的数据流有，Web服务日志、监控agent的日志、移动端日志等；</li>
<li><strong>Processing time </strong> ：Processing time是处理事件数据的服务器时间，一般是运行流处理应用的服务器时钟。</li>
</ul>
<p>许多流处理场景中，事件发生的时间和事件到达待处理的消息队列时间有各种延迟：</p>
<ol>
<li>各种网络延迟；</li>
<li>数据流消费者导致的队列阻塞和反压影响；</li>
<li>数据流毛刺，即，数据波动；</li>
<li>事件生产者（移动设备、传感器等）离线；</li>
</ol>
<p>上述诸多原因会导致队列中的消息频繁乱序。事件发生的时间和事件到达待处理的消息队列时间的不同随着时间在不断变化，这常被称为时间偏移（<em>event time skew</em>），表示成：<em>“processing time – event time”</em>。</p>
<p>对大部分应用来讲，基于事件的创建时间分析数据比基于事件的处理时间分析数据要更有意义。Flink允许用户定义基于事件时间（event time）的窗口，而不是处理时间。</p>
<p>Flink使用<em>事件时间 clock</em> 来跟踪事件时间，其是以<em>watermarks</em>来实现的。<em>watermarks</em>是Flink 源流基于事件时间点生成的特殊事件。 <em>T</em> 时间点的<em>watermarks</em>意味着，小于 T 的时间戳的事件不会再到达。Flink的所有操作都基于<em>watermarks</em>来跟踪事件时间。</p>
<p>下图描述Flink是如何计算事件时间窗口。当<em>watermarks</em>到达时窗口计算会被触发，并更新事件时间clock：</p>
<p>很明显，左上角<em>watermarks</em> W(4)快要到达，出现计算窗口T1-T4；右上角因为消息有乱序（事件时间为3的事件排在事件时间为7的后面），同时出现两个计算窗口T1-T4和T4-T8；左下角<em>watermarks</em> W(4)触发计算窗口演化，小于事件时间4的事件不再到达；右下角参考前面解读。</p>
<p>基于事件时间的Pipeline会产生更精确的结果，因为一旦有相应事件时间的事件到达会尽快计算；而相对于周期性的批量处理来讲，基于事件时间的数据流pipeline会更早的计算出结果，并且更精确（批量处理不能很好的处理跨batch的消息乱序）。</p>
<h5 id="结合事件时间和实时pipeline"><a href="#结合事件时间和实时pipeline" class="headerlink" title="结合事件时间和实时pipeline"></a>结合事件时间和实时pipeline</h5><p>事件时间pipeline会因为必要的事件时间过程而导致一定的延迟。有时延迟太大导致无法获得实时结果，这时就得增加延迟短的结果。</p>
<p>Flink是一个流处理框架，能毫秒级处理事件，它能在同一个应用中综合低延迟的实时pipeline和事件时间pipeline，列子如下：</p>
<ol>
<li>基于单个事件的低延迟报警。如果某类事件被识别，需要发出报警信息；</li>
<li>基于处理时间窗口的实时dashboard，能够聚合秒级的事件数；</li>
<li>基于事件时间的精确统计</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Main entry point.</div><div class="line">    */</div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">       </div><div class="line">       <span class="comment">// create environment and configure it</span></div><div class="line">       <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</div><div class="line">       env.registerType(Statistic.class);</div><div class="line">       env.registerType(SensorReading.class);</div><div class="line">       </div><div class="line">       env.setParallelism(<span class="number">4</span>);</div><div class="line">       env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</div><div class="line">       </div><div class="line">       </div><div class="line">       <span class="comment">// create a stream of sensor readings, assign timestamps, and create watermarks</span></div><div class="line">       DataStream&lt;SensorReading&gt; readings = env</div><div class="line">               .addSource(<span class="keyword">new</span> SampleDataGenerator())</div><div class="line">               .assignTimestamps(<span class="keyword">new</span> ReadingsTimestampAssigner());</div><div class="line">       </div><div class="line">       <span class="comment">// path (1) - low latency event-at a time filter</span></div><div class="line">       readings</div><div class="line">               .filter(reading -&gt; reading.reading() &gt; <span class="number">100.0</span>)</div><div class="line">               .map( reading -&gt; <span class="string">"-- ALERT -- Reading above threshold: "</span> + reading )</div><div class="line">               .print();</div><div class="line">       </div><div class="line">       <span class="comment">// path (2) - processing time windows: Compute max readings per sensor group</span></div><div class="line">       </div><div class="line">       <span class="comment">// because the default stream time is set to Event Time, we override the trigger with a</span></div><div class="line">       <span class="comment">// processing time trigger</span></div><div class="line">       </div><div class="line">       readings</div><div class="line">               .keyBy( reading -&gt; reading.sensorGroup() )</div><div class="line">               .window(TumblingTimeWindows.of(Time.seconds(<span class="number">5</span>)))</div><div class="line">               .trigger(ProcessingTimeTrigger.create())</div><div class="line">               .fold(<span class="keyword">new</span> Statistic(), (curr, next) -&gt;</div><div class="line">                       <span class="keyword">new</span> Statistic(next.sensorGroup(), next.timestamp(), Math.max(curr.value(), next.reading())))</div><div class="line">               </div><div class="line">               .map(stat -&gt; <span class="string">"PROC TIME - max for "</span> + stat)</div><div class="line">               .print();</div><div class="line">       </div><div class="line">       <span class="comment">// path (3) - event time windows: Compute average reading over sensors per minute</span></div><div class="line">       </div><div class="line">       <span class="comment">// we use a WindowFunction here, to illustrate how to get access to the window object</span></div><div class="line">       <span class="comment">// that contains bounds, etc.</span></div><div class="line">       <span class="comment">// Pre-aggregation is possible by adding a pre-aggregator ReduceFunction</span></div><div class="line">       </div><div class="line">       readings</div><div class="line">               <span class="comment">// group by, window and aggregate </span></div><div class="line">               .keyBy(reading -&gt; reading.sensorId() )</div><div class="line">               .timeWindow(Time.minutes(<span class="number">1</span>), Time.seconds(<span class="number">10</span>))</div><div class="line">               .apply(<span class="keyword">new</span> WindowFunction&lt;SensorReading, Statistic, String, TimeWindow&gt;() &#123;</div><div class="line"></div><div class="line">                   <span class="meta">@Override</span></div><div class="line">                   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(String id, TimeWindow window, Iterable&lt;SensorReading&gt; values, Collector&lt;Statistic&gt; out)</span> </span>&#123;</div><div class="line">                       <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">                       <span class="keyword">double</span> agg = <span class="number">0.0</span>;</div><div class="line">                       <span class="keyword">for</span> (SensorReading r : values) &#123;</div><div class="line">                           agg += r.reading();</div><div class="line">                           count++;</div><div class="line">                       &#125;</div><div class="line">                       out.collect(<span class="keyword">new</span> Statistic(id, window.getStart(), agg / count));</div><div class="line">                   &#125;</div><div class="line">               &#125;)</div><div class="line">               </div><div class="line">               .map(stat -&gt; <span class="string">"EVENT TIME - avg for "</span> + stat)</div><div class="line">               .print();</div><div class="line">       </div><div class="line">       env.execute(<span class="string">"Event time example"</span>);</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>Flink提供的窗口触发条件包括处理时间clock，事件时间clock，以及数据流内容。</p>
<h5 id="Flink是如何度量时间？"><a href="#Flink是如何度量时间？" class="headerlink" title="Flink是如何度量时间？"></a>Flink是如何度量时间？</h5><p>下面看下Flink是如何处理时间的，在这点上与其它老的流处理系统有啥不同。</p>
<p>一般意义上讲，时间是用clock度量的。最简单的clock称为<em>wall clock</em>，它是集群中服务器执行流处理作业的间隔clock。<em>wall clock</em>是用来跟踪处理时间的。</p>
<p>为了跟踪事件时间，我们需要集群机器间相同的clock。Flink是通过<em>watermarks</em>机制实现的。一个<em>watermarks</em>是指在真实事件流时间点发生的事件（比如，上午10点），那么到现在为止上午10点前的事件不会再到达。事件时间clock（<em>event time clock</em>）跟踪时间比wall clock要粗粒度，但是更准确。</p>
<p>还有第三种clock，叫做<em>system clock</em>。它是用来保证流处理系统的“exactly-once“语义的。Flink跟踪作业的处理是通过<em>barriers</em>（栏栅），并进行snapshot。<em>barriers</em>与<em>watermarks</em>类似，不同之处在于，<em>barriers</em>是由Flink的master机器的<em>wall clock</em> 生成， 而<em>watermarks</em>是由真实世界的时间生成。同样，Spark Streaming的micro-batche schedule是基于Spark receiver的<em>wall clock</em> 。</p>
<p>下图完美展现刚才讲的各种时间：</p>
<p>Worker 1和Worker 2机器上并行执行对数据源和窗口的操作作业。事件上的数字代表时间戳，方块的颜色代表不同的key（灰色流向窗口1，紫色流向窗口2）。数据源从队列中读取事件（有分区，通过key分区），把他们分发到正确的窗口。窗口定义为基于事件时间的时间窗口（Flink包含时间窗口和count窗口）。我能看到Worker 1、Worker 2和Master机器的<em>wall clock</em>不同（缺乏时间同步，具体看ntp），分别为10，8，7。数据源发出<em>watermarks</em>，当前的<em>watermarks</em>时间戳为4。这意味着，event time clock是4，这时进行并行计算。Master（JobManager）对数据源做<em>barriers</em>，并对计算做snapshot。系统时间此时为7，checkpoint为第七个。</p>
<p>下面对流处理框架中的三种clock进行总结：</p>
<ul>
<li><strong>event time clock</strong>：度量事件流的时间，粗粒度；</li>
<li><strong>system clock</strong>：度量计算的过程。实际上是协调者机器的<em>wall clock</em>；</li>
<li><strong>wall clock </strong>：度量处理时间。</li>
</ul>
<p>下面也给出老的流处理系统的弊端：</p>
<ol>
<li>计算不准确：因为真实世界的事件发生顺序与处理的顺序经常不一致；</li>
<li>计算结果强依赖当前时间；</li>
<li>系统参数配置会影响程序的语义：比如，增加checkpoin的间隔。</li>
</ol>
<p>老的流处理系统的这些缺点让它们没法获得准确的结果（至少是可控的准确度）。</p>
<p>而Flink完全分离这三种clock：</p>
<ol>
<li>基于<em>event time clock</em>的<em>watermarks</em>跟踪事件流时间，允许用户定义基于事件时间的窗口；</li>
<li><em>system clock</em>与<em>event time clock</em>完全解藕，跟踪计算过程和全局snapshot，不对外暴露api，仅仅用来分布式系统的协调；</li>
<li>处理时间是用的机器的<em>wall clock</em>，暴露给用户支持处理时间窗口。</li>
</ol>
<p>相关文章：</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/kafka-cluster-producer/" itemprop="url">
                  Kafka使用总结：Producer
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:24:30+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Kafka作为消息中间件是各公司平台架构绕不开的话题。</p>
<p>不管你是把Kafka作为队列，还是消息通道，都需要在应用中通过producer写数据到Kafka，再用consumer从Kafka中消费。应用往Kafka写数据的原因有很多：用户行为分析、日志存储、异步通信等。多样化的使用场景带来了多样化的需求：消息是否能丢失？是否容忍重复？消息的吞吐量？消息的延迟？</p>
<p>这么苛刻的要求Kafka能满足吗？</p>
<p><img src="http://img1.ph.126.net/jOA6c9KB5qbpivkjsYGDwg==/6632071619817192826.png" alt="image"></p>
<h5 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h5><p>首先，创建ProducerRecord必须包含Topic和Value，key和partition可选。然后，序列化key和value对象为ByteArray，并发送到网络。</p>
<p>接下来，消息发送到partitioner。如果创建ProducerRecord时指定了partition，此时partitioner啥也不用做，简单的返回指定的partition即可。如果未指定partition，partitioner会基于ProducerRecord的key生成partition。producer选择好partition后，增加record到对应topic和partition的batch record。最后，专有线程负责发送batch record到合适的Kafka broker。</p>
<p>当broker收到消息时，它会返回一个应答（response）。如果消息成功写入Kafka，broker将返回RecordMetadata对象（包含topic，partition和offset）；相反，broker将返回error。这时producer收到error会尝试重试发送消息几次，直到producer返回error。</p>
<h5 id="Producer实战"><a href="#Producer实战" class="headerlink" title="Producer实战"></a>Producer实战</h5><h6 id="构造Kafka-Producer"><a href="#构造Kafka-Producer" class="headerlink" title="构造Kafka Producer"></a>构造Kafka Producer</h6><p>创建Properties对象，配置producer参数。根据Properties创建producer对象。Kafka producer必选参数有3个：</p>
<ul>
<li><em>bootstrap.servers</em> ：Kafka broker的列表，包含host和port。此处不必包含Kafka集群所有的broker，因为producer会通过其它broker查询到所需信息。但至少包含2个broker；</li>
<li><em>key.serializer</em>：序列化key参数，值为类名，org.apache.kafka.common.serialization.Serializer接口的实现；</li>
<li><em>value.serializer</em>：序列化value参数，值为类名，使用方式同<em>key.serializer</em>。</li>
</ul>
<p>最简代码实现如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">private Properties kafkaProps = new Properties();</div><div class="line">kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");</div><div class="line">kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.String-</div><div class="line">Serializer");</div><div class="line">kafkaProps.put("value.serializer", "org.apache.kafka.common.serializa-</div><div class="line">tion.StringSerializer");</div><div class="line">producer = new KafkaProducer&lt;String, String&gt;(kafkaProps);</div></pre></td></tr></table></figure>
<p>创建Properties对象，key和value为String类型，选用Kafka自带的StringSerializer。通过属性配置可以控制Producer的行为。</p>
<p>实例化producer后，接着发送消息。这里主要有3种发送消息的方法：</p>
<ul>
<li>立即发送：只管发送消息到server端，不care消息是否成功发送。大部分情况下，这种发送方式会成功，因为Kafka自身具有高可用性，producer会自动重试；但有时也会丢失消息；</li>
<li>同步发送：通过send()方法发送消息，并返回Future对象。get()方法会等待Future对象，看send()方法是否成功；</li>
<li>异步发送：通过带有回调函数的send()方法发送消息，当producer收到Kafka broker的response会触发回调函数</li>
</ul>
<p>以上所有情况，一定要时刻考虑发送消息可能会失败，想清楚如何去处理异常。</p>
<p>通常我们是一个producer起一个线程开始发送消息。为了优化producer的性能，一般会有下面几种方式：单个producer起多个线程发送消息；使用多个producer。</p>
<p>下面开始详细展示上面所提到的三种发送消息的方法，以及各种类型错误的处理方式。</p>
<h6 id="发送消息到Kafka"><a href="#发送消息到Kafka" class="headerlink" title="发送消息到Kafka"></a>发送消息到Kafka</h6><p>最简单的方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ProducerRecord&lt;String, String&gt; record =</div><div class="line">            <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Precision Products"</span>,<span class="string">"France"</span>);</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      producer.send(record);</div><div class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>创建ProducerRecord对象，Producer使用send()方法发送ProducerRecord。send()方法会返回带有RecordMetadata的Future对象，这里只简单的忽略返回值，所以我们并不会知道消息是否发送成功；</p>
<p>但即使如此简单，Producer发送消息到Kafka也仍然得处理些异常：当序列化消息失败会抛出SerializationException；buffer溢出会抛出BufferExhaustedException；当发送线程终止会抛出InterruptException。</p>
<h6 id="同步发消息"><a href="#同步发消息" class="headerlink" title="同步发消息"></a>同步发消息</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ProducerRecord&lt;String, String&gt; record =</div><div class="line">            <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Precision Products"</span>, <span class="string">"France"</span>);</div><div class="line">producer.send(record).get();</div></pre></td></tr></table></figure>
<p>这里，我们使用Future.get()方法等待Kafka的状态返回。Producer可以实现自己的Future来处理Kafka broker返回的异常。如果Producer发送消息成功，它会返回RecordMetadata对象（可用来检索消息的offset）。</p>
<p>Kafka Producer一般有两类错误。可重试错误会通过重试发送消息解决。比如，连接重连可解决连接错误；partition重新选举leader可解决“no leader”错误。Kafka Producer能配置重试次数，超过重试次数还不能解决的会抛出错误。另外一类就是不能通过重试处理的错误，比如，消息大小太大，这种情况下Kafka Producer会立即报错。</p>
<h6 id="异步发送消息"><a href="#异步发送消息" class="headerlink" title="异步发送消息"></a>异步发送消息</h6><p>如果应用和Kafka集群间的网络质量太差，那么同步发送消息的方式发送每条消息后需要等待较长时间才收到应答。这对高并发海量消息发送简直就是灾难，因为等待应答的时间远超过消息发送时间。另外，有些app压根就不要求返回值。况且，即使发送消息失败了，只要写下对应的错误日志即可。</p>
<p>为了异步发送消息，同时可以处理错误。Producer支持带有回调函数的发送消息方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoProducerCallback</span> <span class="keyword">implements</span> <span class="title">Callback</span> </span>&#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</div><div class="line">         <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</div><div class="line">             e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">&#125; &#125;</div><div class="line"></div><div class="line">ProducerRecord&lt;String, String&gt; record =</div><div class="line">            <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Biomedical Materials"</span>, <span class="string">"USA"</span>);</div><div class="line">producer.send(record, <span class="keyword">new</span> DemoProducerCallback());</div></pre></td></tr></table></figure>
<p>使用回调函数的前提是实现org.apache.kafka.clients.producer.Callback 接口。如果Kafka返回错误，onCompletion捕获到非null异常。示例代码仅仅打印出了异常信息，实际应用开发需根据实际情况添加业务逻辑处理。</p>
<h5 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h5><p>在前面的列子中，可看出Producer配置必须指定序列化方法（serializer，默认是String serializer）。</p>
<p>这里将讲解如何构建定制化的序列化器，然后介绍Avro序列化器。</p>
<h6 id="定制序列化器"><a href="#定制序列化器" class="headerlink" title="定制序列化器"></a>定制序列化器</h6><p>当你需要发送到Kafka的对象非String和Integer，那你要么自己实现对应的序列化器，要么使用像Avro、Thrift或者Protobuf之类的业界通用的序列化库。这里强烈推荐使用这些工业化的通用的序列化库。</p>
<p>为了让大家理解序列化器的工作原理，这里还是先讲讲如何构建定制化的序列化器。下面先建一个简单的Customer类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</div><div class="line">            <span class="keyword">private</span> <span class="keyword">int</span> customerID;</div><div class="line">            <span class="keyword">private</span> String customerName;</div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">(<span class="keyword">int</span> ID, String name)</span> </span>&#123;</div><div class="line">                    <span class="keyword">this</span>.customerID = ID;</div><div class="line">                    <span class="keyword">this</span>.customerName = name;</div><div class="line">&#125;</div><div class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getID</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> customerID;</div><div class="line">&#125;</div><div class="line">      <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">       <span class="keyword">return</span> customerName;</div><div class="line">&#125; &#125;</div></pre></td></tr></table></figure>
<p>接着创建Customer类的序列化器：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.kafka.common.errors.SerializationException;</div><div class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</div><div class="line"><span class="keyword">import</span> java.util.Map;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerSerializer</span> <span class="keyword">implements</span> <span class="title">Serializer</span>&lt;<span class="title">Customer</span>&gt; </span>&#123;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map configs, <span class="keyword">boolean</span> isKey)</span> </span>&#123;</div><div class="line">   <span class="comment">// nothing to configure</span></div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">  We are serializing Customer as:</div><div class="line">  4 byte int representing customerId</div><div class="line">  4 byte int representing length of customerName in UTF-8 bytes (0 if name is</div><div class="line">Null)</div><div class="line">  N bytes representing customerName in UTF-8</div><div class="line">  **/</div><div class="line">  <span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String topic, Customer data) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">byte</span>[] serializedName;</div><div class="line">                  <span class="keyword">int</span> stringSize;</div><div class="line">      <span class="keyword">if</span> (data == <span class="keyword">null</span>)</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">      <span class="keyword">else</span> &#123;</div><div class="line">                                <span class="keyword">if</span> (data.getName() != <span class="keyword">null</span>) &#123;</div><div class="line">         serializeName = data.getName().getBytes(<span class="string">"UTF-8"</span>);</div><div class="line">         stringSize = serializedName.length;</div><div class="line">                                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                                  serializedName = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>];</div><div class="line">                                  stringSize = <span class="number">0</span>;</div><div class="line">                                &#125; </div><div class="line">      &#125;</div><div class="line">      </div><div class="line">      ByteBuffer buffer = ByteBuffer.allocate(<span class="number">4</span> + <span class="number">4</span> + stringSize);</div><div class="line">      buffer.putInt(data.getID());</div><div class="line">      buffer.putInt(stringSize);</div><div class="line">      buffer.put(serializedName);</div><div class="line">      <span class="keyword">return</span> buffer.array();</div><div class="line">          &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Error when serializing Customer to byte[] "</span> + e);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// nothing to close</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h6 id="Avro的序列化"><a href="#Avro的序列化" class="headerlink" title="Avro的序列化"></a>Avro的序列化</h6><p>Avro详细说明见官方文档，这里只列出部分要用到的特性。</p>
<p>Avro Schema是用Json描述，如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"> &#123;<span class="attr">"namespace"</span>: <span class="string">"customerManagement.avro"</span>,</div><div class="line">     <span class="attr">"type"</span>: <span class="string">"record"</span>,</div><div class="line">     <span class="attr">"name"</span>: <span class="string">"Customer"</span>,</div><div class="line">     <span class="attr">"fields"</span>: [</div><div class="line">         &#123;<span class="attr">"name"</span>: <span class="string">"id"</span>, <span class="attr">"type"</span>: <span class="string">"int"</span>&#125;,</div><div class="line">         &#123;<span class="attr">"name"</span>: <span class="string">"name"</span>,  <span class="attr">"type"</span>: <span class="string">"string"</span>&#125;,</div><div class="line">         &#123;<span class="attr">"name"</span>: <span class="string">"email"</span>, <span class="attr">"type"</span>: [<span class="string">"null"</span>, <span class="string">"string"</span>], <span class="attr">"default"</span>: <span class="string">"null"</span>&#125;</div><div class="line">] &#125;</div></pre></td></tr></table></figure>
<p>Avro依赖模式(Schema)来实现数据结构定义，所以读写Avro文件都得依赖其Schema。Kafka中<a href="http://docs.confluent.io/3.0.0/schema-registry/docs/intro.html#schemaregistry-intro" target="_blank" rel="external">Schema Registry</a>提供元数据的存储和解析。那Producer的序列化和Consumer的反序列化都会去Schema Registry读取对应的Schema。</p>
<p><img src="http://img0.ph.126.net/X0tYnyzV8cKuoxOvK1w4rw==/6632381682093836586.png" alt="image"></p>
<p>Avro的使用有两种：一种是使用Avro Schema生成的类（官方提供生成工具，比如，avro-tools-1.7.0.jar）；一种是直接Avro Schema。Kafka Producer使用Avro序列化器的方式与其它序列化器相同。下面先说使用Avro Schema生成的类的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">    Properties props = <span class="keyword">new</span> Properties();</div><div class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">    props.put(<span class="string">"key.serializer"</span>, <span class="string">"io.confluent.kafka.serializers.KafkaAvroSerializer"</span>);</div><div class="line">    props.put(<span class="string">"value.serializer"</span>, <span class="string">"io.confluent.kafka.serializers.KafkaAvroSerializer"</span>);</div><div class="line">    props.put(<span class="string">"schema.registry.url"</span>, schemaUrl);</div><div class="line">    String topic = <span class="string">"customerContacts"</span>;</div><div class="line">    <span class="keyword">int</span> wait = <span class="number">500</span>;</div><div class="line">    Producer&lt;String, Customer&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, Customer&gt;(props);</div><div class="line">    <span class="comment">// We keep producing new events until someone ctrl-c</span></div><div class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">        Customer customer = CustomerGenerator.getNext();</div><div class="line">        System.out.println(<span class="string">"Generated customer "</span> + customer.toString());</div><div class="line">        ProducerRecord&lt;String, Customer&gt; record =</div><div class="line">                            <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, customer.getId(), customer);</div><div class="line">        producer.send(record);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中，schema.registry.url是schema存储的位置，<em>KafkaAvroSerializer</em> 是Avro的序列化器，<em>Customer</em> 是生成的类。</p>
<p>如果你想直接使用Avro Schema，方法如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">Properties props = new Properties();</div><div class="line">props.put("bootstrap.servers", "localhost:9092");</div><div class="line">props.put("key.serializer", "io.confluent.kafka.serializers.KafkaAvroSerializer");</div><div class="line">props.put("value.serializer", "io.confluent.kafka.serializers.KafkaAvroSerializer");</div><div class="line">props.put("schema.registry.url", url);</div><div class="line"></div><div class="line">String schemaString = "&#123;\"namespace\": \"customerManagement.avro\",</div><div class="line">  \"type\": \"record\", " +</div><div class="line">                               "\"name\": \"Customer\"," +</div><div class="line">                               "\"fields\": [" +</div><div class="line">                                "&#123;\"name\": \"id\", \"type\": \"int\"&#125;," +</div><div class="line">                                "&#123;\"name\": \"name\", \"type\": \"string\"&#125;," +</div><div class="line">                                "&#123;\"name\": \"email\", \"type\": [\"null\",\"string</div><div class="line">    \"], \"default\":\"null\" &#125;" +</div><div class="line">                               "]&#125;";</div><div class="line"></div><div class="line">Producer&lt;String, GenericRecord&gt; producer = new KafkaProducer&lt;String, GenericRecord&gt;(props);</div><div class="line"></div><div class="line">Schema.Parser parser = new Schema.Parser();</div><div class="line">Schema schema = parser.parse(schemaString);</div><div class="line"></div><div class="line">for (int nCustomers = 0; nCustomers &lt; customers; nCustomers++) &#123;</div><div class="line">  String name = "exampleCustomer" + nCustomers;</div><div class="line">  String email = "example " + nCustomers + "@example.com";</div><div class="line">  GenericRecord customer = new GenericData.Record(schema);</div><div class="line">  customer.put("id", nCustomer);</div><div class="line">  customer.put("name", name);</div><div class="line">  customer.put("email", email);</div><div class="line">  ProducerRecord&lt;String, GenericRecord&gt; data =</div><div class="line">    new ProducerRecord&lt;String, GenericRecord&gt;("customerContacts", name, customer);</div><div class="line">  producer.send(data);</div><div class="line">&#125; &#125;</div></pre></td></tr></table></figure>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://img0.ph.126.net/3vPAbMoh_6fH3-g_I0zo-w==/6631748363397501906.jpg"
               alt="侠天" />
          <p class="site-author-name" itemprop="name">侠天</p>
          <p class="site-description motion-element" itemprop="description">侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">32</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/1333564335" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.infoq.com/cn/author/%E4%BE%A0%E5%A4%A9" target="_blank" title="InfoQ">
                  
                    <i class="fa fa-fw fa-infoq"></i>
                  
                  InfoQ
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">侠天</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
