<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="神机喵算" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。">
<meta property="og:type" content="website">
<meta property="og:title" content="神机喵算">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="神机喵算">
<meta property="og:description" content="侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神机喵算">
<meta name="twitter:description" content="侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/page/2/"/>

  <title> 神机喵算 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">神机喵算</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/BeautifulSoup-scrap/" itemprop="url">
                  Python:BeautifulSoup爬虫手把手实例教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:25:17+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Web爬虫能自动抽取数据，并以人们容易理解的方式展现。本文章将举个金融市场的例子，但是Web爬虫能做的远不止于此。</p>
<p>如果你是一个狂热的投资者，当你需要的股票价格跨多个网站，那获取每天的股票价格是相当痛苦。本文通过创建一个Web爬虫自动从互联网上检索股指数据。</p>
<h5 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h5><p>我们将使用Python和BeautifulSoup编写爬虫：</p>
<ul>
<li>对于Mac用户，Python已预装好。打开终端，输入python —version，你回看到Python版本是2.7.x；</li>
<li>对于Windows用户，请按官方文档安装Python</li>
</ul>
<p>接下来使用<code>pip</code>安装BeautifulSoup库，在terminal中执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">easy_install pip  </div><div class="line">pip install BeautifulSoup4</div></pre></td></tr></table></figure>
<p><strong>Note</strong>：如果执行以上命令失败，请尝试加上<code>sudo</code>再次执行。</p>
<h5 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h5><p>在看代码之前，先理解一下HTML网页基本知识和爬取规则。</p>
<h6 id="HTML标签"><a href="#HTML标签" class="headerlink" title="HTML标签"></a>HTML标签</h6><p>如果你已经熟悉HTML标签，可以跳过此部分。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span>  </div><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span> First Scraping <span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span> Hello World <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<p>上面是HTML网页基本的语法，网页中的每个<tag>代表一个功能块：</tag></p>
<ol>
<li><code>&lt;!DOCTYPE html&gt;</code>：HTML文档必须以&lt;!DOCTYPE html&gt;标签为起点；</li>
<li>HTML文档包含在<code>&lt;html&gt;</code> 和<code>&lt;/html&gt;</code>标签之间；</li>
<li>HTML文档的元数据和脚本声明放在<code>&lt;head&gt;</code> 和 <code>&lt;/head&gt;</code>标签之间；</li>
<li>HTML文档的正文部分放在 <code>&lt;body&gt;</code> 和 <code>&lt;/body&gt;</code>标签内；</li>
<li><code>&lt;h1&gt;</code> 到 <code>&lt;h6&gt;</code>标签定义标题；</li>
<li><code>&lt;p&gt;</code> 标签定义段落； </li>
</ol>
<p>其它常用的标签有，<code>&lt;a&gt;</code> ：超链接，<code>&lt;table&gt;</code> ：表格；<code>&lt;tr&gt;</code> 表格的行，<code>&lt;td&gt;</code>表格的列。</p>
<p>有时，HTML标签也带有 <code>id</code> 或者 <code>class</code>  属性。 <code>id</code> 属性是指定HTML标签的唯一id，其在HTML文档内取值唯一。 <code>class</code> 属性是表示同一类HTML标签。我们可以使用两个属性进行数据定位。</p>
<p>W3Schools上可以学到更多关于HTML tag，id和class的知识。</p>
<h6 id="爬取规则"><a href="#爬取规则" class="headerlink" title="爬取规则"></a>爬取规则</h6><ul>
<li>爬取网站的第一步是，阅读网站的爬取协议或者声明。一般情况，爬取的数据不能用于商业目的。</li>
<li>不能太频繁的请求网站数据，不然会被列入黑名单。最好能让你的程序模拟人的行为。一般设为每秒访问一个页面为最佳。</li>
<li>网站的布局会随时改变，确保改写你的代码能重新爬取该网页。</li>
</ul>
<h5 id="检查（Inspect）网页"><a href="#检查（Inspect）网页" class="headerlink" title="检查（Inspect）网页"></a>检查（Inspect）网页</h5><p>下面拿<a href="http://www.bloomberg.com/quote/SPX:IND" target="_blank" rel="external">Bloomberg Quote</a>网站举例：</p>
<p>当前炒股非常火，假设某个炒股者关注股票市场，想得到股指（S&amp;P 500）名字和价格。首先在浏览器打开该网页，使用浏览器的检查器（inspector）来检查网页。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*KOJCuAYQyMIC8QdQyXERyw.png" alt="imge"></p>
<p>鼠标悬停在价格的位置，你会看到价格周围蓝色的方框。当点击它时，相关的网页在浏览器控制台上显示被选中。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*T0t6G2tawfTtKHR4yY_iVQ.png" alt="image"></p>
<p>上面的结果显示，该股指的价格包含在HTML标签的一级， <code>&lt;div class=&quot;basic-quote&quot;&gt;</code> → <code>&lt;div class=&quot;price-container up&quot;&gt;</code> → <code>&lt;div class=&quot;price&quot;&gt;</code>。</p>
<p>相似的，如果将鼠标悬停在“S&amp;P 500 Index”并点击名字，会看到它包含在<code>&lt;div class=&quot;basic-quote&quot;&gt;</code> 和 <code>&lt;h1 class=&quot;name&quot;&gt;</code>。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*ga5bmPtLDdWUTvL-pNxBgg.png" alt="imge"></p>
<p>现在我们知道可以通过<code>class</code> 标签辅助定位所需爬取的数据。</p>
<h5 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h5><p>知道所要爬取的数据位置，那就动起手来开始爬虫。</p>
<p>首先，导入所需的编程库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># import libraries</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div></pre></td></tr></table></figure>
<p>接着，声明网页URL变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># specify the url</span></div><div class="line">quote_page = ‘http://www.bloomberg.com/quote/SPX:IND<span class="string">'</span></div></pre></td></tr></table></figure>
<p>然后，使用Python urllib2获取HTML网页：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># query the website and return the html to the variable ‘page’</span></div><div class="line">page = urllib2.urlopen(quote_page)</div></pre></td></tr></table></figure>
<p>最后，把网页解析成BeautifulSoup格式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># parse the html using beautiful soap and store in variable `soup`</span></div><div class="line">soup = BeautifulSoup(page, ‘html.parser’)</div></pre></td></tr></table></figure>
<p>上面<code>soup</code>变量获得网页的HTML内容。我们将从其中抽取数据。</p>
<p>还记得所需爬取数据的唯一层吗？BeautifulSoup能帮我们获取这些层，并使用<code>find()</code>抽取其内容。因为HTML的class标签是唯一的，所以可简单的查询 <code>&lt;div class=&quot;name&quot;&gt;</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Take out the &lt;div&gt; of name and get its value</span></div><div class="line">name_box = soup.find(‘h1’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span> ‘name’&#125;)</div></pre></td></tr></table></figure>
<p>通过 <code>text</code>函数获取数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">name = name_box.text.strip() <span class="comment"># strip() is used to remove starting and trailing</span></div><div class="line"><span class="keyword">print</span> name</div></pre></td></tr></table></figure>
<p>同样地，我们获取股指价格：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get the index price</span></div><div class="line">price_box = soup.find(‘div’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span>’price’&#125;)</div><div class="line">price = price_box.text</div><div class="line"><span class="keyword">print</span> price</div></pre></td></tr></table></figure>
<p>当运行程序，将会打印S&amp;P 500股指。</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*8sCE0XTu0Q0iHi2-QLpgXg.png" alt="image"></p>
<h5 id="导出Excel-CSV文件"><a href="#导出Excel-CSV文件" class="headerlink" title="导出Excel CSV文件"></a>导出Excel CSV文件</h5><p>获取数据之后进行存储，Excel逗号分隔的格式看起来不错。你能用Excel打开查看数据。</p>
<p>首先，导入Python的csv模块和datetime模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> csv</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div></pre></td></tr></table></figure>
<p>将爬取的数据存储到一个csv文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># open a csv file with append, so old data will not be erased</span></div><div class="line"><span class="keyword">with</span> open(‘index.csv’, ‘a’) <span class="keyword">as</span> csv_file:</div><div class="line"> writer = csv.writer(csv_file)</div><div class="line"> writer.writerow([name, price, datetime.now()])</div></pre></td></tr></table></figure>
<p>执行程序后，你可以打开一个index.csv文件，看到如下内容：</p>
<p><img src="http://img1.ph.126.net/7RTZNqWxEwVnVHR6LIA8Aw==/6632293721166253840.png" alt="image"></p>
<p>如果每天执行该程序，你无需打开网站即可获得S&amp;P 500股指价格。</p>
<h5 id="进阶使用"><a href="#进阶使用" class="headerlink" title="进阶使用"></a>进阶使用</h5><p>这时你可以轻松爬取一个股指，下面举例一次抽取多个股指数据。</p>
<p>首先，更新quote_page变量为一个URL数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">quote_page = [‘http://www.bloomberg.com/quote/SPX:IND<span class="string">', ‘http://www.bloomberg.com/quote/CCMP:IND'</span>]</div></pre></td></tr></table></figure>
<p>然后，将爬取代码加一个for循环，其处理每个URL并将数据存储到data：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># for loop</span></div><div class="line">data = []</div><div class="line"><span class="keyword">for</span> pg <span class="keyword">in</span> quote_page:</div><div class="line"> <span class="comment"># query the website and return the html to the variable ‘page’</span></div><div class="line"> page = urllib2.urlopen(pg)</div><div class="line"><span class="comment"># parse the html using beautiful soap and store in variable `soup`</span></div><div class="line"> soup = BeautifulSoup(page, ‘html.parser’)</div><div class="line"><span class="comment"># Take out the &lt;div&gt; of name and get its value</span></div><div class="line"> name_box = soup.find(‘h1’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span> ‘name’&#125;)</div><div class="line"> name = name_box.text.strip() <span class="comment"># strip() is used to remove starting and trailing</span></div><div class="line"><span class="comment"># get the index price</span></div><div class="line"> price_box = soup.find(‘div’, attrs=&#123;‘<span class="class"><span class="keyword">class</span>’:</span>’price’&#125;)</div><div class="line"> price = price_box.text</div><div class="line"><span class="comment"># save the data in tuple</span></div><div class="line"> data.append((name, price))</div></pre></td></tr></table></figure>
<p>同时，更改存储csv文件部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># open a csv file with append, so old data will not be erased</span></div><div class="line"><span class="keyword">with</span> open(‘index.csv’, ‘a’) <span class="keyword">as</span> csv_file:</div><div class="line"> writer = csv.writer(csv_file)</div><div class="line"> <span class="comment"># The for loop</span></div><div class="line"> <span class="keyword">for</span> name, price <span class="keyword">in</span> data:</div><div class="line"> writer.writerow([name, price, datetime.now()])</div></pre></td></tr></table></figure>
<p>现在实现一次爬取两个股指价格。</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/how-apache-flink-enables-new-streaming-applications/" itemprop="url">
                  Flink开启流处理技术新潮流：解决流处理event time和消息乱序
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:24:57+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>写在之前：此文翻译自：<a href="http://data-artisans.com/how-apache-flink-enables-new-streaming-applications-part-1" target="_blank" rel="external">how-apache-flink-enables-new-streaming-applications</a>，做了少许改动，感谢原作者。</em></p>
<p>速度是成功的一重要要素，流处理技术的速度使得其越来越受青睐。在现实世界中，数据产品总是以持续不断的处理面目示人，比如，web服务日志，移动应用用户行为，或者传感器数据。</p>
<p>到目前为止，大部分数据处理架构技术栈都建立在有限的、静态的数据假设之上。现代流处理技术在不断地努力，通过模拟和处理现实世界的event，而最理想的模拟情况是把数据看作“streams”。Flink不但实现“streams”流，而且具有开创性的技术点。本篇先来讲述Flink解决消息乱序和event time窗口。</p>
<h5 id="消息乱序和event-time窗口"><a href="#消息乱序和event-time窗口" class="headerlink" title="消息乱序和event time窗口"></a>消息乱序和event time窗口</h5><p>在讨论解决消息乱序问题之前，需先定义时间和顺序。在流处理中，时间的概念有两个：</p>
<ul>
<li><strong>Event time </strong>：Event time是事件发生的时间，经常以时间戳表示，并和数据一起发送。带时间戳的数据流有，Web服务日志、监控agent的日志、移动端日志等；</li>
<li><strong>Processing time </strong> ：Processing time是处理事件数据的服务器时间，一般是运行流处理应用的服务器时钟。</li>
</ul>
<p>许多流处理场景中，事件发生的时间和事件到达待处理的消息队列时间有各种延迟：</p>
<ol>
<li>各种网络延迟；</li>
<li>数据流消费者导致的队列阻塞和反压影响；</li>
<li>数据流毛刺，即，数据波动；</li>
<li>事件生产者（移动设备、传感器等）离线；</li>
</ol>
<p>上述诸多原因会导致队列中的消息频繁乱序。事件发生的时间和事件到达待处理的消息队列时间的不同随着时间在不断变化，这常被称为时间偏移（<em>event time skew</em>），表示成：<em>“processing time – event time”</em>。</p>
<p>对大部分应用来讲，基于事件的创建时间分析数据比基于事件的处理时间分析数据要更有意义。Flink允许用户定义基于事件时间（event time）的窗口，而不是处理时间。</p>
<p>Flink使用<em>事件时间 clock</em> 来跟踪事件时间，其是以<em>watermarks</em>来实现的。<em>watermarks</em>是Flink 源流基于事件时间点生成的特殊事件。 <em>T</em> 时间点的<em>watermarks</em>意味着，小于 T 的时间戳的事件不会再到达。Flink的所有操作都基于<em>watermarks</em>来跟踪事件时间。</p>
<p>下图描述Flink是如何计算事件时间窗口。当<em>watermarks</em>到达时窗口计算会被触发，并更新事件时间clock：</p>
<p>很明显，左上角<em>watermarks</em> W(4)快要到达，出现计算窗口T1-T4；右上角因为消息有乱序（事件时间为3的事件排在事件时间为7的后面），同时出现两个计算窗口T1-T4和T4-T8；左下角<em>watermarks</em> W(4)触发计算窗口演化，小于事件时间4的事件不再到达；右下角参考前面解读。</p>
<p>基于事件时间的Pipeline会产生更精确的结果，因为一旦有相应事件时间的事件到达会尽快计算；而相对于周期性的批量处理来讲，基于事件时间的数据流pipeline会更早的计算出结果，并且更精确（批量处理不能很好的处理跨batch的消息乱序）。</p>
<h5 id="结合事件时间和实时pipeline"><a href="#结合事件时间和实时pipeline" class="headerlink" title="结合事件时间和实时pipeline"></a>结合事件时间和实时pipeline</h5><p>事件时间pipeline会因为必要的事件时间过程而导致一定的延迟。有时延迟太大导致无法获得实时结果，这时就得增加延迟短的结果。</p>
<p>Flink是一个流处理框架，能毫秒级处理事件，它能在同一个应用中综合低延迟的实时pipeline和事件时间pipeline，列子如下：</p>
<ol>
<li>基于单个事件的低延迟报警。如果某类事件被识别，需要发出报警信息；</li>
<li>基于处理时间窗口的实时dashboard，能够聚合秒级的事件数；</li>
<li>基于事件时间的精确统计</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Main entry point.</div><div class="line">    */</div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">       </div><div class="line">       <span class="comment">// create environment and configure it</span></div><div class="line">       <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</div><div class="line">       env.registerType(Statistic.class);</div><div class="line">       env.registerType(SensorReading.class);</div><div class="line">       </div><div class="line">       env.setParallelism(<span class="number">4</span>);</div><div class="line">       env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</div><div class="line">       </div><div class="line">       </div><div class="line">       <span class="comment">// create a stream of sensor readings, assign timestamps, and create watermarks</span></div><div class="line">       DataStream&lt;SensorReading&gt; readings = env</div><div class="line">               .addSource(<span class="keyword">new</span> SampleDataGenerator())</div><div class="line">               .assignTimestamps(<span class="keyword">new</span> ReadingsTimestampAssigner());</div><div class="line">       </div><div class="line">       <span class="comment">// path (1) - low latency event-at a time filter</span></div><div class="line">       readings</div><div class="line">               .filter(reading -&gt; reading.reading() &gt; <span class="number">100.0</span>)</div><div class="line">               .map( reading -&gt; <span class="string">"-- ALERT -- Reading above threshold: "</span> + reading )</div><div class="line">               .print();</div><div class="line">       </div><div class="line">       <span class="comment">// path (2) - processing time windows: Compute max readings per sensor group</span></div><div class="line">       </div><div class="line">       <span class="comment">// because the default stream time is set to Event Time, we override the trigger with a</span></div><div class="line">       <span class="comment">// processing time trigger</span></div><div class="line">       </div><div class="line">       readings</div><div class="line">               .keyBy( reading -&gt; reading.sensorGroup() )</div><div class="line">               .window(TumblingTimeWindows.of(Time.seconds(<span class="number">5</span>)))</div><div class="line">               .trigger(ProcessingTimeTrigger.create())</div><div class="line">               .fold(<span class="keyword">new</span> Statistic(), (curr, next) -&gt;</div><div class="line">                       <span class="keyword">new</span> Statistic(next.sensorGroup(), next.timestamp(), Math.max(curr.value(), next.reading())))</div><div class="line">               </div><div class="line">               .map(stat -&gt; <span class="string">"PROC TIME - max for "</span> + stat)</div><div class="line">               .print();</div><div class="line">       </div><div class="line">       <span class="comment">// path (3) - event time windows: Compute average reading over sensors per minute</span></div><div class="line">       </div><div class="line">       <span class="comment">// we use a WindowFunction here, to illustrate how to get access to the window object</span></div><div class="line">       <span class="comment">// that contains bounds, etc.</span></div><div class="line">       <span class="comment">// Pre-aggregation is possible by adding a pre-aggregator ReduceFunction</span></div><div class="line">       </div><div class="line">       readings</div><div class="line">               <span class="comment">// group by, window and aggregate </span></div><div class="line">               .keyBy(reading -&gt; reading.sensorId() )</div><div class="line">               .timeWindow(Time.minutes(<span class="number">1</span>), Time.seconds(<span class="number">10</span>))</div><div class="line">               .apply(<span class="keyword">new</span> WindowFunction&lt;SensorReading, Statistic, String, TimeWindow&gt;() &#123;</div><div class="line"></div><div class="line">                   <span class="meta">@Override</span></div><div class="line">                   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(String id, TimeWindow window, Iterable&lt;SensorReading&gt; values, Collector&lt;Statistic&gt; out)</span> </span>&#123;</div><div class="line">                       <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">                       <span class="keyword">double</span> agg = <span class="number">0.0</span>;</div><div class="line">                       <span class="keyword">for</span> (SensorReading r : values) &#123;</div><div class="line">                           agg += r.reading();</div><div class="line">                           count++;</div><div class="line">                       &#125;</div><div class="line">                       out.collect(<span class="keyword">new</span> Statistic(id, window.getStart(), agg / count));</div><div class="line">                   &#125;</div><div class="line">               &#125;)</div><div class="line">               </div><div class="line">               .map(stat -&gt; <span class="string">"EVENT TIME - avg for "</span> + stat)</div><div class="line">               .print();</div><div class="line">       </div><div class="line">       env.execute(<span class="string">"Event time example"</span>);</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>Flink提供的窗口触发条件包括处理时间clock，事件时间clock，以及数据流内容。</p>
<h5 id="Flink是如何度量时间？"><a href="#Flink是如何度量时间？" class="headerlink" title="Flink是如何度量时间？"></a>Flink是如何度量时间？</h5><p>下面看下Flink是如何处理时间的，在这点上与其它老的流处理系统有啥不同。</p>
<p>一般意义上讲，时间是用clock度量的。最简单的clock称为<em>wall clock</em>，它是集群中服务器执行流处理作业的间隔clock。<em>wall clock</em>是用来跟踪处理时间的。</p>
<p>为了跟踪事件时间，我们需要集群机器间相同的clock。Flink是通过<em>watermarks</em>机制实现的。一个<em>watermarks</em>是指在真实事件流时间点发生的事件（比如，上午10点），那么到现在为止上午10点前的事件不会再到达。事件时间clock（<em>event time clock</em>）跟踪时间比wall clock要粗粒度，但是更准确。</p>
<p>还有第三种clock，叫做<em>system clock</em>。它是用来保证流处理系统的“exactly-once“语义的。Flink跟踪作业的处理是通过<em>barriers</em>（栏栅），并进行snapshot。<em>barriers</em>与<em>watermarks</em>类似，不同之处在于，<em>barriers</em>是由Flink的master机器的<em>wall clock</em> 生成， 而<em>watermarks</em>是由真实世界的时间生成。同样，Spark Streaming的micro-batche schedule是基于Spark receiver的<em>wall clock</em> 。</p>
<p>下图完美展现刚才讲的各种时间：</p>
<p>Worker 1和Worker 2机器上并行执行对数据源和窗口的操作作业。事件上的数字代表时间戳，方块的颜色代表不同的key（灰色流向窗口1，紫色流向窗口2）。数据源从队列中读取事件（有分区，通过key分区），把他们分发到正确的窗口。窗口定义为基于事件时间的时间窗口（Flink包含时间窗口和count窗口）。我能看到Worker 1、Worker 2和Master机器的<em>wall clock</em>不同（缺乏时间同步，具体看ntp），分别为10，8，7。数据源发出<em>watermarks</em>，当前的<em>watermarks</em>时间戳为4。这意味着，event time clock是4，这时进行并行计算。Master（JobManager）对数据源做<em>barriers</em>，并对计算做snapshot。系统时间此时为7，checkpoint为第七个。</p>
<p>下面对流处理框架中的三种clock进行总结：</p>
<ul>
<li><strong>event time clock</strong>：度量事件流的时间，粗粒度；</li>
<li><strong>system clock</strong>：度量计算的过程。实际上是协调者机器的<em>wall clock</em>；</li>
<li><strong>wall clock </strong>：度量处理时间。</li>
</ul>
<p>下面也给出老的流处理系统的弊端：</p>
<ol>
<li>计算不准确：因为真实世界的事件发生顺序与处理的顺序经常不一致；</li>
<li>计算结果强依赖当前时间；</li>
<li>系统参数配置会影响程序的语义：比如，增加checkpoin的间隔。</li>
</ol>
<p>老的流处理系统的这些缺点让它们没法获得准确的结果（至少是可控的准确度）。</p>
<p>而Flink完全分离这三种clock：</p>
<ol>
<li>基于<em>event time clock</em>的<em>watermarks</em>跟踪事件流时间，允许用户定义基于事件时间的窗口；</li>
<li><em>system clock</em>与<em>event time clock</em>完全解藕，跟踪计算过程和全局snapshot，不对外暴露api，仅仅用来分布式系统的协调；</li>
<li>处理时间是用的机器的<em>wall clock</em>，暴露给用户支持处理时间窗口。</li>
</ol>
<p>相关文章：</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/kafka-cluster-producer/" itemprop="url">
                  Kafka使用总结：Producer
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:24:30+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Kafka作为消息中间件是各公司平台架构绕不开的话题。</p>
<p>不管你是把Kafka作为队列，还是消息通道，都需要在应用中通过producer写数据到Kafka，再用consumer从Kafka中消费。应用往Kafka写数据的原因有很多：用户行为分析、日志存储、异步通信等。多样化的使用场景带来了多样化的需求：消息是否能丢失？是否容忍重复？消息的吞吐量？消息的延迟？</p>
<p>这么苛刻的要求Kafka能满足吗？</p>
<p><img src="http://img1.ph.126.net/jOA6c9KB5qbpivkjsYGDwg==/6632071619817192826.png" alt="image"></p>
<h5 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h5><p>首先，创建ProducerRecord必须包含Topic和Value，key和partition可选。然后，序列化key和value对象为ByteArray，并发送到网络。</p>
<p>接下来，消息发送到partitioner。如果创建ProducerRecord时指定了partition，此时partitioner啥也不用做，简单的返回指定的partition即可。如果未指定partition，partitioner会基于ProducerRecord的key生成partition。producer选择好partition后，增加record到对应topic和partition的batch record。最后，专有线程负责发送batch record到合适的Kafka broker。</p>
<p>当broker收到消息时，它会返回一个应答（response）。如果消息成功写入Kafka，broker将返回RecordMetadata对象（包含topic，partition和offset）；相反，broker将返回error。这时producer收到error会尝试重试发送消息几次，直到producer返回error。</p>
<h5 id="Producer实战"><a href="#Producer实战" class="headerlink" title="Producer实战"></a>Producer实战</h5><h6 id="构造Kafka-Producer"><a href="#构造Kafka-Producer" class="headerlink" title="构造Kafka Producer"></a>构造Kafka Producer</h6><p>创建Properties对象，配置producer参数。根据Properties创建producer对象。Kafka producer必选参数有3个：</p>
<ul>
<li><em>bootstrap.servers</em> ：Kafka broker的列表，包含host和port。此处不必包含Kafka集群所有的broker，因为producer会通过其它broker查询到所需信息。但至少包含2个broker；</li>
<li><em>key.serializer</em>：序列化key参数，值为类名，org.apache.kafka.common.serialization.Serializer接口的实现；</li>
<li><em>value.serializer</em>：序列化value参数，值为类名，使用方式同<em>key.serializer</em>。</li>
</ul>
<p>最简代码实现如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">private Properties kafkaProps = new Properties();</div><div class="line">kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");</div><div class="line">kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.String-</div><div class="line">Serializer");</div><div class="line">kafkaProps.put("value.serializer", "org.apache.kafka.common.serializa-</div><div class="line">tion.StringSerializer");</div><div class="line">producer = new KafkaProducer&lt;String, String&gt;(kafkaProps);</div></pre></td></tr></table></figure>
<p>创建Properties对象，key和value为String类型，选用Kafka自带的StringSerializer。通过属性配置可以控制Producer的行为。</p>
<p>实例化producer后，接着发送消息。这里主要有3种发送消息的方法：</p>
<ul>
<li>立即发送：只管发送消息到server端，不care消息是否成功发送。大部分情况下，这种发送方式会成功，因为Kafka自身具有高可用性，producer会自动重试；但有时也会丢失消息；</li>
<li>同步发送：通过send()方法发送消息，并返回Future对象。get()方法会等待Future对象，看send()方法是否成功；</li>
<li>异步发送：通过带有回调函数的send()方法发送消息，当producer收到Kafka broker的response会触发回调函数</li>
</ul>
<p>以上所有情况，一定要时刻考虑发送消息可能会失败，想清楚如何去处理异常。</p>
<p>通常我们是一个producer起一个线程开始发送消息。为了优化producer的性能，一般会有下面几种方式：单个producer起多个线程发送消息；使用多个producer。</p>
<p>下面开始详细展示上面所提到的三种发送消息的方法，以及各种类型错误的处理方式。</p>
<h6 id="发送消息到Kafka"><a href="#发送消息到Kafka" class="headerlink" title="发送消息到Kafka"></a>发送消息到Kafka</h6><p>最简单的方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ProducerRecord&lt;String, String&gt; record =</div><div class="line">            <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Precision Products"</span>,<span class="string">"France"</span>);</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      producer.send(record);</div><div class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>创建ProducerRecord对象，Producer使用send()方法发送ProducerRecord。send()方法会返回带有RecordMetadata的Future对象，这里只简单的忽略返回值，所以我们并不会知道消息是否发送成功；</p>
<p>但即使如此简单，Producer发送消息到Kafka也仍然得处理些异常：当序列化消息失败会抛出SerializationException；buffer溢出会抛出BufferExhaustedException；当发送线程终止会抛出InterruptException。</p>
<h6 id="同步发消息"><a href="#同步发消息" class="headerlink" title="同步发消息"></a>同步发消息</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ProducerRecord&lt;String, String&gt; record =</div><div class="line">            <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Precision Products"</span>, <span class="string">"France"</span>);</div><div class="line">producer.send(record).get();</div></pre></td></tr></table></figure>
<p>这里，我们使用Future.get()方法等待Kafka的状态返回。Producer可以实现自己的Future来处理Kafka broker返回的异常。如果Producer发送消息成功，它会返回RecordMetadata对象（可用来检索消息的offset）。</p>
<p>Kafka Producer一般有两类错误。可重试错误会通过重试发送消息解决。比如，连接重连可解决连接错误；partition重新选举leader可解决“no leader”错误。Kafka Producer能配置重试次数，超过重试次数还不能解决的会抛出错误。另外一类就是不能通过重试处理的错误，比如，消息大小太大，这种情况下Kafka Producer会立即报错。</p>
<h6 id="异步发送消息"><a href="#异步发送消息" class="headerlink" title="异步发送消息"></a>异步发送消息</h6><p>如果应用和Kafka集群间的网络质量太差，那么同步发送消息的方式发送每条消息后需要等待较长时间才收到应答。这对高并发海量消息发送简直就是灾难，因为等待应答的时间远超过消息发送时间。另外，有些app压根就不要求返回值。况且，即使发送消息失败了，只要写下对应的错误日志即可。</p>
<p>为了异步发送消息，同时可以处理错误。Producer支持带有回调函数的发送消息方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoProducerCallback</span> <span class="keyword">implements</span> <span class="title">Callback</span> </span>&#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</div><div class="line">         <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</div><div class="line">             e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">&#125; &#125;</div><div class="line"></div><div class="line">ProducerRecord&lt;String, String&gt; record =</div><div class="line">            <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Biomedical Materials"</span>, <span class="string">"USA"</span>);</div><div class="line">producer.send(record, <span class="keyword">new</span> DemoProducerCallback());</div></pre></td></tr></table></figure>
<p>使用回调函数的前提是实现org.apache.kafka.clients.producer.Callback 接口。如果Kafka返回错误，onCompletion捕获到非null异常。示例代码仅仅打印出了异常信息，实际应用开发需根据实际情况添加业务逻辑处理。</p>
<h5 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h5><p>在前面的列子中，可看出Producer配置必须指定序列化方法（serializer，默认是String serializer）。</p>
<p>这里将讲解如何构建定制化的序列化器，然后介绍Avro序列化器。</p>
<h6 id="定制序列化器"><a href="#定制序列化器" class="headerlink" title="定制序列化器"></a>定制序列化器</h6><p>当你需要发送到Kafka的对象非String和Integer，那你要么自己实现对应的序列化器，要么使用像Avro、Thrift或者Protobuf之类的业界通用的序列化库。这里强烈推荐使用这些工业化的通用的序列化库。</p>
<p>为了让大家理解序列化器的工作原理，这里还是先讲讲如何构建定制化的序列化器。下面先建一个简单的Customer类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</div><div class="line">            <span class="keyword">private</span> <span class="keyword">int</span> customerID;</div><div class="line">            <span class="keyword">private</span> String customerName;</div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">(<span class="keyword">int</span> ID, String name)</span> </span>&#123;</div><div class="line">                    <span class="keyword">this</span>.customerID = ID;</div><div class="line">                    <span class="keyword">this</span>.customerName = name;</div><div class="line">&#125;</div><div class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getID</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> customerID;</div><div class="line">&#125;</div><div class="line">      <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">       <span class="keyword">return</span> customerName;</div><div class="line">&#125; &#125;</div></pre></td></tr></table></figure>
<p>接着创建Customer类的序列化器：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.kafka.common.errors.SerializationException;</div><div class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</div><div class="line"><span class="keyword">import</span> java.util.Map;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerSerializer</span> <span class="keyword">implements</span> <span class="title">Serializer</span>&lt;<span class="title">Customer</span>&gt; </span>&#123;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map configs, <span class="keyword">boolean</span> isKey)</span> </span>&#123;</div><div class="line">   <span class="comment">// nothing to configure</span></div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">  We are serializing Customer as:</div><div class="line">  4 byte int representing customerId</div><div class="line">  4 byte int representing length of customerName in UTF-8 bytes (0 if name is</div><div class="line">Null)</div><div class="line">  N bytes representing customerName in UTF-8</div><div class="line">  **/</div><div class="line">  <span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String topic, Customer data) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">byte</span>[] serializedName;</div><div class="line">                  <span class="keyword">int</span> stringSize;</div><div class="line">      <span class="keyword">if</span> (data == <span class="keyword">null</span>)</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">      <span class="keyword">else</span> &#123;</div><div class="line">                                <span class="keyword">if</span> (data.getName() != <span class="keyword">null</span>) &#123;</div><div class="line">         serializeName = data.getName().getBytes(<span class="string">"UTF-8"</span>);</div><div class="line">         stringSize = serializedName.length;</div><div class="line">                                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                                  serializedName = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>];</div><div class="line">                                  stringSize = <span class="number">0</span>;</div><div class="line">                                &#125; </div><div class="line">      &#125;</div><div class="line">      </div><div class="line">      ByteBuffer buffer = ByteBuffer.allocate(<span class="number">4</span> + <span class="number">4</span> + stringSize);</div><div class="line">      buffer.putInt(data.getID());</div><div class="line">      buffer.putInt(stringSize);</div><div class="line">      buffer.put(serializedName);</div><div class="line">      <span class="keyword">return</span> buffer.array();</div><div class="line">          &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Error when serializing Customer to byte[] "</span> + e);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// nothing to close</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h6 id="Avro的序列化"><a href="#Avro的序列化" class="headerlink" title="Avro的序列化"></a>Avro的序列化</h6><p>Avro详细说明见官方文档，这里只列出部分要用到的特性。</p>
<p>Avro Schema是用Json描述，如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"> &#123;<span class="attr">"namespace"</span>: <span class="string">"customerManagement.avro"</span>,</div><div class="line">     <span class="attr">"type"</span>: <span class="string">"record"</span>,</div><div class="line">     <span class="attr">"name"</span>: <span class="string">"Customer"</span>,</div><div class="line">     <span class="attr">"fields"</span>: [</div><div class="line">         &#123;<span class="attr">"name"</span>: <span class="string">"id"</span>, <span class="attr">"type"</span>: <span class="string">"int"</span>&#125;,</div><div class="line">         &#123;<span class="attr">"name"</span>: <span class="string">"name"</span>,  <span class="attr">"type"</span>: <span class="string">"string"</span>&#125;,</div><div class="line">         &#123;<span class="attr">"name"</span>: <span class="string">"email"</span>, <span class="attr">"type"</span>: [<span class="string">"null"</span>, <span class="string">"string"</span>], <span class="attr">"default"</span>: <span class="string">"null"</span>&#125;</div><div class="line">] &#125;</div></pre></td></tr></table></figure>
<p>Avro依赖模式(Schema)来实现数据结构定义，所以读写Avro文件都得依赖其Schema。Kafka中<a href="http://docs.confluent.io/3.0.0/schema-registry/docs/intro.html#schemaregistry-intro" target="_blank" rel="external">Schema Registry</a>提供元数据的存储和解析。那Producer的序列化和Consumer的反序列化都会去Schema Registry读取对应的Schema。</p>
<p><img src="http://img0.ph.126.net/X0tYnyzV8cKuoxOvK1w4rw==/6632381682093836586.png" alt="image"></p>
<p>Avro的使用有两种：一种是使用Avro Schema生成的类（官方提供生成工具，比如，avro-tools-1.7.0.jar）；一种是直接Avro Schema。Kafka Producer使用Avro序列化器的方式与其它序列化器相同。下面先说使用Avro Schema生成的类的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">    Properties props = <span class="keyword">new</span> Properties();</div><div class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">    props.put(<span class="string">"key.serializer"</span>, <span class="string">"io.confluent.kafka.serializers.KafkaAvroSerializer"</span>);</div><div class="line">    props.put(<span class="string">"value.serializer"</span>, <span class="string">"io.confluent.kafka.serializers.KafkaAvroSerializer"</span>);</div><div class="line">    props.put(<span class="string">"schema.registry.url"</span>, schemaUrl);</div><div class="line">    String topic = <span class="string">"customerContacts"</span>;</div><div class="line">    <span class="keyword">int</span> wait = <span class="number">500</span>;</div><div class="line">    Producer&lt;String, Customer&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, Customer&gt;(props);</div><div class="line">    <span class="comment">// We keep producing new events until someone ctrl-c</span></div><div class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">        Customer customer = CustomerGenerator.getNext();</div><div class="line">        System.out.println(<span class="string">"Generated customer "</span> + customer.toString());</div><div class="line">        ProducerRecord&lt;String, Customer&gt; record =</div><div class="line">                            <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, customer.getId(), customer);</div><div class="line">        producer.send(record);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中，schema.registry.url是schema存储的位置，<em>KafkaAvroSerializer</em> 是Avro的序列化器，<em>Customer</em> 是生成的类。</p>
<p>如果你想直接使用Avro Schema，方法如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">Properties props = new Properties();</div><div class="line">props.put("bootstrap.servers", "localhost:9092");</div><div class="line">props.put("key.serializer", "io.confluent.kafka.serializers.KafkaAvroSerializer");</div><div class="line">props.put("value.serializer", "io.confluent.kafka.serializers.KafkaAvroSerializer");</div><div class="line">props.put("schema.registry.url", url);</div><div class="line"></div><div class="line">String schemaString = "&#123;\"namespace\": \"customerManagement.avro\",</div><div class="line">  \"type\": \"record\", " +</div><div class="line">                               "\"name\": \"Customer\"," +</div><div class="line">                               "\"fields\": [" +</div><div class="line">                                "&#123;\"name\": \"id\", \"type\": \"int\"&#125;," +</div><div class="line">                                "&#123;\"name\": \"name\", \"type\": \"string\"&#125;," +</div><div class="line">                                "&#123;\"name\": \"email\", \"type\": [\"null\",\"string</div><div class="line">    \"], \"default\":\"null\" &#125;" +</div><div class="line">                               "]&#125;";</div><div class="line"></div><div class="line">Producer&lt;String, GenericRecord&gt; producer = new KafkaProducer&lt;String, GenericRecord&gt;(props);</div><div class="line"></div><div class="line">Schema.Parser parser = new Schema.Parser();</div><div class="line">Schema schema = parser.parse(schemaString);</div><div class="line"></div><div class="line">for (int nCustomers = 0; nCustomers &lt; customers; nCustomers++) &#123;</div><div class="line">  String name = "exampleCustomer" + nCustomers;</div><div class="line">  String email = "example " + nCustomers + "@example.com";</div><div class="line">  GenericRecord customer = new GenericData.Record(schema);</div><div class="line">  customer.put("id", nCustomer);</div><div class="line">  customer.put("name", name);</div><div class="line">  customer.put("email", email);</div><div class="line">  ProducerRecord&lt;String, GenericRecord&gt; data =</div><div class="line">    new ProducerRecord&lt;String, GenericRecord&gt;("customerContacts", name, customer);</div><div class="line">  producer.send(data);</div><div class="line">&#125; &#125;</div></pre></td></tr></table></figure>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/28/htop-tools/" itemprop="url">
                  Linux性能利器Htop：完胜top、strace
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-28T15:07:52+08:00" content="2017-12-28">
              2017-12-28
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>写在之前：此文翻译自：<a href="https://peteris.rocks/blog/htop，做了少许改动，感谢原作者。" target="_blank" rel="external">https://peteris.rocks/blog/htop，做了少许改动，感谢原作者。</a></em></p>
<p>长久以来，我只知Linux有个神器htop，却不知道htop的各项指标的内涵。</p>
<p>比如，2核的服务器 CPU利用率为 50%，那为啥load average 却显示 1.0？那接下来开始捋捋。。。</p>
<p>俗话说得好，好记性不如个烂笔头。</p>
<h5 id="Htop-on-CentOS"><a href="#Htop-on-CentOS" class="headerlink" title="Htop on CentOS"></a>Htop on CentOS</h5><p>来个htop全身照：</p>
<p><img src="http://img2.ph.126.net/r9cGoR7qNxoukqdaBRgBAQ==/6632126595396926285.png" alt="image"></p>
<ul>
<li>Uptime</li>
</ul>
<p>uptime：系统运行的时长。</p>
<p>当然，你可以用<code>uptime</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ uptime</div><div class="line"> 12:17:58 up 111 days, 31 min,  1 user,  load average: 0.00, 0.01, 0.05</div></pre></td></tr></table></figure>
<p><code>uptime</code>从 <code>/proc/uptime</code>文件获取信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">9592411.58 9566042.33</div></pre></td></tr></table></figure>
<p>前者数字（9592411.58）代表系统运行的秒值，后者（9566042.33）代表服务器空闲秒数。一般多核系统后者秒值会比系统的uptime值大，因为它是取和。作者是怎么知道这个原因的呢？通过跟踪 <code>uptime</code> 程序运行打开的文件，这里是用的 <code>strace</code> 工具：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">strace uptime</div></pre></td></tr></table></figure>
<p>从strace输出中<code>grep</code>查找系统调用的<code>open</code> 函数。由于strace标准输出内容较多，可以使用<code>2&gt;&amp;1</code>重定向：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ strace uptime 2&gt;&amp;1 | grep open</div><div class="line">...</div><div class="line">open(&quot;/proc/uptime&quot;, O_RDONLY)          = 3</div><div class="line">open(&quot;/var/run/utmp&quot;, O_RDONLY|O_CLOEXEC) = 4</div><div class="line">open(&quot;/proc/loadavg&quot;, O_RDONLY)         = 4</div></pre></td></tr></table></figure>
<p>其中，包括前面提到的 <code>/proc/uptime</code>文件。这说明我们可以使用 <code>strace -e open uptime</code>来代替<code>strace uptime 2&gt;&amp;1 | grep open</code>。Linux的<code>uptime</code>命令提供易读、宜用的方法。</p>
<ul>
<li>Load average</li>
</ul>
<p>除了uptime，有三个数字表示 load average：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ uptime</div><div class="line"> 12:59:09 up 32 min,  1 user,  load average: 0.00, 0.01, 0.03</div></pre></td></tr></table></figure>
<p>load average值是从 <code>/proc/loadavg</code>文件获得，同时你也可以用 <code>strace</code> 验证。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ cat /proc/loadavg</div><div class="line">0.00 0.01 0.03 1/120 1500</div></pre></td></tr></table></figure>
<p>前三个数字分别表示最近1分钟、5分钟、15分钟的CPU和IO的利用率。第四行显示当前正在运行的进程数和进程总数，最后一行显示最近使用的进程ID。</p>
<p>下面讲下进程ID。当你启动一个新进程，它将会分到一个ID数字。进程ID通常是递增的，除非进程退出后进程ID重新复用。特殊进程ID <strong>1</strong> 是属于<code>/sbin/init</code> ，系统启动时即分配。</p>
<p>让我们再来看下 <code>/proc/loadavg</code>文件的内容，然后后台启动 <code>sleep</code> 命令，这时会输出进程ID。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ cat /proc/loadavg</div><div class="line">0.00 0.01 0.03 1/123 1566</div><div class="line">$ sleep 10 &amp;</div><div class="line">[1] 1567</div></pre></td></tr></table></figure>
<p>所以，<em>1/123</em> 代表一个进程正在运行，总共有123个进程运行过。</p>
<p>当运行<code>cat /dev/urandom &gt; /dev/null</code> （重复生成随机数）时，你会发现有 2 个进程在运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ cat /dev/urandom &gt; /dev/null &amp;</div><div class="line">[1] 1639</div><div class="line">$ cat /proc/loadavg</div><div class="line">1.00 0.69 0.35 2/124 1679</div></pre></td></tr></table></figure>
<p>这里的两个进程是：随机数生成、<code>cat /proc/loadavg</code>，同时load average值也在增加。</p>
<p>System load average是runnable或uninterruptable状态的进程数的平均数。所以上面的 load average为 1（平均1个运行的进程），是因为作者演示的服务器是单核CPU，一次跑一个进程那CPU的利用率是100%。如果服务器是双核，那CPU利用率就是50%。双核CPU的利用率如果是100%，那load average 将会是2.0。CPU的核数可以从htop的左上角看到，或者运行 <code>nproc</code>。</p>
<ul>
<li>Processes</li>
</ul>
<p>在htop的右上角显示进程数和多少个进程正在运行。但是htop使用 <em>Tasks</em> 代表进程（注：<em>Tasks</em> 是进程的一个别名）。</p>
<p>在htop中，使用键盘上的<code>Shift</code>+<code>H</code>组合键也可轻松看到线程数<em>Tasks: 23, 10 thr</em>，使用<code>Shift</code>+<code>K</code>组合键可以看到内核线程数，<em>Tasks: 23, 40 kthr</em>。</p>
<ul>
<li>Process ID / PID</li>
</ul>
<p>每个进程启动都会分配一个唯一的进程ID，称作进程ID或者PID。如果你在<em>bash</em>中使用 (<code>&amp;</code>)在后台执行，你将会看到输出的PID。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sleep 1000 &amp;</div><div class="line">[1] 12503</div></pre></td></tr></table></figure>
<p>如果你手滑没看到，那也可以在<em>bash</em>中使用 <code>$!</code>内建变量查看到最近一次后台运行的PID：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ echo $!</div><div class="line">12503</div></pre></td></tr></table></figure>
<p>进程ID是非常有用的，具体为什么可以看维基百科。</p>
<p><code>procfs</code>是伪文件系统，procfs可以让用户的程序通过读取文件的方法从Linux内核中获取信息。它经常被挂载在 <code>/proc/</code>下，伪装的看起来像个正规文件目录，你也可以使用 <code>ls</code> 和 <code>cd</code>命令。</p>
<p>某进程相关的所有信息都放在 <code>/proc/&lt;pid&gt;/</code>下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ ls /proc/12503</div><div class="line">attr        coredump_filter  fdinfo     maps        ns             personality  smaps    task</div><div class="line">auxv        cpuset           gid_map    mem         numa_maps      projid_map   stack    uid_map</div><div class="line">cgroup      cwd              io         mountinfo   oom_adj        root         stat     wchan</div><div class="line">clear_refs  environ          limits     mounts      oom_score      schedstat    statm</div><div class="line">cmdline     exe              loginuid   mountstats  oom_score_adj  sessionid    status</div><div class="line">comm        fd               map_files  net         pagemap        setgroups    syscall</div></pre></td></tr></table></figure>
<p>比如，  /proc/\<pid>/cmdline  会让你知道这个进程是如何启动的：</pid></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ cat /proc/12503/cmdline</div><div class="line">sleep1000$</div></pre></td></tr></table></figure>
<p>正确的查看姿势是（因为命令是用<em>\0</em> 分隔）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ od -c /proc/12503/cmdline</div><div class="line">0000000   s   l   e   e   p  \0   1   0   0   0  \0</div><div class="line">0000013</div></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ tr &apos;\0&apos; &apos;\n&apos; &lt; /proc/12503/cmdline</div><div class="line">sleep</div><div class="line">1000</div><div class="line">$ strings /proc/12503/cmdline</div><div class="line">sleep</div><div class="line">1000</div></pre></td></tr></table></figure>
<p>进程的进程目录还包含有链接（link），比如： <code>cwd</code>指向工作目录，<code>exe</code>指向可执行的二进制文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ls -l /proc/12503/&#123;cwd,exe&#125;</div><div class="line">lrwxrwxrwx 1 ubuntu ubuntu 0 Jul  6 10:10 /proc/12503/cwd -&gt; /home/username</div><div class="line">lrwxrwxrwx 1 ubuntu ubuntu 0 Jul  6 10:10 /proc/12503/exe -&gt; /bin/sleep</div></pre></td></tr></table></figure>
<p>以上就是<code>htop</code>，<code>top</code>， <code>ps</code>这些诊断工具是为啥可以获取到一个进程的详细信息的，/proc/\<pid>/\<file>。</file></pid></p>
<ul>
<li>Process tree</li>
</ul>
<p>在htop中使用<code>F5</code> 即可看到进程树，当然也可以用<code>ps f</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ ps f</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line">12472 pts/0    Ss     0:00 -bash</div><div class="line">12684 pts/0    R+     0:00  \_ ps f</div></pre></td></tr></table></figure>
<p>或者 <code>pstree</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ pstree -a</div><div class="line">init</div><div class="line">  ├─atd</div><div class="line">  ├─cron</div><div class="line">  ├─sshd -D</div><div class="line">  │   └─sshd</div><div class="line">  │       └─sshd</div><div class="line">  │           └─bash</div><div class="line">  │               └─pstree -a</div><div class="line">...</div></pre></td></tr></table></figure>
<p>从这里你就可以知道为啥 <code>bash</code> 或者 <code>sshd</code> 是其它进程的父进程。</p>
<p> <code>/sbin/init</code> 作为系统启动进程，进程ID为1，接着是SSH的守护进程 <code>sshd</code>（当你用ssh连接到服务器），接着是 <code>bash</code> shell。</p>
<ul>
<li>Process user</li>
</ul>
<p>每个进程属于一个user，user以数值ID代表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sleep 1000 &amp;</div><div class="line">[1] 2045</div><div class="line">$  grep Uid /proc/2045/status</div><div class="line">Uid:    1000    1000    1000    1000</div></pre></td></tr></table></figure>
<p>可以用<code>id</code>命令发现更多关于此user的信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ id 1000</div><div class="line">uid=1000(ubuntu) gid=1000(ubuntu) groups=1000(ubuntu),4(adm)</div></pre></td></tr></table></figure>
<p>通过如下证明<code>id</code>是从<code>/etc/passwd</code> 和 <code>/etc/group</code> 文件获取信息的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ strace -e open id 1000</div><div class="line">open(&quot;/etc/passwd&quot;, O_RDONLY|O_CLOEXEC) = 3</div><div class="line">open(&quot;/etc/group&quot;, O_RDONLY|O_CLOEXEC)  = 3</div></pre></td></tr></table></figure>
<p>查看<code>/etc/passwd</code> 和 <code>/etc/group</code> 文件的内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ cat /etc/passwd</div><div class="line">root:x:0:0:root:/root:/bin/bash</div><div class="line">daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin</div><div class="line">xxx:x:1000:1000:Ubuntu:/home/ubuntu:/bin/bash</div><div class="line">$ cat /etc/group</div><div class="line">root:x:0:</div><div class="line">adm:x:4:syslog,ubuntu</div><div class="line">xxx:x:1000:</div></pre></td></tr></table></figure>
<p>passwd文件内没有密码，那密码存储在哪里呢？实际存在<code>/etc/shadow</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sudo cat /etc/shadow</div><div class="line">root:$6$mS9o0QBw$P1ojPSTexV2PQ.Z./rqzYex.k7TJE2nVeIVL0dql/:17126:0:99999:7:::</div><div class="line">daemon:*:17109:0:99999:7:::</div><div class="line">ubuntu:$6$GIfdqlb/$ms9ZoxfrUq455K6UbmHyOfz7DVf7TWaveyHcp.:17126:0:99999:7:::</div></pre></td></tr></table></figure>
<p>如果你想以root用户来运行程序，得用<code>sudo</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ id</div><div class="line">uid=1000(ubuntu) gid=1000(ubuntu) groups=1000(ubuntu),4(adm)</div><div class="line">$ sudo id</div><div class="line">uid=0(root) gid=0(root) groups=0(root)</div><div class="line">$ sudo -u ubuntu id</div><div class="line">uid=1000(ubuntu) gid=1000(ubuntu) groups=1000(ubuntu),4(adm)</div><div class="line">$ sudo -u daemon id</div><div class="line">uid=1(daemon) gid=1(daemon) groups=1(daemon)</div></pre></td></tr></table></figure>
<p>如果你想登录到另外一个用户并启动各种命令，使用<code>sudo bash</code> 或者 <code>sudo -u user bash</code>。</p>
<p>当你不想输入密码登录服务器，则可以增加user到 <code>/etc/sudoers</code> 文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ echo &quot;$USER ALL=(ALL) NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers</div><div class="line">-bash: /etc/sudoers: Permission denied</div></pre></td></tr></table></figure>
<p>你会发现只有root用户可以操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo echo &quot;$USER ALL=(ALL) NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers</div><div class="line">-bash: /etc/sudoers: Permission denied</div></pre></td></tr></table></figure>
<p>咋回事呢？还是不行。。。</p>
<p>当你以root权限执行<code>echo</code>命令追加一行到<code>/etc/sudoers</code> ，仍然使用的原user。</p>
<p>通常有两种解决方法：</p>
<ol>
<li><code>echo &quot;$USER ALL=(ALL) NOPASSWD: ALL&quot; | sudo tee -a /etc/sudoers</code></li>
<li><code>sudo bash -c &quot;echo &#39;$USER ALL=(ALL) NOPASSWD: ALL&#39; &gt;&gt; /etc/sudoers&quot;</code></li>
</ol>
<p>第一种，<code>tee -a</code>追加标准输入到文件，这时执行以root权限；</p>
<p>第二种，我们以root用户执行bash，用 (<code>-c</code>) 以root执行整个命令。注意双引号/单引号，因为 <code>$USER</code>变量转义的问题。</p>
<p>当你想更改密码时，可用 <code>passwd</code>，也可用 <code>/etc/shadow</code> 文件，这个文件必须用root权限：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ ls -l /etc/shadow</div><div class="line">-rw-r----- 1 root shadow 1122 Nov 27 18:52 /etc/shadow</div></pre></td></tr></table></figure>
<p> <code>passwd</code> 如何才能被常规user执行往具有保护权限的文件写入？</p>
<p>当你启动一个进程时，那这个进程属于你的用户，即使这个可执行文件的拥有者是其它user。</p>
<p>你能改变文件的权限：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ ls -l /usr/bin/passwd</div><div class="line">-rwsr-xr-x 1 root root 54256 Mar 29  2016 /usr/bin/passwd</div></pre></td></tr></table></figure>
<p>注意 <code>s</code> 字符，它是<code>sudo chmod u+s /usr/bin/passwd</code>实现的，意味着能以拥有者root的身份运行可执行文件。</p>
<p>你使用 <code>find /bin -user root -perm -u+s</code>会发现一个<code>setuid</code> 可执行文件。同理，对用户组可以用 (<code>g+s</code>)。</p>
<ul>
<li>Process state</li>
</ul>
<p>接下来看下<em>htop</em>中进程状态列，其用字母 <em>S</em> 表示。</p>
<p>下面是进程列的可能取值：</p>
<table>
<thead>
<tr>
<th>R</th>
<th>运行状态（running）或者运行队列中的就绪状态（runnable）</th>
</tr>
</thead>
<tbody>
<tr>
<td>S</td>
<td>中断睡眠（等待事件完成）</td>
</tr>
<tr>
<td>D</td>
<td>非中断睡眠（常为IO）</td>
</tr>
<tr>
<td>Z</td>
<td>僵尸进程，无效进程但是未被父进程回收</td>
</tr>
<tr>
<td>T</td>
<td>被控制信号停止</td>
</tr>
<tr>
<td>t</td>
<td>跟踪时被调试者停止</td>
</tr>
<tr>
<td>X</td>
<td>死亡状态</td>
</tr>
</tbody>
</table>
<p> 注意，当你运行<code>ps</code>时，它将也会显示子状态，比如<em>Ss，R+，Ss+</em>，等等.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ ps x</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line"> 1688 ?        Ss     0:00 /lib/systemd/systemd --user</div><div class="line"> 1689 ?        S      0:00 (sd-pam)</div><div class="line"> 1724 ?        S      0:01 sshd: vagrant@pts/0</div><div class="line"> 1725 pts/0    Ss     0:00 -bash</div><div class="line"> 2628 pts/0    R+     0:00 ps x</div></pre></td></tr></table></figure>
<p><strong>R - 运行状态或者运行队列中的就绪状态</strong></p>
<p>在这种状态下，进程正在运行或者在运行队列中等待运行。</p>
<p>那运行的都是啥呢？</p>
<p>当你编译所写的源代码，生成的机器码是CPU指令集，并保存为可执行文件。当你启动程序时，该程序被加载进内存，然后CPU执行这些指令集。</p>
<p>从根本上来说，CPU是在执行指令，换句话说，处理数字。</p>
<p><strong>S - 中断睡眠</strong></p>
<p>这意味着该进程的指令不能在CPU上立即执行。相反地，该进程等待某个事件或者条件发生。当事件发生，系统内核设置进程状态为运行状态。</p>
<p>本例是GNU的coreutils软件包中的<code>sleep</code>工具。它将睡眠指定秒数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ sleep 1000 &amp;</div><div class="line">[1] 10089</div><div class="line">$ ps f</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line"> 3514 pts/1    Ss     0:00 -bash</div><div class="line">10089 pts/1    S      0:00  \_ sleep 1000</div><div class="line">10094 pts/1    R+     0:00  \_ ps f</div></pre></td></tr></table></figure>
<p>所以这是一个中断睡眠。那如何中断该进程？通过发送控制信号。</p>
<p>你能在 <em>htop</em> 中点击 <em>F9</em> ，然后在左侧菜单中选择一个信号发送。</p>
<p>发送的信号中最有名的是<code>kill</code>。因为<code>kill</code>是一个系统调用，其能发送信号给进程。程序<code>/bin/kill</code>能从用户空间做系统调用，默认的信号是使用<code>TERM</code>，该信号要求进程中止或者杀死。</p>
<p>信号其实只是一个数字，但是数字太难记住，所以我们常说对应的名字。信号名字用大写表示，并用<code>SIG</code>前缀。</p>
<p>常用的信号有<code>INT</code>， <code>KILL</code>， <code>STOP</code>， <code>CONT</code>， <code>HUP</code>。</p>
<p>让我们发送<code>INT</code>（也称作，<code>SIGINT</code>或者<code>2</code>或者 <code>Terminal interrupt</code> ）中断睡眠。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">kill</span> -INT 10089</div><div class="line">[1]+  Interrupt               sleep 1000</div></pre></td></tr></table></figure>
<p>当你在键盘上敲击<code>CTRL</code>+<code>C</code> 也会产生上面同样的效果。 <code>bash</code> 将发送前台进程 <code>SIGINT</code> 信号。</p>
<p>顺便提一下，在 <code>bash</code>中，虽然大部分操作系统都有 <code>/bin/kill</code> ，但是 <code>kill</code> 是一个内建命令。这是为什么呢？如果你创建的进程达到限制条件，它允许进程被kill。</p>
<p>实现相同功能的命令：</p>
<ul>
<li><code>kill -INT 10089</code></li>
<li><code>kill -2 10089</code></li>
<li><code>/bin/kill -2 10089</code></li>
</ul>
<p>另外一个有用的信号是 <code>SIGKILL</code> (也被称作 <code>9</code>)。你可以使用该信号kill掉不响应的进程，省的你发狂的按 <code>CTRL</code>+<code>C</code> 键盘。</p>
<p>当编写程序时，你能设置信号handler函数，该函数将在进程收到信号时被调用。换句话说，你能捕获信号，然后做点什么事。例如，清理或者优雅的关闭进程。所以发送 <code>SIGINT</code> 信号（用户想中断一个进程）和<code>SIGTERM</code> （用户想中止一个进程）并不意味着进程被中止。</p>
<p>当你运行Python脚本，你会发现一个意外：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ python -c <span class="string">'import sys; sys.stdin.read()'</span></div><div class="line">^C</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;string&gt;"</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">KeyboardInterrupt</div></pre></td></tr></table></figure>
<p>你可以告诉内核强制中止一个进程，使用发送 <code>KILL</code>信号：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sleep 1000 &amp;</div><div class="line">[1] 2658</div><div class="line">$ <span class="built_in">kill</span> -9 2658</div><div class="line">[1]+  Killed                  sleep 1000</div></pre></td></tr></table></figure>
<p><strong>D - 非中断睡眠</strong></p>
<p>不像中止睡眠进程那么简单，你不能用信号唤醒该进程。这就是为什么许多人喊怕看到这个状态。你不能kill该进程，因为kill意味着通过发送<code>SIGKILL</code> 信号给该进程。</p>
<p>如果进程必须等待不中断或者事件被期望快速发生，那这个状态被使用，比如读写磁盘。但是这仅仅发生一秒分之一。</p>
<p>引用自StackOverflow</p>
<blockquote>
<p>不中断进程经常等到I/O出现页缺失（page fault）。进程/任务不能在这种状态下中断，因为它不能处理任何信号；如果中断了，另外一个页缺失将会发生，会返回到原始位置。</p>
</blockquote>
<p>换句话说，如果你在使用NFS（网络文件系统）时出现中断，那得好久才恢复。</p>
<p>或者，以我的经验看，意味着进程正在交换许多小内存。</p>
<p>让我们试着一个进程进入不中断睡眠。</p>
<p><code>8.8.8.8</code> 是Google提供的公共DNS服务。他们没有一个开放的NFS，但是也不能阻止试验。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sudo mount 8.8.8.8:/tmp /tmp &amp;</div><div class="line">[1] 12646</div><div class="line">$ sudo ps x | grep mount.nfs</div><div class="line">12648 pts/1    D      0:00 /sbin/mount.nfs 8.8.8.8:/tmp /tmp -o rw</div></pre></td></tr></table></figure>
<p>如何找出刚才发生了什么？ <code>strace</code>!</p>
<p> <code>strace</code>上面<code>ps</code>的输出命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ sudo strace /sbin/mount.nfs 8.8.8.8:/tmp /tmp -o rw</div><div class="line">...</div><div class="line">mount(<span class="string">"8.8.8.8:/tmp"</span>, <span class="string">"/tmp"</span>, <span class="string">"nfs"</span>, 0, ...</div></pre></td></tr></table></figure>
<p>所以 <code>mount</code> 系统调用正在阻塞进程。</p>
<p>如果想看看发生了什么，你能运行带<code>intr</code> 选项的 <code>mount</code> 命令来中断： <code>sudo mount 8.8.8.8:/tmp /tmp -o intr</code>。</p>
<p><strong>Z - 僵尸进程，无效进程但是未被父进程回收</strong></p>
<p>当一个进程以 <code>exit</code>退出时，它还有子进程，此时子进程变成了僵尸进程。</p>
<ul>
<li>如果僵尸进程存在一小会，那相当正常；</li>
<li>僵尸进程存在很长时间可能导致程序bug；</li>
<li>僵尸进程不消耗内存，仅仅是一个进程ID；</li>
<li>僵尸进程不能被<code>kill</code> ；</li>
<li>发生<code>SIGCHLD</code> 信号能让父进程回收僵尸进程；</li>
<li><code>kill</code> 僵尸进程的父进程能摆脱父进程和其僵尸进程</li>
</ul>
<p>下面写个C程序的例子展示下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="built_in">printf</span>(<span class="string">"Running\n"</span>);</div><div class="line"></div><div class="line">  <span class="keyword">int</span> pid = fork();</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"I am the child process\n"</span>);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"The child process is exiting now\n"</span>);</div><div class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"I am the parent process\n"</span>);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"The parent process is sleeping now\n"</span>);</div><div class="line">    sleep(<span class="number">20</span>);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"The parent process is finished\n"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>安装GNU C编译器（GCC）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt install -y gcc</div></pre></td></tr></table></figure>
<p>编译代码并运行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">gcc zombie.c -o zombie</div><div class="line">./zombie</div></pre></td></tr></table></figure>
<p>查看进程树：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ ps f</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line"> 3514 pts/1    Ss     0:00 -bash</div><div class="line"> 7911 pts/1    S+     0:00  \_ ./zombie</div><div class="line"> 7912 pts/1    Z+     0:00      \_ [zombie] &lt;defunct&gt;</div><div class="line"> 1317 pts/0    Ss     0:00 -bash</div><div class="line"> 7913 pts/0    R+     0:00  \_ ps f</div></pre></td></tr></table></figure>
<p>我们得到了僵尸进程。当父进程退出，僵尸进程也退出。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ ps f</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line"> 3514 pts/1    Ss+    0:00 -bash</div><div class="line"> 1317 pts/0    Ss     0:00 -bash</div><div class="line"> 7914 pts/0    R+     0:00  \_ ps f</div></pre></td></tr></table></figure>
<p>如果用<code>while (true) ;</code> 代替 <code>sleep(20)</code> ，僵尸进程将正常退出。</p>
<p>使用<code>exit</code>时，该进程所有的内存和资源被释放，其它的进程可以继续使用。</p>
<p>为什么要保留僵尸进程存在呢？</p>
<p>父进程使用 <code>wait</code>系统调用找出其子进程退出码（信号 handler）。如果一个进程睡眠，它需要等待唤醒。</p>
<p>为什么不简单的强制进程唤醒和kill掉？当你厌倦小孩时，你不会把他扔垃圾桶。这里的原因相同。坏事情总会发生的。</p>
<p><strong>T - 被控制信号停止</strong></p>
<p>打开两个终端窗口，使用 <code>ps u</code>能查看到用户的进程：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ ps u</div><div class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</div><div class="line">ubuntu    1317  0.0  0.9  21420  4992 pts/0    Ss+  Jun07   0:00 -bash</div><div class="line">ubuntu    3514  1.5  1.0  21420  5196 pts/1    Ss   07:28   0:00 -bash</div><div class="line">ubuntu    3528  0.0  0.6  36084  3316 pts/1    R+   07:28   0:00 ps u</div></pre></td></tr></table></figure>
<p>忽略 <code>-bash</code> 和<code>ps u</code>进程。</p>
<p>现在在其中一个终端窗口运行<code>cat /dev/urandom &gt; /dev/null</code> 。其进程状态为 <code>R+</code> ，意味着正在运行。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ps u</div><div class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</div><div class="line">ubuntu    3540  103  0.1   6168   688 pts/1    R+   07:29   0:04 cat /dev/urandom</div></pre></td></tr></table></figure>
<p>按 <code>CTRL</code>+<code>Z</code> 停止该进程：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ <span class="comment"># CTRL+Z</span></div><div class="line">[1]+  Stopped                 cat /dev/urandom &gt; /dev/null</div><div class="line">$ ps aux</div><div class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</div><div class="line">ubuntu    3540 86.8  0.1   6168   688 pts/1    T    07:29   0:15 cat /dev/urandom</div></pre></td></tr></table></figure>
<p>该进程的状态现在为 <code>T</code>。</p>
<p>在第一个终端运行 <code>fg</code> 可以重新恢复该进程。</p>
<p>另外一种停止进程的方法是用 <code>kill</code> 发送 <code>STOP</code> 信号给进程。然后使用 <code>CONT</code> 信号可让进程恢复执行。</p>
<p><strong>t - 跟踪时被调试者停止</strong></p>
<p>首先，安装GNU调试器（gdb）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt install -y gdb</div></pre></td></tr></table></figure>
<p>监听网络端口1234的入网连接：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ nc <span class="_">-l</span> 1234 &amp;</div><div class="line">[1] 3905</div></pre></td></tr></table></figure>
<p>状态显示睡眠状态，那意味着该进程在等待网络传入数据。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ps u</div><div class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</div><div class="line">ubuntu    3905  0.0  0.1   9184   896 pts/0    S    07:41   0:00 nc <span class="_">-l</span> 1234</div></pre></td></tr></table></figure>
<p>运行调试器，并与进程ID为3905的进程关联：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo gdb -p 3905</div></pre></td></tr></table></figure>
<p>你会发现这个进程的状态变为<code>t</code>，这意味着调试器正在跟踪该进程。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ps u</div><div class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</div><div class="line">ubuntu    3905  0.0  0.1   9184   896 pts/0    t    07:41   0:00 nc <span class="_">-l</span> 1234</div></pre></td></tr></table></figure>
<ul>
<li>Process time</li>
</ul>
<p>Linux是一个多任务的操作系统。这意味着，即使机器只有一个PCU，也能在同一个时间点运行多个进程。你可以通过SSH连接服务器查看 <em>htop</em> 输出，同时你的web服务也在通过网络传输博客内容给读者。</p>
<p>那系统是如何做到在单个CPU上一个时间点只执行一个指令呢？答案是时间共享。</p>
<p>一个进程运行“一点时间”，然后挂起；这时另外一个等待的进程运行“一点时间”。进程运行的这“一点时间”称为时间片（time slice）。</p>
<p>时间片通常是几毫秒。所以只要服务器系统的负载不高，你是注意不到的。</p>
<p>这也就可以解释为什么平均负载（load average）是运行进程的平均数了。如果你的服务器只有一个核，平均负载是1.0，那CPU的利用率达到100%。如果平均负载高于1.0，那意味着等待运行的进程数大于CPU能承载运行的进程数。所以会发现服务器宕机或者延迟。如果负载小雨1.0，那意味着CPU有时会处于空闲状态，不做任何工作。</p>
<p>这也给你一个提示：为什么一个运行了10秒的进程的运行时间有时会高于或者低于准确的10秒。</p>
<ul>
<li>Process niceness and priority</li>
</ul>
<p>当运行的task数比可用的CPU核数要多时，你必须找个方法决定接下来哪个task运行哪个task保持等待。这其实是 task scheduler的职责。</p>
<p>Linux内核的scheduler负责选择运行进程队列中哪个进程接下来运行，依赖于内核使用的scheduler算法。</p>
<p>一般你不能影响scheduler，但是让它知道哪个进程更重要。</p>
<p>Nice值(<code>NI</code>) 是表示用户空间进程优先级的数值，其代表静态优先级。Nice值的范围是-20~+19，拥有Nice值越大的进程的实际优先级越小（即Nice值为+19的进程优先级最小，为-20的进程优先级最大），默认的Nice值是0。Nice值增加1，降低进程10%的CPU时间。</p>
<p>priority(优先级，<code>PRI</code>)是Linux内核级的优先级，其代表动态优先级。该优先级范围从0到139，0到99表示实时进程，100到139表示用户空间进程优先级。</p>
<p>你可以改变Nice值让内核考虑该进程优先级，但是不能改变priority。</p>
<p>Nice值和priority之间的关系如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PR = 20 + NI</div></pre></td></tr></table></figure>
<p>所以 <code>PR = 20 + (-20 to +19)</code> 的值是0到39，映射为100到139。</p>
<p>在启动进程前设置该进程的Nice值：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nice -n niceness program</div></pre></td></tr></table></figure>
<p>当程序已经正在运行，可用 <code>renice</code>改变其Nice值：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">renice -n niceness -p PID</div></pre></td></tr></table></figure>
<p>下面是CPU使用颜色代表的意义：</p>
<blockquote>
<p>蓝色：低优先级线程（nice &gt; 0）</p>
<p>绿色：常规优先级线程</p>
<p>红色：内核线程</p>
</blockquote>
<ul>
<li>内存使用 - VIRT/RES/SHR/MEM</li>
</ul>
<p>进程给人的假象是只有一个进程使用内存，其实这是通过虚拟内存实现的。</p>
<p>进程没有直接访问物理内存，而是拥有虚拟地址空间，Linux内核将虚拟内存地址转换成物理内存或者映射到磁盘。这就是为什么看起来进程能够使用的内存比电脑真实的内存要多。</p>
<p>这里说明的是，想准确计算一个进程占用多少内存并不是那么直观。你也想计算共享内存或者磁盘映射内存吗？<code>htop</code> 显示的一些信息能帮助你估计内存使用量。</p>
<p>内存使用颜色代表的意义：</p>
<blockquote>
<p>绿色：Used memory</p>
<p>蓝色：Buffers</p>
<p>橘黄色：Cache</p>
</blockquote>
<p><strong>VIRT/VSZ - 虚拟内存</strong></p>
<blockquote>
<p>task使用的虚拟内存总量。它包含代码、数据和共享内存（加上调出内存到磁盘的分页和已映射但未使用的分页）。</p>
</blockquote>
<p><code>VIRT</code> 是虚拟内存使用量。它包括所有的内存，含内存映射文件。</p>
<p>如果应用请求1GB内存，但是内存只有1MB，那 <code>VIRT</code>显示1GB。如果 <code>mmap</code>映射的是一个1GB 文件， <code>VIRT</code>也显示1GB。</p>
<p>大部分情况下， <code>VIRT</code>并不是一个太有用的数字。</p>
<p><strong>RES/RSS - 常驻内存大小</strong></p>
<blockquote>
<p>task使用的非交换的物理内存。</p>
</blockquote>
<p><code>RES</code>是常驻内存使用量。</p>
<p><code>RES</code>相比于 <code>VIRT</code>，能更好的表征进程的内存使用量：</p>
<blockquote>
<p>不包含交换出的内存；</p>
<p>不包含共享内存</p>
</blockquote>
<p>如果一个进程使用1GB内存，并调用<code>fork()</code>函数，fork的结果是两个进程的 <code>RES</code> 都是1GB，但是实际上只使用了1GB内存。因为Linux采用的是copy-on-write机制。</p>
<p><strong>SHR - 共享内存大</strong></p>
<blockquote>
<p>task使用的共享内存总量。</p>
<p>简单的反应进程间共享的内存。</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="built_in">printf</span>(<span class="string">"Started\n"</span>);</div><div class="line">  sleep(<span class="number">10</span>);</div><div class="line"></div><div class="line">  <span class="keyword">size_t</span> memory = <span class="number">10</span> * <span class="number">1024</span> * <span class="number">1024</span>; <span class="comment">// 10 MB</span></div><div class="line">  <span class="keyword">char</span>* buffer = <span class="built_in">malloc</span>(memory);</div><div class="line">  <span class="built_in">printf</span>(<span class="string">"Allocated 10M\n"</span>);</div><div class="line">  sleep(<span class="number">10</span>);</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; memory/<span class="number">2</span>; i++)</div><div class="line">    buffer[i] = <span class="number">42</span>;</div><div class="line">  <span class="built_in">printf</span>(<span class="string">"Used 5M\n"</span>);</div><div class="line">  sleep(<span class="number">10</span>);</div><div class="line"></div><div class="line">  <span class="keyword">int</span> pid = fork();</div><div class="line">  <span class="built_in">printf</span>(<span class="string">"Forked\n"</span>);</div><div class="line">  sleep(<span class="number">10</span>);</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (pid != <span class="number">0</span>) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = memory/<span class="number">2</span>; i &lt; memory/<span class="number">2</span> + memory/<span class="number">5</span>; i++)</div><div class="line">      buffer[i] = <span class="number">42</span>;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Child used extra 2M\n"</span>);</div><div class="line">  &#125;</div><div class="line">  sleep(<span class="number">10</span>);</div><div class="line"></div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">fallocate <span class="_">-l</span> 10G</div><div class="line">gcc -std=c99 mem.c -o mem</div><div class="line">./mem</div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Process  Message               VIRT  RES SHR</div><div class="line">main     Started               4200  680 604</div><div class="line">main     Allocated 10M        14444  680 604</div><div class="line">main     Used 5M              14444 6168 1116</div><div class="line">main     Forked               14444 6168 1116</div><div class="line">child    Forked               14444 5216 0</div><div class="line">main     Child used extra 2M        8252 1116</div><div class="line">child    Child used extra 2M        5216 0</div></pre></td></tr></table></figure>
<p><strong>MEM% - 内存使用量占比</strong></p>
<blockquote>
<p>task当前使用的内存占比。</p>
</blockquote>
<p>该值为 <code>RES</code> 除以RAM总量。</p>
<p>如果 <code>RES</code> 是400M，你有8GB的RAM，<code>MEM%</code> 是 <code>400/8192*100</code> = <code>4.88%</code>。</p>
<p>“庖丁解牛”式问诊Linux启动全过程</p>
<p>本文使用Digital Ocean droplet Ubuntu服务器启动过程为“蓝本”，详细解说Linux启动涉及的所有进程。</p>
<p>Ubuntu系统引导启动的进程都有哪些？你都需要它们吗？</p>
<p>下面是在全新Digital Ocean droplet 的Ubuntu（16.04.1 LTS x64）服务器上启动系统。</p>
<p><img src="https://peteris.rocks/blog/htop/canyoukillit-before.png" alt="image"></p>
<ul>
<li>/sbin/init</li>
</ul>
<blockquote>
<p>/sbin/init程序，也称init，调度除boot进程外所有的进程，配置用户环境。</p>
<p>init启动后，将成为所有系统自动启动进程的父进程或者祖父进程。</p>
</blockquote>
<p>它是systemd吗？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ dpkg -S /sbin/init</div><div class="line">systemd-sysv: /sbin/init</div></pre></td></tr></table></figure>
<p>答案是，yes。</p>
<p>如果kill掉<code>/sbin/init</code>会发生什么呢？什么也不会发生，哈哈。</p>
<blockquote>
<ul>
<li><a href="https://wiki.ubuntu.com/SystemdForUpstartUsers" target="_blank" rel="external">https://wiki.ubuntu.com/SystemdForUpstartUsers</a></li>
<li><a href="https://www.centos.org/docs/5/html/5.1/Installation_Guide/s2-boot-init-shutdown-init.html" target="_blank" rel="external">https://www.centos.org/docs/5/html/5.1/Installation_Guide/s2-boot-init-shutdown-init.html</a></li>
</ul>
</blockquote>
<ul>
<li>/lib/systemd/systemd-journald</li>
</ul>
<blockquote>
<p>systemd-journald进程是一个系统服务，其收集、存储log数据。它基于接收的log信息创建和维护结构化、索引journal。</p>
</blockquote>
<p>换句话讲。</p>
<blockquote>
<p>journald主要的变化之一，是采用优化的log存储替代简单文本log文件。使得系统管理员访问相应的log信息更有效。journald引入数据库式log的集中存储能力。</p>
</blockquote>
<p>你可以使用 <code>journalctl</code> 命令查询log文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">journalctl _COMM=sshd logs by sshd</div><div class="line">journalctl _COMM=sshd -o json-pretty logs by sshd in JSON</div><div class="line">journalctl --since &quot;2015-01-10&quot; --until &quot;2015-01-11 03:00&quot;</div><div class="line">journalctl --since 09:00 --until &quot;1 hour ago&quot;</div><div class="line">journalctl --since yesterday</div><div class="line">journalctl -b logs since boot</div><div class="line">journalctl -f to follow logs</div><div class="line">journalctl --disk-usage</div><div class="line">journalctl --vacuum-size=1G</div></pre></td></tr></table></figure>
<p>相当酷有木有！</p>
<p>看起来不能移除或者disable该服务，但是你可以关闭logging。</p>
<blockquote>
<ul>
<li><a href="https://www.freedesktop.org/software/systemd/man/systemd-journald.service.html" target="_blank" rel="external">https://www.freedesktop.org/software/systemd/man/systemd-journald.service.html</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs" target="_blank" rel="external">https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs</a></li>
<li><a href="https://www.loggly.com/blog/why-journald/" target="_blank" rel="external">https://www.loggly.com/blog/why-journald/</a></li>
<li><a href="https://ask.fedoraproject.org/en/question/63985/how-to-correctly-disable-journald/" target="_blank" rel="external">https://ask.fedoraproject.org/en/question/63985/how-to-correctly-disable-journald/</a></li>
</ul>
</blockquote>
<ul>
<li>/sbin/lvmetad -f</li>
</ul>
<blockquote>
<p>lvmetad守护进程缓存LVM元数据（metadata），所以LVM命令不用扫描磁盘就能读取元数据。</p>
<p>元数据缓存的优势，在于扫描磁盘是非常耗时的，并且可能中断系统和磁盘的正常工作。</p>
</blockquote>
<p>那什么才是LVM（Logical Volume Management，逻辑卷管理）呢？</p>
<blockquote>
<p>你可以认为逻辑卷管理LVM是动态分区（dynamic partitions），意味着你能在正在运行的系统上用命令行创建/重设大小/删除（create/resize/delete）LVM分区（用LVM的话讲是逻辑卷）：无须重启操作系统来让内核感知新建或者重设大小的分区。</p>
</blockquote>
<p>听起来像，如果你正在使用LVM服务，那得保留该服务。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ lvscan</div><div class="line">$ sudo apt remove lvm2 -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/lvmetad.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/lvmetad.8.html</a></li>
<li><a href="http://askubuntu.com/questions/3596/what-is-lvm-and-what-is-it-used-for" target="_blank" rel="external">http://askubuntu.com/questions/3596/what-is-lvm-and-what-is-it-used-for</a></li>
</ul>
</blockquote>
<ul>
<li>/lib/systemd/udevd</li>
</ul>
<blockquote>
<p>systemd-udevd监听Linux内核uevent事件（uevent是内核空间和用户空间之间通信的机制，主要用于热插拔事件（hotplug））。对于每个事件，systemd-udevd都会根据udev规则执行匹配的指定设备。</p>
<p>udev是Linux内核的设备管理器。其作为devfsd和hotplug的升级，udev主要管理/dev目录下的设备节点。</p>
</blockquote>
<p>所以该服务会管理 <code>/dev</code>。</p>
<p>作者不太确定是否一定要运行在虚拟机上。</p>
<blockquote>
<ul>
<li><a href="https://www.freedesktop.org/software/systemd/man/systemd-udevd.service.html" target="_blank" rel="external">https://www.freedesktop.org/software/systemd/man/systemd-udevd.service.html</a></li>
<li><a href="https://wiki.archlinux.org/index.php/udev" target="_blank" rel="external">https://wiki.archlinux.org/index.php/udev</a></li>
</ul>
</blockquote>
<ul>
<li>/lib/systemd/timesyncd</li>
</ul>
<blockquote>
<p>systemd-timesyncd是使用远程网络时间协议来同步本地系统时钟的系统服务。</p>
</blockquote>
<p>所以该服务是来替代<code>ntpd</code>的。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ timedatectl status</div><div class="line">      Local time: Fri 2016-08-26 11:38:21 UTC</div><div class="line">  Universal time: Fri 2016-08-26 11:38:21 UTC</div><div class="line">        RTC time: Fri 2016-08-26 11:38:20</div><div class="line">       Time zone: Etc/UTC (UTC, +0000)</div><div class="line"> Network time on: yes</div><div class="line">NTP synchronized: yes</div><div class="line"> RTC <span class="keyword">in</span> <span class="built_in">local</span> TZ: no</div></pre></td></tr></table></figure>
<p>查看一下服务器上打开的端口：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo netstat -nlput</div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      2178/sshd</div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN      2178/sshd</div></pre></td></tr></table></figure>
<p>以前在Ubuntu 14.04上打开的端口如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install ntp -y</div><div class="line">$ sudo netstat -nlput</div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1380/sshd</div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1380/sshd</div><div class="line">udp        0      0 10.19.0.6:123           0.0.0.0:*                           2377/ntpd</div><div class="line">udp        0      0 139.59.256.256:123      0.0.0.0:*                           2377/ntpd</div><div class="line">udp        0      0 127.0.0.1:123           0.0.0.0:*                           2377/ntpd</div><div class="line">udp        0      0 0.0.0.0:123             0.0.0.0:*                           2377/ntpd</div><div class="line">udp6       0      0 fe80::601:6aff:fxxx:123 :::*                                2377/ntpd</div><div class="line">udp6       0      0 ::1:123                 :::*                                2377/ntpd</div><div class="line">udp6       0      0 :::123                  :::*                                2377/ntpd</div></pre></td></tr></table></figure>
<blockquote>
<p><a href="https://www.freedesktop.org/software/systemd/man/systemd-timesyncd.service.html" target="_blank" rel="external">https://www.freedesktop.org/software/systemd/man/systemd-timesyncd.service.html</a></p>
<p><a href="https://wiki.archlinux.org/index.php/systemd-timesyncd" target="_blank" rel="external">https://wiki.archlinux.org/index.php/systemd-timesyncd</a></p>
</blockquote>
<ul>
<li>/usr/sbin/atd -f</li>
</ul>
<blockquote>
<p>atd将作业加入队列稍后执行。atd通过<code>at</code>将业务加入队列。</p>
<p><code>at</code>和批量从标准输入输出或者指定文件读命令并稍后执行。</p>
</blockquote>
<p><code>cron</code>命令调度作业周期性重复运行，<code>at</code>只在指定时间运行一次。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">echo</span> <span class="string">"touch /tmp/yolo.txt"</span> | at now + 1 minute</div><div class="line">job 1 at Fri Aug 26 10:44:00 2016</div><div class="line">$ atq</div><div class="line">1       Fri Aug 26 10:44:00 2016 a root</div><div class="line">$ sleep 60 &amp;&amp; ls /tmp/yolo.txt</div><div class="line">/tmp/yolo.txt</div></pre></td></tr></table></figure>
<p>不需要使用的话可以卸载：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove at -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/atd.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/atd.8.html</a></li>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man1/at.1.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man1/at.1.html</a></li>
<li><a href="http://askubuntu.com/questions/162439/why-does-ubuntu-server-run-both-cron-and-atd" target="_blank" rel="external">http://askubuntu.com/questions/162439/why-does-ubuntu-server-run-both-cron-and-atd</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/lib/snapd/snapd</li>
</ul>
<blockquote>
<p>Snappy Ubuntu Core是带有事务性更新的Ubuntu版本，其和当前的Ubuntu具有相同的library的最小服务器镜像，但是以更简单的机制来提供应用。</p>
</blockquote>
<p>很显然，它是一个简化版的deb包，分发的所有依赖都在单个snap中。</p>
<p>作者从来不用snappy在服务器上发布或者分发应用，所以可以卸载：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove snapd -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="https://developer.ubuntu.com/en/snappy/" target="_blank" rel="external">https://developer.ubuntu.com/en/snappy/</a></li>
<li><a href="https://insights.ubuntu.com/2016/06/14/universal-snap-packages-launch-on-multiple-linux-distros/" target="_blank" rel="external">https://insights.ubuntu.com/2016/06/14/universal-snap-packages-launch-on-multiple-linux-distros/</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/bin/dbus-daemon</li>
</ul>
<blockquote>
<p>在计算机中，D-Bus或者DBus是进程间通信（ inter-process communication，IPC）和远程过程调用（remote procedure call，RPC）机制，它允许在同一台机器上并发运行的多个计算机程序（进程）通信。</p>
</blockquote>
<p>作者觉得当你需要桌面环境时要启动该服务，当你只是在服务器上运行web应用则可以卸载：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove dbus -y --purge</div></pre></td></tr></table></figure>
<p>然而，当你想看下时间是否通过NTP同步，发现了问题：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ timedatectl status</div><div class="line">Failed to create bus connection: No such file or directory</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="https://en.wikipedia.org/wiki/D-Bus" target="_blank" rel="external">https://en.wikipedia.org/wiki/D-Bus</a></li>
</ul>
</blockquote>
<ul>
<li>/lib/systemd/systemd-logind</li>
</ul>
<blockquote>
<p>systemd-logind是管理用户登录的系统服务。</p>
<ul>
<li><a href="https://www.freedesktop.org/software/systemd/man/systemd-logind.service.html" target="_blank" rel="external">https://www.freedesktop.org/software/systemd/man/systemd-logind.service.html</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/sbin/cron -f</li>
</ul>
<blockquote>
<p><code>cron</code>守护进程执行调度计划命令。</p>
<p><code>-f</code> 保持运行在前台，不以守护进程运行。</p>
</blockquote>
<p>你可以使用<code>cron</code>周期性调度任务运行。</p>
<p> <code>crontab -e</code> 编辑cron的配置文件，在Ubuntu上可以用 <code>/etc/cron.hourly</code>，<code>/etc/cron.daily</code>等配置。</p>
<p>你可以使用下面的方法查看cron的log文件：</p>
<ul>
<li><code>grep cron /var/log/syslog</code> </li>
<li><code>journalctl _COMM=cron</code></li>
<li><code>journalctl _COMM=cron --since=&quot;date&quot; --until=&quot;date&quot;</code></li>
</ul>
<p>如果你不想使用cron时，可以停止并disable该服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo systemctl stop cron</div><div class="line">sudo systemctl <span class="built_in">disable</span> cron</div></pre></td></tr></table></figure>
<p>当使用 <code>apt remove cron</code> 删除cron服务时，会发现其会安装postfix：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo apt remove cron</div><div class="line">The following packages will be REMOVED:</div><div class="line">  cron</div><div class="line">The following NEW packages will be installed:</div><div class="line">  anacron bcron bcron-run fgetty libbg1 libbg1-doc postfix runit ssl-cert ucspi-unix</div></pre></td></tr></table></figure>
<p>看起来cron服务需要邮件客户端（MTA）发送邮件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">$ apt show cron</div><div class="line">Package: cron</div><div class="line">Version: 3.0pl1-128ubuntu2</div><div class="line">...</div><div class="line">Suggests: anacron (&gt;= 2.0-1), logrotate, checksecurity, exim4 | postfix | mail-transport-agent</div><div class="line"></div><div class="line">$ apt depends cron</div><div class="line">cron</div><div class="line">  ...</div><div class="line">  Suggests: anacron (&gt;= 2.0-1)</div><div class="line">  Suggests: logrotate</div><div class="line">  Suggests: checksecurity</div><div class="line"> |Suggests: exim4</div><div class="line"> |Suggests: postfix</div><div class="line">  Suggests: &lt;mail-transport-agent&gt;</div><div class="line">    ...</div><div class="line">    exim4-daemon-heavy</div><div class="line">    postfix</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="https://help.ubuntu.com/community/CronHowto" target="_blank" rel="external">https://help.ubuntu.com/community/CronHowto</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-use-cron-to-automate-tasks-on-a-vps" target="_blank" rel="external">https://www.digitalocean.com/community/tutorials/how-to-use-cron-to-automate-tasks-on-a-vps</a></li>
<li><a href="http://unix.stackexchange.com/questions/212355/where-is-my-logfile-of-crontab" target="_blank" rel="external">http://unix.stackexchange.com/questions/212355/where-is-my-logfile-of-crontab</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/sbin/rsyslogd -n</li>
</ul>
<blockquote>
<p>Rsyslogd是提供消息日志的系统组件。</p>
</blockquote>
<p>换句话说，rsyslogd将日志写入 <code>/var/log/</code> 目录下，比如 <code>/var/log/auth.log</code> 是SSH登陆的权限日志。</p>
<p>rsyslogd的配置文件是<code>/etc/rsyslog.d</code>。</p>
<p>你也可以配置rsyslogd发送log文件到远程服务器，实现日志log中心化。</p>
<p>你也可以在后台脚本中使用 <code>logger</code> 命令将消息日志写入 <code>/var/log/syslog</code> 。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"></div><div class="line">logger Starting doing something</div><div class="line"><span class="comment"># NFS, get IPs, etc.</span></div><div class="line">logger Done doing something</div></pre></td></tr></table></figure>
<p>但是，前面已经有 <code>systemd-journald</code> 服务在运行了，那还需 <code>rsyslogd</code> 吗？</p>
<blockquote>
<p>Rsyslog 和 Journal服务是存在于系统中的两个log日志应用，它们功能不同。大部分情况下，需要同时结合两者的功能。比如，创建结构化的消息并存储到文件数据库。通信接口需要Rsyslog提供输入和输出模块，通信socket由Journal提供。</p>
</blockquote>
<p>所以呢？看样子还是暂时保留吧。</p>
<blockquote>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/rsyslogd.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/rsyslogd.8.html</a></li>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man1/logger.1.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man1/logger.1.html</a></li>
<li><a href="https://wiki.archlinux.org/index.php/rsyslog" target="_blank" rel="external">https://wiki.archlinux.org/index.php/rsyslog</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-rsyslog-logstash-and-elasticsearch-on-ubuntu-14-04" target="_blank" rel="external">https://www.digitalocean.com/community/tutorials/how-to-centralize-logs-with-rsyslog-logstash-and-elasticsearch-on-ubuntu-14-04</a></li>
<li><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/System_Administrators_Guide/s1-interaction_of_rsyslog_and_journal.html" target="_blank" rel="external">https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/System_Administrators_Guide/s1-interaction_of_rsyslog_and_journal.html</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/sbin/acpid</li>
</ul>
<blockquote>
<p>acpid，是高级配置与电源接口（Advanced Configuration and Power Interface，ACPI）事件守护进程。</p>
<p>acpid设计用来通知ACPI事件的用户空间程序，其在系统启动时已启动，并默认以后台进程运行。</p>
<p>计算机中的高级配置与电源接口，提供处理电源相关事件的开源标准。操作系统可以处理计算机硬件的发现和配置，可以进行电源管理。比如，将未使用的组件置为睡眠，进行状态监控。</p>
</blockquote>
<p>但是本例中使用的虚拟机，不需要挂起/继续。</p>
<p>这里删除该服务，看下会发生什么。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove acpid -y --purge</div></pre></td></tr></table></figure>
<p>作者可以成功执行 <code>reboot</code>重启 droplet，但是执行 <code>halt</code> 后必须通过web接口关闭虚拟机。</p>
<blockquote>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/acpid.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/acpid.8.html</a></li>
<li><a href="https://en.wikipedia.org/wiki/Advanced_Configuration_and_Power_Interface" target="_blank" rel="external">https://en.wikipedia.org/wiki/Advanced_Configuration_and_Power_Interface</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/bin/lxcfs /var/lib/lxcfs/</li>
</ul>
<blockquote>
<p>Lxcfs主要是以lxc容器为用户提供fuse文件系统。在Ubuntu 15.04上，默认提供两个功能：一是，一些/proc文件的视图；二是，过滤访问主机的cgroup文件系统。</p>
<p>总之，在Ubuntu 15.04上你能用通用的方式（ lxc-create）创建容器。创建的容器使用uptime、top等能得出“正确”结果。</p>
</blockquote>
<p>不用LXC容器时可以移除该服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove lxcfs -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="https://insights.ubuntu.com/2015/03/02/introducing-lxcfs/" target="_blank" rel="external">https://insights.ubuntu.com/2015/03/02/introducing-lxcfs/</a></li>
<li><a href="https://www.stgraber.org/2016/03/31/lxcfs-2-0-has-been-released/" target="_blank" rel="external">https://www.stgraber.org/2016/03/31/lxcfs-2-0-has-been-released/</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/lib/accountservice/accounts-daemon</li>
</ul>
<blockquote>
<p>账户管理AccountsService包提供一系列D-Bus接口查询和管理用户账户信息。其是基于usermod(8)，useradd(8) 和userdel(8) 命令实现的。</p>
</blockquote>
<p>作者想知道移除该服务会出现什么问题。当移除DBus时， <code>timedatectl</code>失效。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove accountsservice -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="http://www.linuxfromscratch.org/blfs/view/systemd/gnome/accountsservice.html" target="_blank" rel="external">http://www.linuxfromscratch.org/blfs/view/systemd/gnome/accountsservice.html</a></li>
</ul>
</blockquote>
<ul>
<li>/sbin/mdadm</li>
</ul>
<blockquote>
<p>Linux组件mdadm是管理RAID设备的管理和监控软件。</p>
<p>其名字是源于md（multiple device，多设备）节点管理（administers），它替代之前的mdctl。原始的名字是 “Mirror Disk”，随着功能的增加名字随之改变。</p>
<p>RAID是将多块硬盘看作是一块硬盘的方法。RAID的目的有两个：1)扩展磁盘驱动容量：RAID 0。如果你有2个500GB的HDD，则总的容量即为1TB；2)防止驱动失败时数据丢失。比如RAID 1，RAID 5， RAID 6和RAID 10。</p>
</blockquote>
<p>可以用如下命令移除：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove mdadm -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Mdadm" target="_blank" rel="external">https://en.wikipedia.org/wiki/Mdadm</a></li>
<li><a href="https://help.ubuntu.com/community/Installation/SoftwareRAID" target="_blank" rel="external">https://help.ubuntu.com/community/Installation/SoftwareRAID</a></li>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/mdadm.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/mdadm.8.html</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/lib/policykit-1/polkitd –no-debug</li>
</ul>
<blockquote>
<p>polkitd：PolicyKit守护进程。</p>
<p>polkit：授权管理。</p>
</blockquote>
<p>有点类似是细粒度的sudo权限控制。你能允许非权限用户做某些root用户的操作。比如，桌面计算机中的Linux重启计算机。</p>
<p>这里是运行的服务器，可以移除该服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove policykit-1 -y --purge</div></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/polkitd.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/polkitd.8.html</a></li>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/polkit.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/polkit.8.html</a></li>
<li><a href="http://www.admin-magazine.com/Articles/Assigning-Privileges-with-sudo-and-PolicyKit" target="_blank" rel="external">http://www.admin-magazine.com/Articles/Assigning-Privileges-with-sudo-and-PolicyKit</a></li>
<li><a href="https://wiki.archlinux.org/index.php/Polkit#Configuration" target="_blank" rel="external">https://wiki.archlinux.org/index.php/Polkit#Configuration</a></li>
</ul>
</blockquote>
<ul>
<li>/usr/sbin/sshd -D</li>
</ul>
<blockquote>
<p>sshd（OpenSSH Daemon），ssh的守护进程。</p>
<p>指定-D选项时，sshd不断开，也不成为守护进程。这样会更容易监控sshd。</p>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/sshd.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/sshd.8.html</a></li>
</ul>
</blockquote>
<ul>
<li>/sbin/iscsid</li>
</ul>
<p>iscsid是系统守护进程，处理iSCSI配置和管理连接。从帮助页看到：</p>
<blockquote>
<p>iscsid实现iSCSI协议的控制路径，和一些设备管理。比如，守护进程能配置成在服务器启动时自动重启，该功能基于持久化iSCSI数据库。</p>
</blockquote>
<p>可以移除该服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt remove open-iscsi -y --purge</div></pre></td></tr></table></figure>
<ul>
<li>/sbin/agetty –noclear tty1 linux</li>
</ul>
<blockquote>
<p>agetty是alternative Linux getty的缩写。</p>
<p>getty，是”get tty”的简写，通常从 <code>/etc/inittab</code> 启动，允许用户从终端 (TTYs)登录。它会提示输入用户名，运行’login’ 程序授权用户登录。</p>
<p>早期getty存在传统Unix系统，其管理一系列连接到主机上的终端（电传打字机，Teletype machine）连接。其中tty是Teletype的缩写，后来代指各种文字终端。</p>
</blockquote>
<p>如果在物理服务器上，你可以使用getty登录。在Digital Ocean，你可以点击droplet详情上的<em>Console</em>，通过浏览器和终端交互（可能是VNC连接）。</p>
<p>在过去，系统启动后你会看到一大泼tty启动（一般配置在/etc/inittab）；不过现在都用systemd代替。</p>
<p>下面移除 <code>agetty</code>启动的配置文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo rm /etc/systemd/system/getty.target.wants/getty@tty1.service</div><div class="line">sudo rm /lib/systemd/system/getty@.service</div></pre></td></tr></table></figure>
<p>然后重启服务器，仍然可以通过SSH连接服务器，但是不能通过Digital Ocean的web控制台登录服务器啦。</p>
<p><img src="http://img0.ph.126.net/QQy2chIVliRMwjpAkvKNZQ==/6632514723004686312.png" alt="image"></p>
<blockquote>
<ul>
<li><a href="http://manpages.ubuntu.com/manpages/xenial/man8/getty.8.html" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/xenial/man8/getty.8.html</a></li>
<li><a href="https://en.wikipedia.org/wiki/Getty_(Unix" target="_blank" rel="external">https://en.wikipedia.org/wiki/Getty_(Unix)</a>)</li>
<li><a href="http://0pointer.de/blog/projects/serial-console.html" target="_blank" rel="external">http://0pointer.de/blog/projects/serial-console.html</a></li>
<li><a href="http://unix.stackexchange.com/questions/56531/how-to-get-fewer-ttys-with-systemd" target="_blank" rel="external">http://unix.stackexchange.com/questions/56531/how-to-get-fewer-ttys-with-systemd</a></li>
</ul>
</blockquote>
<ul>
<li>sshd: root@pts/0 &amp; -bash &amp; htop</li>
</ul>
<p><code>sshd: root@pts/0</code> 意味着root用户在#<code>0</code>伪终端 (<code>pts</code>)创建啦SSH会话。</p>
<p><code>bash</code> 是指使用的shell。</p>
<p>但是为啥<code>bash</code> 开头有个破折号呢？Reddit上有解释：</p>
<blockquote>
<p><code>bash</code> 开头的破折号是因为<code>bash</code> 以login shell模式启动时（取得<code>bash</code> 时需要完整的登录流程）。启动login shell模式有两种方式：使用“-”参数启动；使用”—login”选项启动。它们都会加载配置文件。</p>
</blockquote>
<p><code>htop</code> 是交互式进程查看工具。</p>
<p>接着移除下面的服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sudo apt remove lvm2 -y --purge</div><div class="line">sudo apt remove at -y --purge</div><div class="line">sudo apt remove snapd -y --purge</div><div class="line">sudo apt remove lxcfs -y --purge</div><div class="line">sudo apt remove mdadm -y --purge</div><div class="line">sudo apt remove open-iscsi -y --purge</div><div class="line">sudo apt remove accountsservice -y --purge</div><div class="line">sudo apt remove policykit-1 -y --purge</div></pre></td></tr></table></figure>
<p>用<code>htop</code>查看会出现如下图：</p>
<p><img src="http://img0.ph.126.net/ts_inlBS6JC-agpy9WFyPw==/3081869520024393963.png" alt="image"></p>
<p>再次挑战“极限”情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sudo apt remove dbus -y --purge</div><div class="line">sudo apt remove rsyslog -y --purge</div><div class="line">sudo apt remove acpid -y --purge</div><div class="line">sudo systemctl stop cron &amp;&amp; sudo systemctl <span class="built_in">disable</span> cron</div><div class="line">sudo rm /etc/systemd/system/getty.target.wants/getty@tty1.service</div><div class="line">sudo rm /lib/systemd/system/getty@.service</div></pre></td></tr></table></figure>
<p>再用<code>htop</code>查看：</p>
<p><img src="http://img2.ph.126.net/6Y5YnkSZ7ci07ByX1GhT_g==/6632304716283782948.png" alt="image"></p>
<p>未完待续。。。</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/19/distribute-frame-hsf-not-dubbo/" itemprop="url">
                  分布式服务框架选型：面对Dubbo，阿里巴巴为什么选择了HSF？
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-05-19T18:05:10+08:00" content="2017-05-19">
              2017-05-19
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>阿里巴巴集团内部使用的分布式服务框架 HSF（High Speed Framework，也有人戏称“好舒服”）已经被很多技术爱好者所熟知，目前已经支撑着近 2000 多个应用的运行。</p>
<p>其对应早期的开源项目 Dubbo（因为某些原因，Dubbo 项目在 2012 年年底，阿里巴巴就停止了对此开源项目的更新），则更是在互联网领域有着非常高的知名度和广泛的使用。</p>
<p>本文通过对阿里巴巴 HSF 服务框架的介绍，让大家能对这类分布式服务框架架构设计、运行原理，以及如何实现作为一个 SOA 架构需要满足的各个特性有一个清晰的认识。</p>
<p><strong>HSF 服务框架主要组件</strong></p>
<p><strong>1、服务提供者</strong></p>
<p>在服务框架中真正提供服务功能实现的应用实例，为了保障服务提供的高可用性，一般均是集群部署。</p>
<p>每一个 HSF 的应用均是以 War 包的形式存在，运行在阿里巴巴优化定制后的 Tomcat 容器中，在 Tomcat 容器层已经集成了 HSF 服务框架对服务提供者或服务调用者进行配置服务器发现、服务注册、订阅、失效转移等相关功能，所以不管是在服务提供者还是调用者开发时，只需要进行服务相关的配置操作，应用中无需引入任何 HSF 相关的 Jar 依赖包。</p>
<p>考虑到应用故障的隔离、更方便的服务管控，<strong>目前淘宝内部大部分应用的部署方式还是一个虚拟机（对应一个操作系统）运行一个 Tomcat 容器</strong>，每个 Tomcat 运行一个服务应用，随着近几年以 Docker 容器技术的发展和流行，现在阿里巴巴内部也正在进行应用容器化部署的工作，让服务器的资源利用更加科学和高效。</p>
<p><strong>2、服务调用者</strong></p>
<p>作为服务的消费者，大多数也是以 WAR 应用包的方式运行在 Tomcat 容器中，在阿里巴巴集团内部也有一部分是基于 C/C++、PHP、Node.js 等语言开发的服务调用者。</p>
<p><strong>3、地址服务器</strong></p>
<p>在 HSF 服务框架中，地址服务器肩负着给服务提供者和服务调用者提供部署环境中所有配置服务器和 Diamond 服务器的服务器列表信息，是由 Nginx（ 是一个高性能的 HTTP 和反向代理服务器）提供该服务能力。</p>
<p>在部署 HSF 服务环境时，会将整个环境中的配置服务器集群（服务器 IP 列表）和 Diamond 服务器集群信息设置在地址服务器上，在实际生产部署中，也会部署多台地址服务器提供负载均衡和高可用性的服务，服务提供者和调用者<strong>通过统一域名的方式访问</strong>这些地址服务器（比如“xxx.tbsite.net”），通过 DNS 轮询实现地址服务器访问的高可用性。</p>
<p><strong>4、配置服务器</strong></p>
<p>配置服务器在 HSF 框架中主要负责记录环境内所有服务发布（服务提供者的 IP 地址和服务端口信息）和服务订阅（服务调用者的 IP 地址和服务端口信息）信息，并将服务相关信息推送到服务节点上。为了追求服务发布和订阅的推送效率，所有的服务发布和订阅信息均是保存在内存中。</p>
<p><strong>配置服务器与所有服务者提供者和调用者均是长连接，采用心跳的方式可监控到各服务运行节点的状况</strong>，一旦出现服务提供者服务节点出现故障时，会自动推送更新后（将出问题的服务提供者服务节点信息从列表中删除）的服务提供者列表给相关的服务调用者端。</p>
<p>在生产环境中，会部署多台配置服务器，用于服务发布、订阅、推送的负载均衡，在多台配置服务器间会进行实时的数据同步，保证服务发布和订阅信息尽快能同步到各服务节点上。</p>
<p>某种程度上，配置服务器在 HSF 框架中扮演了服务调用调度的指挥官，通过给服务调用者端推送不同的服务提供者列表就可以轻易的调整服务调用的路由，这一特性在淘宝平台实现单元化（即某一客户在访问淘宝时，访问请求一旦路由到某一个淘宝机房后，在淘宝上进行的所有业务的操作均可以在该机房完成，而无需访问其他机房的服务，也是实现异地多活的基础）、异地多活起到了至关重要的作用。</p>
<p><strong>5、Diamond 服务器</strong></p>
<p>本质上，<strong>Diamond 服务器是一个通用的统一配置管理服务</strong>，类似 ZooKeeper，给应用提供统一的配置设置和推送服务，使用场景非常广泛，在阿里巴巴内部有很多的产品在需要进行配置的保存和获取时都会使用 Diamond 服务器。</p>
<p>在 HSF 服务框架中，则主要承担了服务调用过程中对于服务调用安全管控的规则、服务路由权重、服务 QPS 阀值等配置规则的保存，<strong>所有的信息均是持久化保存到了后端的 MySQL 服务器中</strong>，在生产环境中，会有多台 Diamond 服务器提供负载均衡的服务。</p>
<p>使用 Diamond 服务器进行服务相关设置的典型场景如下：</p>
<ul>
<li>通过设置白名单（服务调用者所在服务节点 IP 地址）的方式设置某些服务或服务中的方法只能让特定 IP 地址的服务器调用；</li>
<li>通过用户认证的方式控制服务是否能够调用；</li>
<li>按照不同的服务器权重设置服务调用者对多个服务提供者服务节点的访问；</li>
<li>设置某些服务的 QPS 能力上限值，一旦该服务的 QPS 达到该阀值，则拒绝服务的继续调用，这也是实现服务限流的技术实现，在平台进行大促或秒杀场景时，保障平台的稳定的重要屏障。</li>
</ul>
<p>通过这样规则的设置，Diamond 除了将这些规则保存在自身的数据库中外，会自动将这些规则推送到相关的服务节点上（实际实现上是服务节点会定时从 Diamond 服务器上同步相关配置信息），使这些规则能立即在服务运行环境中生效。</p>
<p>如图 3-5 所示是阿里巴巴 HSF 服务框架的工作原理，按照服务注册发布、服务订阅、服务规则推送、最终服务提供者和服务调用者间的服务交互的顺序说明了 HSF 服务框架中每个组件在整个框架中所扮演的角色。</p>
<p><img src="http://img2.ph.126.net/tpQ9qJtMy1GcOt3gujpvFA==/6632258536792469066.jpg" alt="img"></p>
<p>图 3-5 HSF 服务框架工作原理示意图</p>
<p><strong>1）服务节点对配置服务器列表的获取。</strong></p>
<p>服务调用者和服务提供者在随着 Tomcat 容器启动后，会以域名（比如“xxx.tbsite.net”）的方式获取到可用的地址服务器，通过向地址服务器分别发送获取配置服务器和 Diamond 服务器服务 IP 列表请求的方式，在容器启动完成后，就已经在该服务节点上获取到了配置服务器和 Diamond 服务器的 IP 列表信息。整个过程如图 3-5 中的步骤①②。</p>
<p><strong>2）服务的注册发布。</strong></p>
<p>作为服务提供者，当获取到配置服务器的服务器列表后，则向配置服务器发送当前应用中包含的服务提供者相关信息（这些信息均是从应用的配置文件中获取到，比如服务的接口类全名、服务版本、所属服务组等信息），联同当前服务器的 IP 地址、服务端口等信息进行服务注册发布，如图 3-5 中的步骤③。这个步骤在每一个有服务提供的应用启动时都会自动执行，比如现在有 5 个提供同一服务的应用启动后，此时在配置服务器上就已经保存了提供这一服务的 5 个服务器相关信息。</p>
<p><strong>3）服务的订阅。</strong></p>
<p>当作为服务调用者的应用启动时，同样在完成配置服务器列表的获取后，就进行与配置服务器的交互，发送服务消费者相关信息（同样包含了服务的接口全名，服务版本、所属服务组）到配置服务器进行服务的订阅，此时在配置服务器上会通过服务接口全名+服务版本作为匹配条件在当前配置服务器的内存中进行搜索，一旦获取到对应的服务注册信息，则将对应的服务提供者的服务器组 IP 地址及端口返回给服务调用者所在的应用节点上，此时也就完成了服务调用者端对于它所需要调用的服务提供者服务器列表信息，用于在服务真正交互时使用。服务订阅过程如图 3-5 中的步骤④⑤。</p>
<p><strong>4）服务规则的推送（如果需要）。</strong></p>
<p>如果没有上文提到对于服务安全管控、流量控制等需求的时候，对于 Diamond 服务器的使用并不是必需的，在有这样的需求场景时，可通过 Diamond 提供的规则设置界面，可以对指定服务的服务提供者和调用者设置相关的规则，一旦保存规则后，则此规则配置将会在 5 秒内推送到与所设置服务相关的服务节点上。如图 3-5 中的步骤⑥。</p>
<p><strong>5）服务交互。</strong></p>
<p>在应用进行业务请求处理过程中，出现了服务调用者对服务提供者的调用时，服务调用者会从已经保存在该应用节点上的服务提供者服务器列表中选择（阿里巴巴内部使用随机模式）其中一台进行服务请求的发送，服务交互期间完全是服务调用者和服务提供者间两台服务器间的，无需通过中间服务器的中转，这就是相比于“中心化” ESB 模式，所有服务交互都需要“中心” ESB 进行服务路由，而当前这种架构称为“去中心化”的主要原因。如图 3-5 中的步骤⑦。</p>
<p>阿里巴巴的分布式服务框架核心是以服务化的方式构建整个应用体系的同时，要保证在高并发的情况下，服务具备高效交互、高可用性和扩展能力。接下来对于 HSF 框架如何给服务提供以上能力具体加以说明。</p>
<p><strong>1、HSF 框架采用 Netty + Hession 数据序列化协议实现服务交互</strong></p>
<p>HSF 框架中采用如今流行的网络通信框架 Netty 加上 Hession 数据序列化协议实现 HSF 服务间的交互，主要考虑点是在大并发量时，服务交互性能达到最佳。这类 RPC 协议采用多路复用的 TCP 长连接方式，在服务提供者和调用者间有多个服务请求同时调用时会共用同一个长连接，即一个连接交替传输不同请求的字节块。它既避免了反复建立连接开销，也避免了连接的等待闲置从而减少了系统连接总数，同时还避免了 TCP 顺序传输中的线头阻塞（head-of-line blocking）问题。</p>
<p>Hessian 是 HSF 框架中默认使用的数据序列化协议，在数据量较小时性能表现出众，Hessian 的优点是精简高效，同时可以跨语言使用，目前支持 Java, C++,  .net, Python, ruby 等语言。另外 Hessian 可以充分利用 Web 容器的成熟功能，在处理大量用户访问时很有优势，在资源分配、线程排队、异常处理等方面都可以由 Web 容器保证。</p>
<p>HSF 框架同时也支持切换使用 Java 序列化，Hession 相比 JDK 标准的序列化方式（即基于 Serializable 接口的标准序列化），在典型场景中，其序列化时间开销可能缩短 20 倍。虽然 Hessian 不是最快的序列化协议，但它对于复杂业务对象的序列化正确率、准确性相较于最稳定的 Java 序列化并不逊色太多。</p>
<p>业界还有一些比 Hessian 更快的序列化协议，但它们相对于 Hessian 在复杂场景下的处理能力还是会差一些，<strong>所以 Hessian 是在性能和稳定性同时考虑下最优的序列化协议。</strong></p>
<p>阿里巴巴当时在对多种通信协议和数据序列化组件等测试中，Netty + Hession 的组合在互联网高并发量的场景下,特别是在 TPS 上达到 10w 以上时，性能和效率远比 REST 或者 Web Service 高。</p>
<p><strong>2、HSF 框架的容错机制</strong></p>
<p>因为要保证服务的高可用性，所以在生产环境部署中一定会有<strong>多个应用实例作为服务提供者提供某一相同服务。</strong></p>
<p>基于之前所提到的服务框架的运行原理的说明，在进行服务调用时，服务调用者端已经保存了它所需要调用的服务提供者的服务器列表信息（如图 3-6 中为例，则保存了三台服务提供者所在服务器的列表）。</p>
<p>当采用随机方式获取其中一台进行服务交互时（如图 3-6 步骤①），不管是第一台服务器已经某种故障造成了服务请求无法响应，还是该服务器已经接收了服务请求，在进行服务请求处理过程中出现了服务器故障（比如宕机、网络问题），造成该服务器没有在规定的时间（一般服务调用会设置到期时间）返回服务处理的结果，服务调用者端则会获取到服务调用失败的反馈（如图 3-6 步骤②）。</p>
<p>在 HSF 服务调用的代码中会立即从剩下的服务提供者服务器列表中选择另外一个服务器再次进行服务请求（如图 3-6 步骤③），这一次这个服务提供者实例正常提供了此次服务的请求（如图 3-6 步骤④），从而保证了在个别服务提供者出现故障时，完全不会影响该服务正常提供服务。</p>
<p><img src="http://img1.ph.126.net/vuGysK3QsRHQJKUTHPrRGw==/6632018843260281046.jpg" alt="img"></p>
<p>图 3-6 HSF 服务框架实现服务高可用性原理示意图</p>
<p>同时，<strong>因为配置服务器是采用长连接的方式与服务节点进行网络通讯，一旦发现有服务提供者实例出现故障，配置服务器在秒级就会感知到</strong>（如图 3-6 步骤⑤），此时会将出问题这台服务提供者的信息从该服务的服务器列表中删除，并将更新后的服务器列表采用推送的方式同步给与该服务相关的所有服务调用者端（如图 3-6 步骤⑥），这样当下次服务调用者再进行此服务的调用时，就不会因为随机的方式再次对已经停止服务提供的服务器发起服务的调用。</p>
<p><strong>3、HSF 框架的线性扩展支持</strong></p>
<p>作为 HSF 框架设计之初，<strong>最为重要的一个特性就是服务能力的可扩展性。</strong>也就是真正的做到某个服务的业务处理能力能随着服务器资源的增加得到线性的增长。</p>
<p>其实在传统架构中一直也会强调平台的扩展能力，但均会程度不一的出现服务节点数量到达一定量后，出现阻碍平台服务能力扩展的问题，有的是出现网络传输的瓶颈、也有服务节点接入数量上的限制，前文所描述的 ESB 架构带来的“雪崩”效应也均是这类架构给服务能力的扩展带来影响的原因所在。</p>
<p>如图 3-7 中所描述的场景，当服务面对较大的服务调用压力或将要面临如天猫双11大促、秒杀等活动前，已有的服务提供者各服务器水位（CPU、内存、IO等）处于比较高的情况或现有服务能力满足不了业务访问量的要求时，则需要通过增加服务节点数量的方式提升该服务的服务处理能力。</p>
<p><img src="http://img0.ph.126.net/aXYvmt58vBlDyra69PSyfA==/6632181570981194421.jpg" alt="img"></p>
<p>图 3-7 HSF 服务框架对服务能力线性扩展支持1</p>
<p>此时，只需要通过增加该服务的服务提供者实例（如图 3-8 所示，增加了一个服务），基于 HSF 框架的运行机制，<strong>新增加的服务提供者实例一旦应用启动完成后，可在几秒内开始进行服务请求的处理</strong>（主要完成服务注册发布、更新后服务列表推送到服务调用者端），从而达到分担其他服务器实例压力的作用，实现服务能力整体水位恢复到正常的状态（如图 3-9）。</p>
<p><img src="http://img0.ph.126.net/g5M-yIgyLaGutr7V-khlZA==/6632145287097477015.jpg" alt="img"></p>
<p>图 3-8 HSF服务框架对服务能力线性扩展支持2</p>
<p><img src="http://img0.ph.126.net/EJIZHJ1KmkqfSwrZ3NwA2g==/6632081515423068015.jpg" alt="img"></p>
<p>图 3-9 HSF 服务框架对服务能力线性扩展支持3</p>
<p>正是基于 HSF 框架这一特性，从而真正实现了只要增加服务实例就能实现该服务能力扩展的目标，目前在阿里巴巴共享服务事业部中多个服务中心在天猫双 11 那天各自所部署的服务实例节点数量均超过 2000，即同一个服务由超过 2000 个服务实例同时提供负载均衡的服务。</p>
<p>本文由公众号《高可用架构》原创。</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/05/turning-back-time-savepoints/" itemprop="url">
                  Savepoint：Flink让时光倒流
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-05T09:19:04+08:00" content="2016-12-05">
              2016-12-05
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>现在互联网产品对数据的实时性要求极其强烈，比如，某电商产品的推荐系统，当一个用户点击页面就会在秒级内给出相应的推荐页面。进而，实时流处理技术讨论变得越加频繁《<a href="http://mp.weixin.qq.com/s?__biz=MzI0MDIxMDM0MQ==&amp;mid=2247483673&amp;idx=1&amp;sn=d70adf019c8cf797a41da6186e93f0fb&amp;scene=21#wechat_redirect" target="_blank" rel="external">各大主流流处理框架大比拼</a>》和《<a href="http://mp.weixin.qq.com/s?__biz=MzI0MDIxMDM0MQ==&amp;mid=2247483679&amp;idx=1&amp;sn=5e544ae789c8773f73b9e1d552e5f991&amp;scene=21#wechat_redirect" target="_blank" rel="external">实时流处理框架选型：就应该这样“拉出来遛遛”</a>》，比如，延迟性、吞吐量、watermark…</p>
<p>接下来，进入主题：Flink实时流处理中的“reprocess data”。</p>
<p>相信很多同行经常遇到以下几种case：</p>
<ul>
<li>开发新feature或者bug修复，程序新版本上线；</li>
<li>不同版本产品的A/B test；</li>
<li>评估和实现在新处理框架下的应用迁移，或者迁移到不同的集群</li>
</ul>
<p>以上所有情况都可以使用Flink的savepoint功能实现。</p>
<h6 id="Savepoint是什么"><a href="#Savepoint是什么" class="headerlink" title="Savepoint是什么"></a>Savepoint是什么</h6><p>简而言之，Flink的savepoint是一个全局的、一致性的快照（snapshot）。其包含两方面：</p>
<ul>
<li>数据源所有数据的位置；</li>
<li>并行操作的状态</li>
</ul>
<p>“全局一致”是指所有的输入源数据在指定的位置，所有的并行操作的状态都被完全checkpoint了。注意理解这句话，可以多读几遍回味一下。</p>
<p>如果你的应用在过去某个时间点做了savepoint，那你随时可以从前面的savepoint更新发布应用。这时，新的应用会从savepoint中的操作状态进行初始化，并从savepoint的数据源位置开始重新处理所有数据。</p>
<p>Flink的savepoint是完全不依赖的，所以你每个应用可以有N个savepoint，你可以回退到多个位置重新开始你的应用（可以是不同的应用，如下图所示）。这个功能在流处理应用是相当强大的。</p>
<p><img src="http://img0.ph.126.net/IJHz4DXlo7fLjCsEfhqsyg==/6631537257167466063.png" alt="image"></p>
<p>有读者会觉得上图似曾相识，其实你可能想到了Flink的checkpoint，这时是不是有点糊涂了，那savepoint和checkpoint到底啥关系呢？详细答案会在后续某篇文章揭晓，这里先简单说下：checkpoint是Flink实现容错的，savepoint仅仅只是checkpoint的一个扩展。如果checkpoint开启，那Flink会周期性的创建所有操作状态的checkpoint。savepoint和checkpoint最大的不同是，checkpoint会按时间间隔自动创建，而savepoint需要手动触发。</p>
<p>为了让 “reprocess data”得到更精确的结果，那我们不得不提event-time和processing-time或者ingestion-time的区别，这也是在各个流处理技术里常提到的时间语义。不过这里先不展开，后续也会有文章专门讲到。为了让 “reprocess data”得到更精确的结果需要使用event-time，因为依赖processing-time或者ingestion-time的应用会根据当前的wall-clock时间来处理。</p>
<h6 id="如何实现savepoint"><a href="#如何实现savepoint" class="headerlink" title="如何实现savepoint"></a>如何实现savepoint</h6><p>实际上，使用savepoint的前提有以下几点：</p>
<ul>
<li>开始checkpoint；</li>
<li>可重复使用的数据源（e.g., Apache Kafka，Amazon Kinesis，或者文件系统）；</li>
<li>所有保存的状态需继承Flink的管理状态接口；</li>
<li>合适的state backend配置</li>
</ul>
<p>做到了这几点，那你可以通过CLI命令行实现savepoint并重新从savepoint开始应用：</p>
<ol>
<li>创建savepoint</li>
</ol>
<p>首先，获取Flink所有正在运行的job list：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">user$ flink list</div><div class="line">------------Running/Restarting Jobs------------</div><div class="line">12.04.2016 16:20:33 : job_id : 12345678 (RUNNING)</div></pre></td></tr></table></figure>
<p>接着，使用刚才获取到的job ID创建savepoint：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user$ flink savepoint job_id</div></pre></td></tr></table></figure>
<p>这时你可以选择取消正在运行的job（可选操作）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user$ flink cancel job_id</div></pre></td></tr></table></figure>
<ol>
<li>从savepoint开启job</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user$ flink run -d -s hdfs://savepoints/1 directory/your-updated-application.jar</div></pre></td></tr></table></figure>
<h6 id="如果更新应用，该咋办？"><a href="#如果更新应用，该咋办？" class="headerlink" title="如果更新应用，该咋办？"></a>如果更新应用，该咋办？</h6><p>修改的应用从一个savepoint开始需要考虑以下两种情况：</p>
<ul>
<li>用户自定义逻辑的改变，比如，MapFunction；</li>
<li>应用的拓扑的改变，比如，增加或者移除操作</li>
</ul>
<p>如果你的情况属于上面描述的第一类，那不需要做其他额外处理。但是，第二种情况，Flink要求修改前后的操作要能匹配上，这样才好使用保存的操作状态。这时你需要手动在原始和更新的应用中分配操作ID，因为没有操作ID是不可能改变应用的拓扑，所以最好要尽可能的分配操作ID，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">DataStream stream = env.</div><div class="line"> // Stateful source (e.g. Kafka) with ID</div><div class="line"> .addSource(new StatefulSource())</div><div class="line"> .uid(“source-id”)</div><div class="line"> .shuffle()</div><div class="line"> // The stateful mapper with ID</div><div class="line"> .map(new StatefulMapper())</div><div class="line"> .uid(“mapper-id”)</div><div class="line"></div><div class="line">// Stateless sink (no specific ID required)</div><div class="line">stream.print()</div></pre></td></tr></table></figure>
<h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>Savepoint是Flink与其它流处理技术的独特之处，要好好的利用起来。</p>
<p>不过Flink的savepoint使用也有诸多限制，后续有机会再讲到，但相对于Spark Streaming的checkpoint来说还是高级了不少。</p>
<p><em>PS：虽然Spark项目的star数比Flink多一个数量级，但Flink在某些feature上的开发和布局比Spark更快，感觉Flink开发者在最近代表着实时流处理和离线大数据技术的方向，看好Flink</em>。</p>
<p>参考：<br>[1] <a href="http://data-artisans.com/turning-back-time-savepoints" target="_blank" rel="external">http://data-artisans.com/turning-back-time-savepoints</a></p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/05/kafka-cluster-optimize/" itemprop="url">
                  Kafka Cluster优化两三事
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-05T09:18:52+08:00" content="2016-12-05">
              2016-12-05
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>写在之前</em>：本文将讲述Kafka Cluster配置和优化。</p>
<p>Kafka Cluster（相对于单个server）最大的优点：可扩展性和容错性。</p>
<p><img src="http://img0.ph.126.net/InezSQTEYGXiSj-q7IAZ8Q==/6631959469629171084.png" alt="image"></p>
<p>​                               Kafka集群简图</p>
<h6 id="Kafka-Broker个数"><a href="#Kafka-Broker个数" class="headerlink" title="Kafka Broker个数"></a>Kafka Broker个数</h6><p>决定Kafka集群大小的因素有以下几点：</p>
<ul>
<li>磁盘容量：首先考虑的是所需保存的消息所占用的总磁盘容量和每个broker所能提供的磁盘空间。如果Kafka集群需要保留 10 TB数据，单个broker能存储 2 TB，那么我们需要的最小Kafka集群大小 5 个broker。此外，如果启用副本参数，则对应的存储空间需至少增加一倍（取决于副本参数）。这意味着对应的Kafka集群至少需要 10 个broker。</li>
<li>请求量：另外一个要考虑的是Kafka集群处理请求的能力。这主要取决于对Kafka client请求的网络处理能力，特别是，有多个consumer或者网路流量不稳定。如果，高峰时刻，单个broker的网络流量达到80%，这时是撑不住两个consumer的，除非有两个broker。再者，如果启用了副本参数，则需要考虑副本这个额外的consumer。也可以扩展多个broker来减少磁盘的吞吐量和系统内存。</li>
</ul>
<h6 id="Kafka-Broker配置"><a href="#Kafka-Broker配置" class="headerlink" title="Kafka Broker配置"></a>Kafka Broker配置</h6><p>同一个Kafka集群的所有broker机器必须满足以下两个参数：</p>
<ul>
<li>所有broker机器需配置相同的zookeeper连接参数（.connect）。这决定了Kafka集群存储的元数据位置；</li>
<li>所有broker机器需配置唯一的broker id（ .id）。如果一个集群下的两个broker配置了相同的broker id，则第二个broker启动时会失败并报错。</li>
</ul>
<h6 id="操作系统优化"><a href="#操作系统优化" class="headerlink" title="操作系统优化"></a>操作系统优化</h6><p>大部分Linux发布版本默认的内核参数配置能让大部分应用工作的相当好。但对于实际的Kafka broker场景来说，做稍些改变会提升broker性能。主要涉及的配置：虚拟内存、网络和磁盘挂载（用来存储log segment），一般在<em>/etc/sysctl.conf</em> (CentOS系统)。</p>
<ul>
<li>Virtual Memory</li>
</ul>
<p>一般来说，Linux的虚拟内存会根据系统负载自动调整。内存页（page）swap到磁盘会显著的影响Kafka的性能，并且Kafka重度使用page cache，如果VM系统swap到磁盘，那说明没有足够的内存来分配page cache。</p>
<p>避免swap的一种方式是设置swap空间为0。但是，swap会在系统崩溃时提供安全机制，或者会在out of memory的情况下阻止操作系统 kill 掉进程。由于这个原因，推荐 <em>vm.swappiness</em>参数设置为一个非常低的值：1 。这个参数表示 VM系统中的多少百分比用来作为swap空间。</p>
<p>另外一种方式是通过内核调节“脏页”（注：“脏页”会被刷到磁盘上）。Kafka依赖磁盘I/O性能来提高producer的响应时间。这也是为什么通常优先把log segment功能放在可以快速响应的磁盘中（比如，SSD）。这样使得flush进程把“脏数据”写入磁盘前，“脏页”数目就减少了，可以设置<em>vm.dirty_background_ratio</em>（表示占用系统内存的百分比）参数的值为 10 以下。大部分应用场景下，<em>vm.dirty_background_ratio</em>设置为 5 就够用了，要注意了：这个参数值不能设置为 0 ，因为设置为 0 后会引起内核持续刷“脏页”，使得内核的buffer write功能没法施展。</p>
<p>“脏页”的总量可以通过<em>vm.dirty_ratio</em> 来改变，默认值是 20 （此处也是百分比），这个值的设置范围较大，一般建议设置 60 到 80 为合理的值。但是<em>vm.dirty_ratio</em> 参数也引来了不小的风险，会造成大量unflush的数据在硬刷到磁盘时产生较长的I/O停顿。如果<em>vm.dirty_ratio</em> 值设置的较大时，强烈建议Kafka开启备份功能，以备系统崩溃。</p>
<p>在设置了这些参数后，需要监控Kafka集群运行时“脏页”的数量，当前“脏页”数量可由如下方式查看（/proc/vmstat文件）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># cat /proc/vmstat | egrep &quot;dirty|writeback&quot; nr_dirty 3875</div><div class="line">nr_writeback 29</div><div class="line">nr_writeback_temp 0</div></pre></td></tr></table></figure>
<ul>
<li>磁盘</li>
</ul>
<p>除了考虑磁盘硬件本身和RAID配置外，磁盘的filesystem对Kafka集群的影响最大。虽然有许多filesystem，但最常用的是EXT4或者XFS。在这里XFS文件系统比EXT4稍好，具体原因Google下。</p>
<p>另外一点是，建议开启mount的<em>noatime</em> mount选项。文件系统在文件被访问、创建、修改等的时候会记录文件的一些时间戳，比如：文件创建时间（ctime）、最近一次修改时间（mtime）和最近一次访问时间（atime）。默认情况下，atime的更新会有一次读操作，这会产生大量的磁盘读写，然而atime对Kafka完全没用。</p>
<ul>
<li>网络</li>
</ul>
<p>Linux发布版本的网络参数对高网络流量不适用。对于Kafka集群，推荐更改每个socket发送和接收buffer的最大内存：<em>net.core.wmem_default</em> 和 <em>net.core.rmem_default</em> 为128 kb，<em>net.core.wmem_max</em> 和<em>net.core.rmem_max</em> 为 2 Mb。另外一个socket参数是TCP socket的发送和接收buffer： <em>net.ipv4.tcp_wmem</em> 和 <em>net.ipv4.tcp_rmem</em>。</p>
<h6 id="Kafka集群稳定"><a href="#Kafka集群稳定" class="headerlink" title="Kafka集群稳定"></a>Kafka集群稳定</h6><p>主要涉及到GC、数据中心布局和ZK使用：</p>
<ul>
<li>GC调优</li>
</ul>
<p>调GC是门手艺活，幸亏Java 7引进了G1 垃圾回收，使得GC调优变的没那么难。G1主要有两个配置选项来调优：<em>MaxGCPauseMillis</em>和<em>InitiatingHeapOccupancyPercent</em>，具体参数设置可以参考Google，这里不赘述。</p>
<p>Kafka broker能够有效的利用堆内存和对象回收，所以这些值可以调小点。对于 64Gb内存，Kafka运行堆内存5Gb，<em>MaxGCPauseMillis</em>和<em>InitiatingHeapOccupancyPercent</em> 分别设置为 20毫秒和 35。</p>
<p>Kafka的启动脚本使用的不是 G1回收，需要在环境变量中加入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># export JAVA_HOME=/usr/java/jdk1.8.0_51</div><div class="line"># export KAFKA_JVM_PERFORMANCE_OPTS=&quot;-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true&quot;</div><div class="line"># /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties</div></pre></td></tr></table></figure>
<ul>
<li>数据中心布局</li>
</ul>
<p>原则上Kafka broker不建议都在一个机架上，为了容灾，但现实情况大部分公司做不到，此处略去。</p>
<ul>
<li>Zookeeper</li>
</ul>
<p>Kafka集群利用ZK来存储broker、topic和partition的元数据信息。</p>
<p>在Kafka 0.9.0之前，consumer利用ZK来直接存储consumer group的信息，包括topic的消费情况、每个partition消费的周期性commit。在0.9.0版本，提供新的consumer接口利用Kafka broker来管理。</p>
<p>Consumer可以选择使用Zk或者Kafka来提交 offset和 提交间隔。如果consumer使用ZK管理offset，那每个consumer在每个partition的每个时间间隔写入ZK。合理的offset提交间隔是1分钟，但如果一个Kafka集群有大量的consumer消费时，这个ZK流量将是巨大的。所以如果ZK不能处理大流量，那只能把offset提交间隔设大，但同时也带来丢数据的风险。最保险的建议是使用Kafka来提交offset。</p>
<p>另外，建议Kafka集群不要和其他应用使用同一组ZK，因为Kafka对于ZK的延迟和超时是相当敏感的，ZK的不通将会导致Kafka的不可预测性。</p>
<h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>Kafka在各大互联公司应用广泛，希望上述Kafka集群调优对各位有帮助。</p>
<p>PS：最近在负责招聘，有Hadoop、Spark、Flink、Kafka、Storm等相关经验的优秀人才，请联系我或者后台留言。</p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/24/visual-tools-for-machine-learning-part-3/" itemprop="url">
                  机器学习可视化系统完结篇：模型评估和参数调优
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-24T01:30:30+08:00" content="2016-10-24">
              2016-10-24
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>机器学习可视化系统完结篇：模型评估和参数调优</p>
<p><em>写在之前：前两篇讲述了特征分析：《<a href="http://mp.weixin.qq.com/s?__biz=MzI0MDIxMDM0MQ==&amp;mid=2247483684&amp;idx=1&amp;sn=428cf35632b2408e1dc7d36dff497c53&amp;scene=0#wechat_redirect" target="_blank" rel="external">可视化图表让机器学习“biu”的一样简单：特征分析</a>》和模型选择：《<a href="http://mp.weixin.qq.com/s?__biz=MzI0MDIxMDM0MQ==&amp;mid=2247483750&amp;idx=1&amp;sn=34d9979d6e2608535d9921db54d57a8d&amp;chksm=e91f19acde6890baa7e6950b7133bcf290549c8b2ef150e5422a3c2f0df233e51cbde2b5baf3&amp;scene=0#wechat_redirect" target="_blank" rel="external">机器学习模型选择如此简单</a>》。</em></p>
<p>本篇文章详细阐述机器学习模型评估和参数调优。将主要围绕两个问题来阐述：</p>
<ol>
<li>“知其所以然”：当你选择的一个机器学习模型运行时，你要知道它是如何工作的；</li>
<li>“青出于蓝”：更进一步，你得知道如何让此机器学习模型工作的更优。</li>
</ol>
<h4 id="模型评估的方法"><a href="#模型评估的方法" class="headerlink" title="模型评估的方法"></a>模型评估的方法</h4><p>一般情况来说，F1评分或者R平方(R-Squared value)等数值评分可以告诉我们训练的机器学习模型的好坏。也有其它许多度量方式来评估拟合模型。</p>
<p>你应该猜出来，我将提出使用可视化的方法结合数值评分来更直观的评判机器学习模型。接下来的几个部分将分享一些有用的工具。</p>
<p>首先想声明的，单单一个评分或者一条线，是无法完全评估一个机器学习模型。偏离真实场景来评估机器学习模型（’good’ or ‘bad’）都是“耍流氓”。某个机器学习模型若可“驾驭”小样本数据集生成最多预测模型（即，命中更多预测数据集）。如果一个拟合模型比其它拟合过的模型形式或者你昨天的预测模型能够得到更好的结果，那即是好（’good’）。</p>
<p>下面是一些标准指标： <em>confusion_matrix</em>，<em>mean_squared_error</em>， <em>r2_score</em>，这些可以用来评判分类器或者回归的好坏。表格中给出的是<strong><em>Scikit-Learn</em></strong>中的函数以及描述：</p>
<p>评估分类模型：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>描述</th>
<th>Scikit-learn函数</th>
</tr>
</thead>
<tbody>
<tr>
<td>Precision</td>
<td>精准度</td>
<td>from sklearn.metrics import precision_score</td>
</tr>
<tr>
<td>Recall</td>
<td>召回率</td>
<td>from sklearn.metrics import recall_score</td>
</tr>
<tr>
<td>F1</td>
<td>F1值</td>
<td>from sklearn.metrics import f1_score</td>
</tr>
<tr>
<td>Confusion Matrix</td>
<td>混淆矩阵</td>
<td>from sklearn.metrics import confusion_matrix</td>
</tr>
<tr>
<td>ROC</td>
<td>ROC曲线</td>
<td>from sklearn.metrics import roc</td>
</tr>
<tr>
<td>AUC</td>
<td>ROC曲线下的面积</td>
<td>from sklearn.metrics import auc</td>
</tr>
</tbody>
</table>
<p>评估回归模型：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>描述</th>
<th>Scikit-learn函数</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mean Square Error (MSE, RMSE)</td>
<td>平均方差</td>
<td>from sklearn.metrics import mean_squared_error</td>
</tr>
<tr>
<td>Absolute Error (MAE, RAE)</td>
<td>绝对误差</td>
<td>from sklearn.metrics import mean_absolute_error, median_absolute_error</td>
</tr>
<tr>
<td>R-Squared</td>
<td>R平方值</td>
<td>from sklearn.metrics import r2_score</td>
</tr>
</tbody>
</table>
<p>下面开始使用<strong><em>Scikit-Learn</em></strong>的可视化工具来更直观的展现模型的好坏。</p>
<h6 id="评估分类模型"><a href="#评估分类模型" class="headerlink" title="评估分类模型"></a>评估分类模型</h6><p>我们评估分类器是判断预测值时否很好的与实际标记值相匹配。正确的鉴别出正样本（True Positives）或者负样本（True Negatives）都是True。同理，错误的判断正样本（False Positive，即一类错误）或者负样本（False Negative，即二类错误）。</p>
<p>注意：True和False是对于评价预测结果而言，也就是评价预测结果是正确的(True)还是错误的(False)。而Positive和Negative则是样本分类的标记。</p>
<p>通常，我们希望通过一些参数来告知模型评估如何。为此，我们使用混淆矩阵。</p>
<h5 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h5><p><img src="https://silvrback.s3.amazonaws.com/uploads/4ab81a17-4a77-4e9e-b092-de5fac2afa07/confusionmatrix_large.png" alt="Confusion Matrix"></p>
<p>幸运的是，<strong><em>Scikit-Learn</em></strong>提供内建函数（<em>sklearn.metrics.confusion_matrix</em>）来计算混淆矩阵。输入数据集实际值和模型预测值作为参数，输出即为混淆矩阵，结果类似这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[[<span class="number">1238</span>   <span class="number">19</span>]   <span class="comment"># True Positives = 1238, False Negatives = 19</span></div><div class="line"> [   <span class="number">2</span>  <span class="number">370</span>]]  <span class="comment"># False Positives = 2, True Negatives = 370</span></div></pre></td></tr></table></figure>
<h5 id="分类报告"><a href="#分类报告" class="headerlink" title="分类报告"></a>分类报告</h5><p>分类报告除了包括混淆矩阵，也增加了其它优势，比如，混淆矩阵会标示样例是否被正确鉴别，同时也提供precision，recall和 F1 值三种评估指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</div><div class="line"></div><div class="line">print(classification_report(y_true, y_pred, target_names=target_names))</div></pre></td></tr></table></figure>
<p> 更进一步，可以对<strong><em>Scikit-Learn</em></strong>的内建函数做些加强，比如，使用带颜色区分的热力图，它将帮助我们的眼睛更容易的辨别预测成功（橘黄色）和失败（灰色）。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> colors</div><div class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</div><div class="line"></div><div class="line">ddl_heat = [<span class="string">'#DBDBDB'</span>,<span class="string">'#DCD5CC'</span>,<span class="string">'#DCCEBE'</span>,<span class="string">'#DDC8AF'</span>,<span class="string">'#DEC2A0'</span>,<span class="string">'#DEBB91'</span>,\</div><div class="line">            <span class="string">'#DFB583'</span>,<span class="string">'#DFAE74'</span>,<span class="string">'#E0A865'</span>,<span class="string">'#E1A256'</span>,<span class="string">'#E19B48'</span>,<span class="string">'#E29539'</span>]</div><div class="line">ddlheatmap = colors.ListedColormap(ddl_heat)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_classification_report</span><span class="params">(cr, title=None, cmap=ddlheatmap)</span>:</span></div><div class="line">    title = title <span class="keyword">or</span> <span class="string">'Classification report'</span></div><div class="line">    lines = cr.split(<span class="string">'\n'</span>)</div><div class="line">    classes = []</div><div class="line">    matrix = []</div><div class="line"></div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">2</span>:(len(lines)<span class="number">-3</span>)]:</div><div class="line">        s = line.split()</div><div class="line">        classes.append(s[<span class="number">0</span>])</div><div class="line">        value = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> s[<span class="number">1</span>: len(s) - <span class="number">1</span>]]</div><div class="line">        matrix.append(value)</div><div class="line"></div><div class="line">    fig, ax = plt.subplots(<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> range(len(matrix)+<span class="number">1</span>):</div><div class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> range(len(classes)):</div><div class="line">            txt = matrix[row][column]</div><div class="line">            ax.text(column,row,matrix[row][column],va=<span class="string">'center'</span>,ha=<span class="string">'center'</span>)</div><div class="line"></div><div class="line">    fig = plt.imshow(matrix, interpolation=<span class="string">'nearest'</span>, cmap=cmap)</div><div class="line">    plt.title(title)</div><div class="line">    plt.colorbar()</div><div class="line">    x_tick_marks = np.arange(len(classes)+<span class="number">1</span>)</div><div class="line">    y_tick_marks = np.arange(len(classes))</div><div class="line">    plt.xticks(x_tick_marks, [<span class="string">'precision'</span>, <span class="string">'recall'</span>, <span class="string">'f1-score'</span>], rotation=<span class="number">45</span>)</div><div class="line">    plt.yticks(y_tick_marks, classes)</div><div class="line">    plt.ylabel(<span class="string">'Classes'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Measures'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">cr = classification_report(y_true, y_pred)</div><div class="line">plot_classification_report(cr)</div></pre></td></tr></table></figure>
<p><img src="https://silvrback.s3.amazonaws.com/uploads/8a76cb0d-6ead-494f-b000-d3bd3ec58aad/classificationreport_large.png" alt="Classification Report"></p>
<p>看起来挺容易，对不？发现分类热力图的另外一个好处，它可以让我们看出一类错误 VS 二类错误。但有一个缺陷，它并不能垮模型进行比较，而这对评估拟合模型是相当重要的。因为这个原因，接下来将使用第二篇文章中的<em>classify</em>和<em>regress</em>代码。</p>
<p>下面的<em>get_preds</em>函数将输出一个实际标记值和预测值的二元组，这个二元组将会使得后续的跨模型的可视化比较变得容易：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_preds</span><span class="params">(attributes, targets, model)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    Executes classification or regression using the specified model</div><div class="line">    and returns expected and predicted values.</div><div class="line">    Useful for comparison plotting!</div><div class="line">    '''</div><div class="line">    splits = cv.train_test_split(attributes, targets, test_size=<span class="number">0.2</span>)</div><div class="line">    X_train, X_test, y_train, y_test = splits</div><div class="line"></div><div class="line">    model.fit(X_train, y_train)</div><div class="line">    y_true = y_test</div><div class="line">    y_pred = model.predict(X_test)</div><div class="line">    <span class="keyword">return</span> (y_true,y_pred)</div></pre></td></tr></table></figure>
<h5 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h5><p>另一种评估分类模型的方法是ROC（Receiver Operating Characteristic）曲线。我们能从<strong><em>Scikit-Learn</em></strong> 指标模块中import <em>roc_curve</em>，计算 true positive率和false positive 率的数值。我们也可以画出ROC曲线来权衡模型的敏感性和特异性。</p>
<p>下面的代码将画出ROC，Y轴代表true positive率，X轴代表false positive 率。同时，我们也可以增加同时比较两种不同的拟合模型，这里看到的是 <em>KNeighborsClassifier</em> 分类器远胜 <em>LinearSVC</em> 分类器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">roc_compare_two</span><span class="params">(y, yhats, models)</span>:</span></div><div class="line">    f, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, sharey=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">for</span> yhat, m, ax <span class="keyword">in</span> ((yhats[<span class="number">0</span>], models[<span class="number">0</span>], ax1), (yhats[<span class="number">1</span>], models[<span class="number">1</span>], ax2)):</div><div class="line">        false_positive_rate, true_positive_rate, thresholds = roc_curve(y,yhat)</div><div class="line">        roc_auc = auc(false_positive_rate, true_positive_rate)</div><div class="line">        ax.set_title(<span class="string">'ROC for %s'</span> % m)</div><div class="line">        ax.plot(false_positive_rate, true_positive_rate, \</div><div class="line">                c=<span class="string">'#2B94E9'</span>, label=<span class="string">'AUC = %0.2f'</span>% roc_auc)</div><div class="line">        ax.legend(loc=<span class="string">'lower right'</span>)</div><div class="line">        ax.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">'m--'</span>,c=<span class="string">'#666666'</span>)</div><div class="line">    plt.xlim([<span class="number">0</span>,<span class="number">1</span>])</div><div class="line">    plt.ylim([<span class="number">0</span>,<span class="number">1.1</span>])</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">y_true_svc, y_pred_svc = get_preds(stdfeatures, labels, LinearSVC())</div><div class="line">y_true_knn, y_pred_knn = get_preds(stdfeatures, labels, KNeighborsClassifier())</div><div class="line"></div><div class="line">actuals = np.array([y_true_svc,y_true_knn])</div><div class="line">predictions = np.array([y_pred_svc,y_pred_knn])</div><div class="line">models = [<span class="string">'LinearSVC'</span>,<span class="string">'KNeighborsClassifier'</span>]</div><div class="line"></div><div class="line">roc_compare_two(actuals, predictions, models)</div></pre></td></tr></table></figure>
<p><img src="https://silvrback.s3.amazonaws.com/uploads/27a127d5-5486-4175-9194-6f0f520bbe03/roc_auc_compare_large.png" alt="ROC_AUC Curve"></p>
<p>在ROC空间，ROC曲线越凸向左上方向效果越好；越靠近对角线，分类器越趋向于随机分类器。</p>
<p>同时，我们也会计算曲线下的面积（AUC），可以结合上图。如果AUC的值达到0.80，那说明分类器分类非常准确；如果AUC值在0.60～0.80之间，那分类器还算好，但是我们调调参数可能会得到更好的性能；如果AUC值小于0.60，那就惨不忍睹了，你得好好分析下咯。</p>
<h5 id="评估回归模型"><a href="#评估回归模型" class="headerlink" title="评估回归模型"></a>评估回归模型</h5><p>对于混凝土数据集试验一些不同的机器学习模型，然后评判哪种更好。在第二篇文章中，我们使用的平均方差和 R 平方值，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Mean squared error = <span class="number">116.268</span></div><div class="line">R2 score = <span class="number">0.606</span></div></pre></td></tr></table></figure>
<p>这些数值是有用的，特别是对不同的拟合模型比较平均方差和 R 平方值。但是，这是不够的，它不能告诉我们为什么一个模型远胜于另外一个；也不能告诉我们如何对模型调参数提高评分。接下来，我们将看到两种可视化的评估技术来帮助诊断模型有效性：预测错误曲线 和 残差曲线。</p>
<h5 id="预测错误曲线"><a href="#预测错误曲线" class="headerlink" title="预测错误曲线"></a>预测错误曲线</h5><p>为了知道我们的模型预测值与期望值到底有多接近，我们将拿混凝土数据集（混凝土强度）做例子，画出其期望值和模型预测值曲线。下面是不同回归模型的错误曲线：<em>Ridge</em>， <em>SVR</em> 和<em>RANSACRegressor</em>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">error_compare_three</span><span class="params">(mods,X,y)</span>:</span></div><div class="line">    f, (ax1, ax2, ax3) = plt.subplots(<span class="number">3</span>, sharex=<span class="keyword">True</span>, sharey=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">for</span> mod, ax <span class="keyword">in</span> ((mods[<span class="number">0</span>], ax1),(mods[<span class="number">1</span>], ax2),(mods[<span class="number">2</span>], ax3)):</div><div class="line">        predicted = cv.cross_val_predict(mod[<span class="number">0</span>], X, y, cv=<span class="number">12</span>)</div><div class="line">        ax.scatter(y, predicted, c=<span class="string">'#F2BE2C'</span>)</div><div class="line">        ax.set_title(<span class="string">'Prediction Error for %s'</span> % mod[<span class="number">1</span>])</div><div class="line">        ax.plot([y.min(), y.max()], [y.min(), y.max()], <span class="string">'k--'</span>, lw=<span class="number">4</span>, c=<span class="string">'#2B94E9'</span>)</div><div class="line">        ax.set_ylabel(<span class="string">'Predicted'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Measured'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">models = np.array([(Ridge(),<span class="string">'Ridge'</span>), (SVR(),<span class="string">'SVR'</span>), (RANSACRegressor(),<span class="string">'RANSAC'</span>)])</div><div class="line">error_compare_three(models, features, labels)</div></pre></td></tr></table></figure>
<p><img src="https://silvrback.s3.amazonaws.com/uploads/65b6159a-1745-41ac-a71e-d77624566774/model_error_large.png" alt="Visualizing error in regression models"></p>
<p>从这里可以很清晰的看出预测值和期望值的关系。同时也发现线性回归模型效果好。</p>
<h5 id="残差曲线"><a href="#残差曲线" class="headerlink" title="残差曲线"></a>残差曲线</h5><p> 残差是数据集每个实例的实际标记值和预测值之间的差值。通过画出一系列实例的残差，可以帮助我们检测它们是否随机错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">resids_compare_three</span><span class="params">(mods,X,y)</span>:</span></div><div class="line">    f, (ax1, ax2, ax3) = plt.subplots(<span class="number">3</span>, sharex=<span class="keyword">True</span>, sharey=<span class="keyword">True</span>)</div><div class="line">    plt.title(<span class="string">'Plotting residuals using training (blue) and test (green) data'</span>)</div><div class="line">    <span class="keyword">for</span> m, ax <span class="keyword">in</span> ((mods[<span class="number">0</span>], ax1),(mods[<span class="number">1</span>], ax2),(mods[<span class="number">2</span>], ax3)):</div><div class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> list(X):</div><div class="line">            splits = cv.train_test_split(X[[feature]], y, test_size=<span class="number">0.2</span>)</div><div class="line">            X_tn, X_tt, y_tn, y_tt = splits</div><div class="line">            m[<span class="number">0</span>].fit(X_tn, y_tn)</div><div class="line">            ax.scatter(m[<span class="number">0</span>].predict(X_tn),m[<span class="number">0</span>].predict(X_tn)-y_tn,c=<span class="string">'#2B94E9'</span>,s=<span class="number">40</span>,alpha=<span class="number">0.5</span>)</div><div class="line">            ax.scatter(m[<span class="number">0</span>].predict(X_tt), m[<span class="number">0</span>].predict(X_tt)-y_tt,c=<span class="string">'#94BA65'</span>,s=<span class="number">40</span>)</div><div class="line">        ax.hlines(y=<span class="number">0</span>, xmin=<span class="number">0</span>, xmax=<span class="number">100</span>)</div><div class="line">        ax.set_title(m[<span class="number">1</span>])</div><div class="line">        ax.set_ylabel(<span class="string">'Residuals'</span>)</div><div class="line">    plt.xlim([<span class="number">20</span>,<span class="number">70</span>])        <span class="comment"># Adjust according to your dataset</span></div><div class="line">    plt.ylim([<span class="number">-50</span>,<span class="number">50</span>])  </div><div class="line">    plt.show()</div><div class="line"></div><div class="line">models = np.array([(Ridge(),<span class="string">'Ridge'</span>), (LinearRegression(),<span class="string">'Linear Regression'</span>), (SVR(),<span class="string">'SVR'</span>)])</div><div class="line">resids_compare_three(models, features, labels)</div></pre></td></tr></table></figure>
<p><img src="https://silvrback.s3.amazonaws.com/uploads/f4280e91-f5b1-43f8-a2a8-5a0e5b7174b2/residuals_large.png" alt="Plotting residuals in regression models"></p>
<h5 id="Bias-VS-Variance"><a href="#Bias-VS-Variance" class="headerlink" title="Bias VS Variance"></a>Bias VS Variance</h5><p>每种评估器都有是有利有弊。</p>
<p>首先 Error = Bias + Variance。Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。</p>
<h5 id="机器学习可视化调参"><a href="#机器学习可视化调参" class="headerlink" title="机器学习可视化调参"></a>机器学习可视化调参</h5><p>在文章开篇，我们提出了两个问题：我们如何知道一个机器学习模型可以工作？我们如何让这个模型工作（运行）的更好？</p>
<p>接下来，我们将回答第二个问题。如果你有注意，我们用的模型都是使用<strong><em>Scikit-Learn</em></strong> 默认的参数。对于我们的大部分拟合模型来讲，评分已经相当好了。但有时并没有那么幸运，这时我们就得自己调参数。</p>
<h6 id="可视化训练和验证模型"><a href="#可视化训练和验证模型" class="headerlink" title="# 可视化训练和验证模型"></a># 可视化训练和验证模型</h6><p> 如何选择最好的模型参数呢？一种方法是，用单一参数的不同值去验证一个模型的评估分数。让我们拿<em>SVC</em> 分类器来试验，通过调不同的gama值来画出训练值和测试纸的曲线。</p>
<p>我们的关注点是训练值和测试值都高的点。如果两者都低，那是欠拟合（underfit）；如果训练值高但是测试值低，那说明是过拟合（overfit）。</p>
<p>下面的代码画出来的曲线是拿信用卡数据集来做例子，这里用的 6折交叉验证。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_val_curve</span><span class="params">(features, labels, model)</span>:</span></div><div class="line">    p_range = np.logspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">5</span>)</div><div class="line"></div><div class="line">    train_scores, test_scores = validation_curve(</div><div class="line">        model, features, labels, param_name=<span class="string">'gamma'</span>, param_range=p_range,</div><div class="line">        cv=<span class="number">6</span>, scoring=<span class="string">'accuracy'</span>, n_jobs=<span class="number">1</span></div><div class="line">    )</div><div class="line"></div><div class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</div><div class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</div><div class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</div><div class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</div><div class="line"></div><div class="line">    plt.title(<span class="string">'Validation Curve'</span>)</div><div class="line">    plt.xlabel(<span class="string">'$\gamma$'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Score'</span>)</div><div class="line">    plt.semilogx(p_range, train_scores_mean, label=<span class="string">'Training score'</span>, color=<span class="string">'#E29539'</span>)</div><div class="line">    plt.semilogx(p_range, test_scores_mean, label=<span class="string">'Cross-validation score'</span>, color=<span class="string">'#94BA65'</span>)</div><div class="line">    plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">X = scale(credit[[<span class="string">'limit'</span>,<span class="string">'sex'</span>,<span class="string">'edu'</span>,<span class="string">'married'</span>,<span class="string">'age'</span>,<span class="string">'apr_delay'</span>]])</div><div class="line">y = credit[<span class="string">'default'</span>]</div><div class="line">plot_val_curve(X, y, SVC())</div></pre></td></tr></table></figure>
<p><img src="https://silvrback.s3.amazonaws.com/uploads/5b3cc5b4-a6f3-4146-b951-94a2b3547bfc/validation_curve_large.png" alt="Validation curve"></p>
<h5 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h5><p>对于超参数调优，大部分人使用的grid search。Grid search是一种暴力调参方法，即遍历所有可能的参数值。</p>
<p>对于信用卡数据集使用 <em>SVC</em>模型，我们通过试验不同内核系数gama来提高预测准确性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">blind_gridsearch</span><span class="params">(model, X, y)</span>:</span></div><div class="line">    C_range = np.logspace(<span class="number">-2</span>, <span class="number">10</span>, <span class="number">5</span>)</div><div class="line">    gamma_range = np.logspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">5</span>)</div><div class="line">    param_grid = dict(gamma=gamma_range, C=C_range)</div><div class="line">    grid = GridSearchCV(SVC(), param_grid=param_grid)</div><div class="line">    grid.fit(X, y)</div><div class="line"></div><div class="line">    print(</div><div class="line">        <span class="string">'The best parameters are &#123;&#125; with a score of &#123;:0.2f&#125;.'</span>.format(</div><div class="line">            grid.best_params_, grid.best_score_</div><div class="line">        )</div><div class="line">    )</div><div class="line">features = credit[[<span class="string">'limit'</span>,<span class="string">'sex'</span>,<span class="string">'edu'</span>,<span class="string">'married'</span>,<span class="string">'age'</span>,<span class="string">'apr_delay'</span>]]</div><div class="line">labels   = credit[<span class="string">'default'</span>]</div><div class="line">blind_gridsearch(SVC(), features, labels)</div></pre></td></tr></table></figure>
<p>但是，grid search需要我们理解哪些参数是合适的，参数的意义，参数是如何影响模型的以及参数的合理的搜索范围来初始化搜索。</p>
<p>这里，我们使用 <em>visual_gridsearch</em> 代替 <em>blind_gridsearch</em> 函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">visual_gridsearch</span><span class="params">(model, X, y)</span>:</span></div><div class="line">    C_range = np.logspace(<span class="number">-2</span>, <span class="number">10</span>, <span class="number">5</span>)</div><div class="line">    gamma_range = np.logspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">5</span>)</div><div class="line">    param_grid = dict(gamma=gamma_range, C=C_range)</div><div class="line">    grid = GridSearchCV(SVC(), param_grid=param_grid)</div><div class="line">    grid.fit(X, y)</div><div class="line"></div><div class="line">    scores = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> grid.grid_scores_]</div><div class="line">    scores = np.array(scores).reshape(len(C_range), len(gamma_range))</div><div class="line"></div><div class="line">    plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</div><div class="line">    plt.subplots_adjust(left=<span class="number">.2</span>, right=<span class="number">0.95</span>, bottom=<span class="number">0.15</span>, top=<span class="number">0.95</span>)</div><div class="line">    plt.imshow(scores, interpolation=<span class="string">'nearest'</span>, cmap=ddlheatmap)</div><div class="line">    plt.xlabel(<span class="string">'gamma'</span>)</div><div class="line">    plt.ylabel(<span class="string">'C'</span>)</div><div class="line">    plt.colorbar()</div><div class="line">    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=<span class="number">45</span>)</div><div class="line">    plt.yticks(np.arange(len(C_range)), C_range)</div><div class="line">    plt.title(</div><div class="line">        <span class="string">"The best parameters are &#123;&#125; with a score of &#123;:0.2f&#125;."</span>.format(</div><div class="line">        grid.best_params_, grid.best_score_)</div><div class="line">    )</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">visual_gridsearch(SVC(), features, labels)</div></pre></td></tr></table></figure>
<p><img src="https://silvrback.s3.amazonaws.com/uploads/e440eb11-0bbd-44be-a9fb-4264581d654b/validation_heatmap_large.png" alt="Validation accuracy as a function of gamma and C"></p>
<p> <em>visual_gridsearch</em> 的方法可以帮助我们理解不同的模型参数下的精确值。但是超参数调优的路程很长，好些人为此研究了几十年。</p>
<h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><p>这是可视化机器学习部分的最后一篇，可视化在机器学习的过程占用重要的角色。许多工具都提供这个功能，比如， <em>Scikit-Learn</em> ，<em>Matplotlib</em> ， <em>Pandas</em> ，<em>Bokeh</em> 和 <em>Seaborn</em>。</p>
<p><em>希望我写的对部分人有用，如果是这样，请让我知道，谢谢。</em></p>
<p>Enjoy!</p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/20/streaming-process-data-access/" itemprop="url">
                  流式处理架构的“瓶颈”：数据访问（上）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-20T11:31:42+08:00" content="2016-09-20">
              2016-09-20
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>写在之前：这是用微软输入法打出来的一篇文章。</em></p>
<h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a><em>背景</em></h5><p>在Linkedin，大体架构是：ApacheSamza作为流式处理框架，Apache Kafka作为持久化的订阅/发布消息中间件，Databus监控数据库的变化。</p>
<h5 id="数据访问（Data-access）的两种模式"><a href="#数据访问（Data-access）的两种模式" class="headerlink" title="数据访问（Data access）的两种模式"></a><em>数据访问（Data access）的两种模式</em></h5><p>为什么数据访问是规模化的挑战？我们处理的数据访问模式主要分两种：</p>
<p><em>Read/write data：</em><br>这里给出一个在Linkedin中使用read-write数据访问模式的场景。Linkedin许多应用需要推送信息给会员，不管通过email还是通知。为了保证更好的用户体验，尽量不多给会员发email。Linkedin开发一个基于Samza的ATC（Air Traffic Control ）应用来控制email和通知送达终端用户。ATC追踪每个会员收到的最后一封邮件的时间，以及所有新的邮件请求的时间。ATC维护着每个会员的状态信息（read/write）。</p>
<p><em>Read-only data：</em><br>同样，给出一个只读数据访问的场景。Linkedin开发一个应用监听会员点击某条广告的事件的时间。这个应用会生成一个AdQuality事件，并高亮点击某些特定广告的会员特征。AdQuality事件会用来训练广告推荐机器学习模型。应用处理AdQuality事件会去查询点击广告的会员的画像。</p>
<h5 id="数据访问的关键特征"><a href="#数据访问的关键特征" class="headerlink" title="数据访问的关键特征"></a><em>数据访问的关键特征</em></h5><p>除了以上描述的两种访问模式，以下两种数据访问的关键特征也将会极大地影响事件流式处理的架构。</p>
<p><em>数据访问是否分区？</em><br>上面的场景，Kafka的topic是以MemberId分区的。输入事件已经按会员信息（MemberId）分区，那每个事件处理节点仅仅需要访问一个不变的会员数据集。后续我们会看到，如何对已经分区过的数据访问进行缓存优化。<br>另外一种场景，假设处理每个事件都需要查询Company库获取会员的更多信息，那每个事件处理节点就得查询可能的每个公司。这是访问未分区数据的例子。</p>
<p><em>数据集的大小</em><br>后面会看到，访问一个5M数据集的解决方案跟访问一个5 TB数据集的方案完全不同。比如，你可以把5M数据集完整的存储到每个节点上，然而很显然你不可能对5 TB的数据集做同样的操作。</p>
<h5 id="数据访问的解决方案"><a href="#数据访问的解决方案" class="headerlink" title="数据访问的解决方案"></a><em>数据访问的解决方案</em></h5><p>下面是展示的是两种常用的数据访问解决方案。</p>
<p><em>远程存储</em>：这是开发应用的传统的方式。当一个应用处理一个事件，它会远程调用一个隔离的SQL或者No-SQL数据库。这种方法中，写操作总是采用远程调用，但是读数据可以通过本地缓存进行一定程度上的优化。LinkedIn有大量的应用采用这种方法。<br>另外一种模式，在远程数据库（比如，Oracle）前面前置一个远程缓存（比如，Couchbase）。远程缓存主要用来数据读操作，应用通过Databus之类的工具追踪数据库变化，并替代远程缓存。</p>
<p><em>本地存储（嵌入式）</em>：这种方法是要求事件处理结果存储的位置和事件处理的地方在同一台机器上。极端的情况是所有数据存储访问都是本地，这样效率最高。<br>Samza天生就是支持嵌入式本地数据库，它支持把RocksDB嵌入你的事件处理器。它是通过Kafka log compacted topic做备份。</p>
<p>也有其它框架，比如Microsoft ServiceFabric，它本身内建支持本地应用存储。ServiceFabric支持持久化数据到本地磁盘，并把备份持久化到其它处理器实例。ServiceFabric持久化会自动备份到Azure storage。</p>
<h5 id="事件到达点-VS-事件处理点"><a href="#事件到达点-VS-事件处理点" class="headerlink" title="事件到达点 VS 事件处理点"></a><em>事件到达点 VS 事件处理点</em></h5><p>本地存储和远程存储的讨论是相对于事件处理的位置。在选择使用的框架时，事件到达的位置可能与事件处理的位置不在同一位置。</p>
<p>像GoogleDataflow这类框架支持从未分区的输入源（GooglePub-Sub）读取数据。这种模型中，当事件到达时，处理器会先找出当前事件应该归哪个处理器处理，并转发到对应的实际处理器处理。</p>
<p>而Samza、Spark Streaming和Flink之类的流处理框架《<a href="http://mp.weixin.qq.com/s?__biz=MzI0MDIxMDM0MQ==&amp;mid=2247483679&amp;idx=1&amp;sn=5e544ae789c8773f73b9e1d552e5f991#wechat_redirect" target="_blank" rel="external">实时流处理框架选型：就应该这样“拉出来遛遛”</a>》天然就支持事件的分区（Kafka，Kinesis等），因此不会再做一步转发处理。</p>
<p>如果你的应用得瓶颈是网络带宽或者计算能力，那处理事件的节点和事件的到达在同一个节点不会出现转发，将会极大的提高性能。</p>
<p>抛开在事件处理之前进行事件转发的情况，本文讨论的在事件处理过程中考虑数据访问这些依然对所有的事件处理框架适用。</p>
<h5 id="在路上"><a href="#在路上" class="headerlink" title="在路上"></a><em>在路上</em></h5><p>海量流式处理没有一个完美的方案，大家可以根据公司的场景进行平衡取舍。</p>
<p>本文主要讲了两种数据访问的模式，以及数据访问关键特征对架构的影响，并给出了相应的解决方案。最后讨论了事件到达和事件处理位置不同带来的解决方案不同。下期更精彩，敬请关注。</p>
<p><em>PS：最近更新较少，说声抱歉了。这几周工作较忙，主要涉及到的知识点有：CDH集群、Hue、Zeppelin、Caravel for Hive、elasticsearch on hadoop/Hive、Gobblin、Neo4j等，可以后台留言交流。</em></p>
<p><em>参考</em>：<br>[1] <a href="https://engineering.linkedin.com/blog/2016/08/stream-processing-hard-problems-part-ii--data-access" target="_blank" rel="external">https://engineering.linkedin.com/blog/2016/08/stream-processing-hard-problems-part-ii--data-access</a></p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/20/visual-tools-for-machine-learning-part-2/" itemprop="url">
                  机器学习模型选择如此简单
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-20T11:26:21+08:00" content="2016-09-20">
              2016-09-20
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>写在之前：有些概念跟平时你见过的机器学习文章描述的可能不太一样，但是它会给你一种“心里一颤“的感觉</em>。</p>
<p>机器学习的讨论经常会涉及到的问题是：什么机器学习模型才是最好的？是逻辑回归模型，随机森林模型，贝叶斯方法模型，支持向量机模型？抑或是神经网络模型？每个人似乎都有自己心中最爱！但这些讨论试图把机器学习的挑战缩减为单个问题，而这对机器学习的初学者带来了特别严重的误解。</p>
<p>选择一个好的机器学习模型固然重要，但这远远不够。在缺乏领域知识，基本假设，数据选型和实际的应用的情况下，还是值得商榷的。关于机器学习模型评价这部分将留在下一篇文章阐述。</p>
<p> feature engineering (FE)，algorithm selection (AS)，and parameter tuning (PT)；</p>
<h5 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h5><p>能训练一个“合适”的模型和预测是相当依赖特征工程、参数调优和模型选择。模型选择是机器学习过程比较难的部分，复杂、迭代，经常不断的去“试错”和重复。</p>
<h6 id="模型选择实战"><a href="#模型选择实战" class="headerlink" title="模型选择实战"></a>模型选择实战</h6><p>相信大家对Scikit-Learn“<a href="http://scikit-learn.org/stable/tutorial/machine_learning_map" target="_blank" rel="external">如何选择Estimator</a>”里的流程图非常熟悉了，不熟悉的点开链接读读。这个流程图是给初学者一个选择机器学习算法的最佳实践的参考手册。</p>
<p><img src="http://scikit-learn.org/stable/_static/ml_map.png" alt="image"></p>
<p>首先，看下我们的数据集（三个数据集参考上篇《<a href="http://mp.weixin.qq.com/s?__biz=MzI0MDIxMDM0MQ==&amp;mid=2247483684&amp;idx=1&amp;sn=428cf35632b2408e1dc7d36dff497c53&amp;scene=21#wechat_redirect" target="_blank" rel="external">可视化图表让机器学习“biu”的一样简单：特征分析</a>》）的样本数是否够50。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> len(occupancy) <span class="comment"># 8,143</span></div><div class="line"><span class="keyword">print</span> len(credit)    <span class="comment"># 30,000</span></div><div class="line"><span class="keyword">print</span> len(concrete)  <span class="comment"># 1,030</span></div></pre></td></tr></table></figure>
<p>很显然这个条件是满足的。接着看下是否我们是否预测类别。对于房屋入住和信用卡数据集来说是判断类别；而混凝土数据集，缓凝土的抗压强度是连续数据，所以预测的是数量。因此，为前两个数据集选择分类器（classifier）；为后者选择回归模型（regressor）。</p>
<p>因为我们的两个判断类别的数据集都小于100K，接着按图选择<em>sklearn.svm.LinearSVC</em>（其会将数据集映射到高维特征空间）；如果失败，就再选择<em>sklearn.neighbors.KNeighborsClassifier</em>（其会分配样本到它的K领域）。你应该还记得房屋入住数据集单位不统一，所以这里引入<em>scale</em>进行归一化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> scale</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(attributes, targets, model)</span>:</span></div><div class="line">    <span class="comment"># Split data into 'test' and 'train' for cross validation</span></div><div class="line">    splits = cv.train_test_split(attributes, targets, test_size=<span class="number">0.2</span>)</div><div class="line">    X_train, X_test, y_train, y_test = splits</div><div class="line"></div><div class="line">    model.fit(X_train, y_train)</div><div class="line">    y_true = y_test</div><div class="line">    y_pred = model.predict(X_test)</div><div class="line">    print(confusion_matrix(y_true, y_pred))</div><div class="line"></div><div class="line"><span class="comment"># Divide data frame into features and labels</span></div><div class="line">features = occupancy[[<span class="string">'temp'</span>, <span class="string">'humid'</span>, <span class="string">'light'</span>, <span class="string">'co2'</span>, <span class="string">'hratio'</span>]]</div><div class="line">labels   = occupancy[<span class="string">'occupied'</span>]</div><div class="line"></div><div class="line"><span class="comment"># Scale the features</span></div><div class="line">stdfeatures = scale(features)</div><div class="line"></div><div class="line">classify(stdfeatures, labels, LinearSVC())</div><div class="line">classify(stdfeatures, labels, KNeighborsClassifier())</div></pre></td></tr></table></figure>
<p>对于信用卡数据集使用相同的<em>classify</em>，根据上篇的特征分析经验，我们这里需要先进行数据缺失处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">features = credit[[</div><div class="line">    <span class="string">'limit'</span>, <span class="string">'sex'</span>, <span class="string">'edu'</span>, <span class="string">'married'</span>, <span class="string">'age'</span>, <span class="string">'apr_delay'</span>, <span class="string">'may_delay'</span>,</div><div class="line">    <span class="string">'jun_delay'</span>, <span class="string">'jul_delay'</span>, <span class="string">'aug_delay'</span>, <span class="string">'sep_delay'</span>, <span class="string">'apr_bill'</span>, <span class="string">'may_bill'</span>,</div><div class="line">    <span class="string">'jun_bill'</span>, <span class="string">'jul_bill'</span>, <span class="string">'aug_bill'</span>, <span class="string">'sep_bill'</span>, <span class="string">'apr_pay'</span>, <span class="string">'may_pay'</span>,</div><div class="line">    <span class="string">'jun_pay'</span>, <span class="string">'jul_pay'</span>, <span class="string">'aug_pay'</span>, <span class="string">'sep_pay'</span></div><div class="line">]]</div><div class="line">labels   = credit[<span class="string">'default'</span>]</div><div class="line"></div><div class="line">stdfeatures = scale(features)</div><div class="line"></div><div class="line">classify(stdfeatures, labels, LinearSVC())</div><div class="line">classify(stdfeatures, labels, KNeighborsClassifier())</div></pre></td></tr></table></figure>
<p>对于混凝土数据集，我们得决定是否所有的特征都重要，或者只有一部分重要。如果选择所有的特征都很重要，那根据流程图手册路线应该选择<em>sklearn.linear_model.RidgeRegression</em>或者<em>sklearn.svm.SVR</em>（有点类似LinearSVC classifier）；如果觉得只有部分特征重要，那就选择<em>sklearn.linear_model.Lasso</em>（其会在预测时舍弃部分特征）或者<em>sklearn.linear_model.ElasticNet</em>（其介入 Lasso方法和Ridge方法之间，L1和 L2惩罚的线性组合）。</p>
<p>下面来试试看咯：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge, Lasso, ElasticNet</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">regress</span><span class="params">(attributes, targets, model)</span>:</span></div><div class="line">    splits = cv.train_test_split(attributes, targets, test_size=<span class="number">0.2</span>)</div><div class="line">    X_train, X_test, y_train, y_test = splits</div><div class="line"></div><div class="line">    model.fit(X_train, y_train)</div><div class="line">    y_true = y_test</div><div class="line">    y_pred = model.predict(X_test)</div><div class="line">    print(<span class="string">'Mean squared error = &#123;:0.3f&#125;'</span>.format(mse(y_true, y_pred)))</div><div class="line">    print(<span class="string">'R2 score = &#123;:0.3f&#125;'</span>.format(r2_score(y_true, y_pred)))</div><div class="line"></div><div class="line">features = concrete[[</div><div class="line">    <span class="string">'cement'</span>, <span class="string">'slag'</span>, <span class="string">'ash'</span>, <span class="string">'water'</span>, <span class="string">'splast'</span>, <span class="string">'coarse'</span>, <span class="string">'fine'</span>, <span class="string">'age'</span></div><div class="line">]]</div><div class="line">labels   = concrete[<span class="string">'strength'</span>]</div><div class="line"></div><div class="line">regress(features, labels, Ridge())</div><div class="line">regress(features, labels, Lasso())</div><div class="line">regress(features, labels, ElasticNet())</div></pre></td></tr></table></figure>
<p>正如上面代码展示的那样，Scikit-Learn API使得我们可以快速的发布我们需要的模型，这是Scikit-Learn一个强有力的魔力。</p>
<h5 id="可视化模型"><a href="#可视化模型" class="headerlink" title="可视化模型"></a>可视化模型</h5><p>Scikit-Learn流程图非常有用是因为其提供了使用路径地图，但是它不能提供各种模型的函数。因而另外两幅图成为Scikit-Learn的权威：<a href="http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html" target="_blank" rel="external">分类器比较</a>和<a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html" target="_blank" rel="external">聚类比较</a>。</p>
<p>多个小图形很容易比较出不同的数据集适合的聚类算法：</p>
<p><img src="http://scikit-learn.org/stable/_images/plot_classifier_comparison_001.png" alt="image"></p>
<p>类似的，分类器比较图很好的帮助我们对不同的数据集选择哪种合适的分类器：</p>
<p><img src="http://scikit-learn.org/stable/_images/plot_cluster_comparison_001.png" alt="image"></p>
<p>一般来说，这些图形仅仅是证明了各种模型对不同数据集的优化；但我相信大家都希望有一种可视化工具可以对同一个数据集使用不同的模型的情况进行比较。</p>
<h5 id="模型簇"><a href="#模型簇" class="headerlink" title="模型簇"></a>模型簇</h5><p>首先给出“模型”这个词的定义，它包括三方面：</p>
<ul>
<li>模型簇：比如，linear model，nearest neighbors，SVM，Bayes等模型；</li>
<li>模型形式：比如，sklearn.linear_model.Ridge()，sklearn.linear_model.Lasso()，sklearn.linear_model.ElasticNet等；</li>
<li>拟合模型：比如，Ridge().fit(X_train, y_train)。</li>
</ul>
<p>模型簇是由特征空间决定的；模型形式是通过试验和统计检验来选择的；拟合模型是由参数调优和机器计算生成的。</p>
<p>我们讨论的这些，模型形式的试验会在后续文章中讲到，这部分是我们期望能够得到回报的想象空间。模型形式是指出我们的特征是如何和模型簇相关。</p>
<p>我喜欢的模型展示工具之一是Dr. Saed Sayad的可交互的“<a href="http://www.saedsayad.com/data_mining_map.htm" target="_blank" rel="external">数据挖掘地图</a>”。它比Scikit-Learn的流程图手册综合性更高，并且结合里模型簇和模型形式的概念。除了预测方法外，Sayad地图也包含了统计方法部分。</p>
<p>这里给出一个普适的流程图，它旨在结合Sayad地图和 Scikit-Learn流程图。颜色和等级代表模型形式和模型簇：</p>
<p><img src="http://img1.ph.126.net/xsHUK3F6SKjQtXUHzDliYA==/6631651606375660672.png" alt="image"></p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>通过在同一个数据集上比较和对比不同模型的性能，我们能从模型簇中直观的选取模型形式。</p>
<p>下期将会讲解拟合模型和调参的可视化工具。</p>
<p><em>PS：这周深入的“研究”了下Flume，日志收集利器，但是对Hadoop版本的支持太低，填了不少坑……</em></p>
<p><em>希望我写的对部分人有用，如果是这样，请让我知道，谢谢。</em></p>
<hr>
<p>侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
<p>若发现以上文章有任何不妥，请联系我。</p>
<p><img src="http://img1.ph.126.net/FQI2AsgiKe9OkxHv6LZ2JQ==/6631621919559857881.jpg" alt="image"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://img0.ph.126.net/3vPAbMoh_6fH3-g_I0zo-w==/6631748363397501906.jpg"
               alt="侠天" />
          <p class="site-author-name" itemprop="name">侠天</p>
          <p class="site-description motion-element" itemprop="description">侠天，专注于大数据、机器学习和数学相关的内容，并有个人公众号：bigdata_ny分享相关技术文章。</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">35</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/1333564335" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.infoq.com/cn/author/%E4%BE%A0%E5%A4%A9" target="_blank" title="InfoQ">
                  
                    <i class="fa fa-fw fa-infoq"></i>
                  
                  InfoQ
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">侠天</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
